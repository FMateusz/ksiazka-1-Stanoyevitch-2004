\documentclass[../main.tex]{subfiles}
\begin{document}

\chapter{Appendix B: Solutions to All Exercises for the Reader}
\label{chap:chap_15}


NOTE: All of the M-files of this appendix (like the M-files of the text) are downloadable as text files 
from the ftp site for this text: \\
ftp://ftp.wiley.com/public/sci\_tech\_med/numerical\_differential / 
\\
Occasionally, for space considerations, we may refer a particular M-file to this site. Also, in cases 
where a long MATLAB command does not fit on a single line (in this appendix), it will be continued 
on the next line. In an actual MATLAB session, (long) compound commands should either be put on a 
single line, or three periods (...) should be entered after a line to hold offMATLAB's execution until 
the rest of the command is entered on subsequent lines and the ENTER key is pressed. The text 
explains these and other related concepts in greater detail. \\
\line(2,0){\textwidth}\\
\\
\textbf{CHAPTER 1: MATLAB BASICS }\\
\\
\textbf{\underline{EFR 1.1:}} \texttt{linspace(-2,3,ll )} \\
\\
\textbf{\underline{EFR 1.2:}} \texttt{t = 0:.01:10*pi; x = 5*cos(t/5)+cos(2*t) ;} \\
\texttt{y = 5*sin(t/5)+sin(3*t) ; plot(x,y) , axis('equal' ) }
\\
\\
\textbf{\underline{EFR 1.3:}} Simply run the code through MATLAB to see if you analyzed it correctly.
\\
\\ 
\line(2,0){\textwidth}\\
\\
\textbf{CHAPTER 2: BASIC CONCEPTS OF NUMERICAL ANALYSIS WITH 
TAYLOR'S THEOREM }
\\
\\
\textbf{\underline{EFR 2.1:}}
\begin{lstlisting}[numbers=none,frame=none]
 x=-10:.05:10 ; y-cos(x) ; p2=1-x.^2/2 ; p4=1-
x.^2/2+x.^4/gamma(5); p6=l-x.^2/2+x.^4/gamma(5)-x.^6/gamma(7); p8=1-
x.^2/2+x.^4/gamma(5)-x.^6/gamma(7)+x.^8/gamma(9); p10=p8-
x."10/gamma(11); hold on, plot(x,p10,'k:') , axis([-2*p i 2*pi -1. 5 
1.5]) , plot(x,p8,'c:') , plot(x,p6,'r-.') , plot(x,p4,k--') , 
plot(x,p2,'g') , plot(x,y,'+' ) 
\end{lstlisting}
\textbf{\underline{EFR 2.2:}}Computing the first few derivatives of:
\\
\\
$
f(x)=x^{1 / 2}, f^{\prime}(x)=\frac{1}{2} x^{-1 / 2}, f^{\prime \prime}(x)=-\frac{1 \cdot 1}{2 \cdot 2} x^{-3 / 2}, f^{\prime \prime}(x)=\frac{1 \cdot 1 \cdot 3}{2 \cdot 2 \cdot 2} x^{-5 / 2} \text {, }
$
\\
$
f^{(4)}(x)=-\frac{1 \cdot 1 \cdot 3 \cdot 5}{2 \cdot 2 \cdot 2 \cdot 2} x^{-7 / 2} \ldots, $leads us to discover the general pattern:
\\
$
f^{(n)}(x)=(-1)^{n+1} \frac{1 \cdot 3 \cdot 5 \cdots(2[n-1]-1)}{2^{n}} x^{-(2 n-1) / 2} (for \left.n \geq 2\right). $Applying Taylor's theorem (with a= 16, x=17 ), we estimate the error of this approximation:
\\
\\
$
\left|R_{n}(17)\right|=\left|\frac{f^{(n+1)}(c)}{(n+1) !} 1^{n+1}\right|=\left|\frac{1 \cdot 3 \cdot 5 \cdots(2 n-1)}{2^{n}(n+1) !} c^{-(2 n+1) / 2}\right| \leq \frac{1 \cdot 3 \cdot 5 \cdots(2 n-1)}{2^{n}(n+1) !} 16^{-(2 n+1) / 2}=$
\\
$\frac{1 \cdot 3 \cdot 5 \cdots(2 n-1)}{2^{n}(n+1) ! \cdot 4 \cdot 16^{n}}=\frac{1 \cdot 3 \cdot 5 \cdots(2 n-1)}{2^{5 n+2}(n+1) !}$. We use MATLAB to find the smallest $n$ for which this last expression is less than $10^{10}$; then Taylor's theorem will assure us that the Taylor polynomial of this 
order will provide us with the desired approximation.
\begin{lstlisting}[numbers=none,frame=none]
>> n=2; ErrorEst=l*3/gamma(n+2)/2^(5*n+2) ; 
>> while ErrorEst>le-10, n=n+l; ErrorEst=ErrorEst*(2*n-l)/(n+1)/2 5; 
end 
>> n->n =7 
>> ErrorEst->ErrorEst = 2.4386e-011 %this checks out . 
\end{lstlisting} 
So $p_{7}(17)=\sum_{k=0}^{7} \frac{1}{k !} f^{(k)}(16) \cdot 1^{k}$ will give the desired approximation. We use MATLAB to perform and check it: 
\begin{lstlisting}[numbers=none,frame=none]
 >> sum=16^(l/2)+16^(-1/2)/2; %first-order Taylor Polynomial 
term = 16^(-1/2)/2; %first-order term 
for k=2:7, term = -term*(2*(k-1)-1)/2/16/k; sum=sum+term; end, format 
long 
>> sum->sum = 4.12310562562925 (approximation) 
>>abs (sum-sqrt (17))->ans =1.1590e-011 %actual error excels goal 
\end{lstlisting}
\textbf{\underline{EFR 2.3:}} Using ordinary polynomial substitution, subtraction, and multiplication (and ignoring 
terms in the individual Maclaurin series that give rise to terms of order higher than 10), we use (9) and (10) to obtain: (a) sin($x^2$) - cos($x^3$)=
$$
\left(x^{2}-\frac{\left(x^{2}\right)^{3}}{3 !}+\frac{\left(x^{2}\right)^{5}}{5 !}-\cdots\right)-\left(1-\frac{\left(x^{3}\right)^{2}}{2 !}+\cdots\right)=-1+x^{2}-\left(\frac{1}{2 !}-\frac{1}{3 !}\right) x^{6}+\frac{x^{10}}{5 !} \cdots
$$
(b) $\sin ^{2}\left(x^{2}\right)=\left(x^{2}-\frac{\left(x^{2}\right)^{3}}{3 !}+\cdots\right) \cdot\left(x^{2}-\frac{\left(x^{2}\right)^{3}}{3 !}+\cdots\right)=x^{4}-\frac{2}{3 !} x^{3}+\cdots$
In each case, $p_{10}$(x) consists of all of the terms listed on the right-hand sides. 
\\
\\
\line(2,0){\textwidth}\\
\textbf{CHAPTER 3: INTRODUCTION TO M-FILES }\\
\\
\textbf{\underline{EFR 3.1}} : In the left box we give the stored M-file; in the right we give the subsequent MATLAB session. 
\begin{center}
\begin{tabular}{|l|l|}
\hline
\texttt{\% script file for EFR 3.1:}&\texttt{>> n=5 ; listp 2 -> power = 2, power = 4}\\
\texttt{listp2} &\texttt{>> n=264;listp 2}\\
\texttt{power =2;} &\texttt{-> power = 2, power = 4, power = 8, power =16, }\\
\texttt{while power <= n} &\texttt{power = 32, power = 64, power =128, power = 256,}\\
\texttt{~~~power} &\texttt{>>n=2917;listp2 }\\
\texttt{~~~power=2*power;} &\texttt{-> power = 2, power = 4, power = 8, power =16,}\\
\texttt{end} &\texttt{power = 32, power = 64, power =128, power = 256,}\\
&\texttt{power = 1024, power = 2048}\\
\hline
\end{tabular}
\end{center}
Note: If we wanted the output to be just a single vector of the powers of 2, the following modified 
script would do the job: 
\\
\\
\begin{lstlisting}[numbers=none,frame=none]
% script file for EFR 3.1: Iistp2ver2 
power =2; vector = [ ]; %start off with empty vector 
whil e power <= n 
	vector = [vector power]; 
	power=2*power; 
end, vector
\end{lstlisting}
For example, with this file stored, if we enter \texttt{>> n=264; Iistp2ver2} , we get the following 
vector output:\\
\texttt{->vector = 2 4 8 16 32 64 128 256 }\\
\\
\textbf{\underline{EFR 3.2:}} With the boxed function M-file below saved, MATLAB will give the following outputs:
\begin{lstlisting}[numbers=none]
functio n f = fact(n ) 
% FACT f = fact(n) returns the factorial n! of a nonnegative integer 
n 
f=l; 
for i=l:n 
	f=f*i; 
end 
\end{lstlisting}
\texttt{>> fact(4) , fact (10), fact(0)}\\
\texttt{->ans = 24, 3628800, 1 }
\\
\\
\textbf{\underline{EFR 3.3 :}} At any (non-endpoint) maximum or minimum value y($x_0$), a differentiable function has 
its derivative equaling zero. This means that the tangent line is horizontal, so that for small values of a $ \Delta{x}$ = $x-x_0,$ $\Delta{y}/\Delta{x}$ approaches zero. Thus, the y-variations are much smaller than the x-variations as x gets close to the critical point in question. This issue will be revisited in detail in Chapter 6. 
\\
\\
\textbf{\underline{EFR 3.4:}} We have only considered the values of y at a discrete set of (equally spaced) jc-values. It 
is possible for a function to oscillate wildly in intervals between sets of discrete points (think trig 
functions with large amplitudes). More analysis can be done to preclude such pathologies (e.g., 
checking to see that there are no other critical points).
\\
\\
\textbf{\underline{EFR 3.5 :}} The M-file for the function is straightforward:
\begin{lstlisting}[numbers=none]
function y = wiggly(x) 
%Function M-file for the mathematical function of EFR 3.5 
y=sin(exp(1./(x.^2 + 0.5).^2)).*sin(x);
\end{lstlisting}
\begin{lstlisting}[numbers=none,frame=none]
(a)>> x=-2:.001:2 ; plot(x,wiggly(x) ) %plot is shown on left below 
(b)>> quad (Gwiggly, 0,2 , le-5 ) ->ans = 1.03517910753379 
(c) To better see what we are looking for, we create another plot of the function zoomed in near x = 0. 
>> x=0:.001:.3 ; plot(x,wiggly(x) ) %plot is shown (w/ othe radditions) 
on right below. 
\end{lstlisting}
We seek the x-coordinates of the two points marked with "x's" in the figure below.
\begin{figure}[H]
\includegraphics[width=0.9\linewidth]{41}
	\centering
	\label{pfig:ch13_41}
\end{figure}
\begin{lstlisting}[numbers=none,frame=none]
>>xmax=fminbnd('-wiggly(x)',0,0.1,optimset('TolX',le-5))
->xmin =0.02289435851906 
>>xmax=fminbnd('-wiggly(x)',0,0.1,optimset('TolX',le-5)) 
->xmax =0.05909071987402 
Red and green x's can now be added to the graph as follows: >> hold on, 
plot (xmin, wiggly (xmin), 'rx') , plot (xmin, wiggly (xmin) , ' gx')
\end{lstlisting}
This also gives us a visual check that we found what we were looking for.) \\
(d) To get a rough idea of the location of the x-value we are searching for, we now add the graph of the 
line y = x/2 (as a black dotted line): \texttt{>> plot (x, x/2 , ' k--) } From the graph, we see that the 
intersection point we are looking for is the one closest to the midpoint of \texttt{xmin} and \texttt{xmax}.\\
\texttt{>> xcross=fzero('wiggly(x)-x/2',(xmin+xmax)/2 ) }\\
\texttt{-> xcross =0.04479463640226 }\\
Let's do a quality check: \texttt{>> wiggly (xcross)-xcross/2}
\\
\texttt{->ans = 2.185751579730777e-016 (Very Good!) }
\\
\\
\line(2,0){\textwidth}\\
\textbf{CHAPTE R 4 : PROGRAMMIN G IN MATLA B }
\\
\\
\textbf{\underline{EFR 4.1 :}} Simply run the code through MATLAB to see if you analyzed it correctly. 
\\
\\
\textbf{\underline{EFR 4.2:}} (a) The M-file is boxed below:
\begin{lstlisting}[numbers=none]
function [ ] = sum2sq(n) 
%M-file for EFR 4.2 
for a=l:sqrt(n) 
	b=sqrt(n-aA2); %solve n=aA2+bA2 for b 
	if b==floor(b); %checks to see if b is integer 
		fprintf('the integer %d can be written as the sum of squares 
of %d and %d', n,a,b) 
		return 
	end 
end 
fprintf('the integer %d cannot be written as the sum of squares', n) 
\end{lstlisting}
(b) We now perform the indicated program runs:\\ 
>> \texttt{sum2sq (5) ->}the integer 5 can be written as the sum of squares of 1 and 2 \\
>> \texttt{sum2sq (25) ->} the integer 25 can be written as the sum of squares of 3 and 4 \\
>> \texttt{sum2sq (12233)} -The integer 12233 can be written as the sum of squares of 28 and 107 \\
(c) The following modification of the above M-file will be more suitable to solving this problem:
\begin{lstlisting}[numbers=none]
function flag = sum2sqb(n) 
%M-file for EFR 4.2b 
flag=0; %will change to 1 if n can be written as a^2+b^2 
for a=l:sqrt(n) 
	b=sqrt(n-a^2); %solve n=a^2+b^2 for b 
	if b==floor(b); %checks to see if b is integer 
		flag=l; 
		return 
	end 
end 
\end{lstlisting}
The program has output 1 if and only if n is expressible as a sum of squares; otherwise the output is 
zero. Now the following simple code will compute the desired integer n:
\begin{lstlisting}[numbers=none,frame=none]
>> for n=99999:-l:l , flag=sum2sqb(n); 
if flag==0 
fprintf('%d is the largest integer less than 100,000 not expressible 
as a sum of squares',n) 
break 
end 
end 
\end{lstlisting}
->99999 is the largest integer less than 100,000 not expressible as a sum of squares 
(We did not have to go very far.) \\
(d) A minor modification to the above code will give us what we want; simply change the for loop to 
\texttt{>>for n=1001:l : 99999} (and the wording in the \texttt{fprintf} statement).\\
We then find the integer to be 1001. \\
(e) The following code will determine what we are looking for:\\
\begin{lstlisting}[numbers=none,frame=none]
>> for n=2:99999, flag=sum2sqb(n); if flag==0, count=count+l; end, 
end 
>> count 
->count =75972 
\end{lstlisting}
\textbf{Note:} Part (e) took only a few seconds. If the programs were written less efficiently, for example, if 
we had run a nested loop by letting a and b run separately between all integers from 0 to $\sqrt{n}$ (or 
larger), some parts of this problem (notably, part (e)) could not be done in a reasonable amount of 
computer time.
\\
\\
\\
\textbf{\underline{EFR 4.3 :}} (a) Before you run the indicated computations in a MATLAB session, try to figure out the 
output by hand. This will assure that you understand both the Collatz sequence generation process as 
well as the program. The reason for clearing the vector a at the end of the script is so that on 
subsequent runs, this vector will not start with old values from previous runs. \\
(b) The M-file is boxed below:
\begin{lstlisting}[numbers=none]
function n = collctr(an) 
n=0; 
while an ~= 1 
	if ceil(an/2)==an/2 %tests if an is even 
		an=an/2; 
	else 
		an=3*an+1; 
	end 
	n=n+l; 
end 
\end{lstlisting}
\textbf{\texttt{EFR 4.4:}} (a) The M-file is boxed below: 
\begin{lstlisting}[numbers=none]
%raffledraw.m 
%scriptfile for EFR 4.4 

K = input('Enter number of players: ') ; 
N=zeros(K,26); %this allows up to 26 characters for each players 
		%name. 
n=input('Enter IN SINGLE QUOTES first player name: ') ; 
len(l)=length(n); 
N(l,l:len(l))=n; 
W(l)=input('Enter weight of first player: ') ; 
for i=2:K-l 
	n=input('Enter IN SINGLE QUOTES next player name: ') ; 
	len(i)=length(n); 
	N(i,l:len(i))=n; 
	W(i)=input('Enter weight of this player: ') ; 
end 
u=inputTfcntetIN SINGLE QUOTES last player nawe: ' \; 
len(K)=length(n) ; 
N(K, l:len(K))=n; 
W(K)=input('Enter weight of last player: ') ;
 
totW = sum(W); %total weight of all players (=# of raffle tickets) 

%the next four commands are optional, they only add suspense and 
%drama to the raffle drawing which the computer can do in lightning 
%time 
fprintf('\r \r RANDOM SELECTION PROCESS INITIATED \r \r ...') 
paused) %creates a 1 second pause
fprintf C\r \r ...SHUFFLING \r \r') 
pause(5) %creates a 5 second pause 
%%%%%%%%%%%%%%%%%%%%%%% 

rand('state',sum(100*clock)) 
magic = floor(totW*rand); %this will be a random number between 0 and 
		%totW 
count =W(1); %number of raffle tickets of player 1 
if magic<=count 
	fprintf('WINNER IS %s \r \r \ char(N(1,1:len(1)))) 
	fprintf('CONGRATULATIONS %s!!!!!!!!!!!!', char(N(1,1:len (1)))) 
	return 
else count = count + W(2); k=2; 
	while 1 
		if magic <=count 
	 	 fprintf ('WINNER IS %s \r \r 	% char (N (k, 1: len (k) )) ) 
	fprintf('CONGRATULATIONS %s!!!!!!!!!!!!', char(N(k,	1:len(k)))) 
	return 
	end 
	k=k+l; count = count +W(k); 
	end 
end 	
\end{lstlisting}
(b) We now perform the indicated program runs: \\
\texttt{>> raffledraw }
Enter number of players: 4 \\
Enter IN SINGLE QUOTES first player name: '\texttt{Alfredo} ' \\
Enter weight of first player: 4 \\
Enter IN SINGLE QUOTES next player name: ' \texttt{Denise} ' \\
Enter weight of this player: 2 \\
Enter IN SINGLE QUOTES next player name: ' \texttt{Sylvester} ' \\
Enter weight of this player: 2 \\
Enter IN SINGLE QUOTES last player name: ' \texttt{Laurie} ' \\
Enter weight of last player: 4 \\
\\
RANDOM SELECTION PROCESS INITIATED\\
... ...SHUFFLING.... \\
->WINNER IS Laurie \\
->CONGRATULATIONS Laurie!!!!!!!!!!!! \\
\\
On a second run the winner was Denise. If written correctly, and if this same raffledra w is run 
many times, it should turn out (from basic probability) that Alfredo and Laurie will each win roughly 
4/12 or 33 1/3\% of the time while Denise and Sylvester will win roughly 2/12 or 16 2/3\% of the time. 
\\
\\
\\
\line(2,0){\textwidth}\\
\textbf{CHAPTER 5: FLOATING POINT ARITHMETIC AND ERROR 
ANALYSIS }
\\
\\
\underline{\textbf{EFR 5.1}:} For shorthand we write: FPA to mean "the floating point answer," EA to mean "the 
exact answer," E to mean the "error" = |FAP-EA|, and RE to mean "the relative error" = E/|EA|.\\ 
(a) FPA = 0.023, EA = 0.0225, E = 0.0005, RE = 0.02222$\cdots$\\
(b) FPA = 370,000 $\times$.45 = 170,000, EA = 164990.2536, E - 5009.7464, RE = 0.030363... \\
(c) FPA = 8000$ \div$ 120 = 67 , EA = 65.04878..., E = 1.9512195121$\cdots$ , RE = 0.029996... 
\\
\\
\textbf{\underline{EFR 5.2:}} (a) As in the solution of Example 5.3, since the terms are decreasing, we continue to 
compute partial sums (in 2-digit rounded floating point arithmetic) until the terms get sufficiently small 
so as to no longer have any effect on the accumulated sum. 
\\
\\
$S_1$=l, $S_2$=$S_1$+1/2=1+.5= 1.5, $S_3$ = $S_2$ +1/3=1.5+.33=1.8, $S_4$ = $S_3$+1/4=1.8+.25 = 2.1,\\ 
$S_5$=.$S_4$+l/ =2.1+.2=2.3, $S_6$=$S_5$+1/6=2.3+.17=2.5, $S_7$= $S_6$+1/7=2.5+.14=2.6, \\
$S_8$ = $S_7$ +1/8=2.6+.13=2.7, $S_9$ =$S_8$+1/9=2.7+.11 = 2.8, $S_{10}$ = $S_9$+1/10=2.8+.1=2.9.
\\
\\
This pattern continues until we reach $S_20$ : In each such partial sum.$S_k$, 1 / k contributes 0.1 to the cumulative sum. As soon as we reach $S_21$ , the terms (1/21 = 0.048) in floating point arithmetic 
become too small to have any effect on the cumulative sum so we have converged; thus the final 
answer is: 2.9 + 10$\times$.l = 3.9.\\
(b)(i)$x^2$= 100 : Working in exact arithmetic, there are, of course, two solutions: x=±10. These are 
also floating point solutions and any other floating point solutions will lie in some intervals about these 
two. Let's start with the floating point solution x=10. In arithmetic of this problem, the next floating point number greater than 10 is 11 and (in floating point arithmetic) $11^2$ = 120, so there are no floating 
point solutions greater than 10. Similarly the floating point number immediately preceding 10 is 9.9 
and (in floating point arithmetic) $9.9^2$= 98, so there are no (positive) floating point solutions less than 
10. Similarly, -10 is the only negative floating point solution. Thus there are exactly two floating 
point solutions (or more imprecisely: between 2 and 10 solutions). \\
(ii) $8x^2=x^5$: In exact arithmetic, we would factor this $x^5-8x^2=x^2(x^3-8)=0$ to get the real 
solutions: x = 0 and x = 2. Because of underflow, near x = 0, we can get many (more than 10) floating 
point solutions. Indeed, since e=8, if $|x|<10^{-5}$
, then both sides of the equation will underflow to 
zero so we will have a solution. Any number of form $\pm$ a,b$ \times 10^{-c}$
, where a and b are any digits 
(a $\neq$ 0 ) and c = 6, 7, or 8, will thus be a floating point solution, so certainly there are more than 10 
solutions. (How many are there exactly?)
\\
\\
\textbf{\underline{EFR 5.3 :}} (a) As in the solution to Example 5.4, we may assume that x$\neq$0 and write 
x =$.d_1d_2 \cdots d_sd_{s+1} \cdots \times 10^e.$ Now, since we are using s-digit rounded arithmetic, f1(x) is the closer of 
the two numbers$ .d_1d_2 \cdots d_5 \times 10^e and .d_1d_2 \cdots d_s \times 10^e + 10^{-s} \times 10^e to x$. Since the gap between these two numbers has length $10^{-s} \times 10^{e}$, we may conclude that $|x-fl(x)| \leq \frac{1}{2} \cdot 10^{-s} \times 10^{e}$. On the other hand, $|x| \geq .100 \cdots 0 \times 10^{e}=10^{e-1}$. Putting these two estimates together, we obtain the following estimate for the relative error: $\left|\frac{x-fl(x)}{x}\right| \leq \frac{\frac{1}{2} \cdot 10^{-s} \times 10^{e}}{10^{e-1}}=\frac{1}{2} \cdot 10^{1-s}$. Since equality is possible, we conclude that  $u=\frac{1}{2} \cdot 10^{1-s}$, as asserted. The floating point numbers are the same whether we are using 
chopped or rounded arithmetic, so the gap from 1 to the next floating point number is still $10^{1-s}$, as 
explained in the solution of Example 5.4.\\
(b) If x = 0, we can put $\delta$= 0; otherwise put $\delta$ = [fl(x)-x]/x.
\\
\\
\textbf{\texttt{EFR 5.4:}} (a) Since N-i$\leq$N when i is nonnegative, we obtain from (6) that 
$$
\begin{aligned}
\left|\mathrm{fl}\left(S_{N}\right)-S_{N}\right| & \leq u\left[(N-1) a_{1}+(N-1) a_{2}+(N-2) a_{3}+\cdots+2 a_{N-1}+a_{N}\right] \\
& \leq u\left[N a_{1}+N a_{2}+N a_{3}+\cdots+N a_{N-1}+N a_{N}\right]=N u \sum_{n=1}^{N} a_{n} .
\end{aligned}
$$
(b) Simply divide both sides of the inequality in (a) by $\sum_{n=1}^{N} a_{n}$ obtain the inequality in (b).  
\\
\\
\textbf{\underline{EFR 5.5:}} From $1-\frac{1}{3}+\frac{1}{5}-\frac{1}{7}+\cdots=\frac{\pi}{4}$, we can write $\pi=4-\frac{4}{3}+\frac{4}{5}-\frac{4}{7}+\cdots=\sum_{n=0}^{\infty}(-1)^{n} a_{n}$, where $a_{n}=4 /(2 n+1)$. Letting $s_{N}$ denote the partial sum $\sum_{n=0}^{N}(-1)^{n} a_{n}$, Leibniz's theorem tells us that Error $=\left|\pi-S_{N}\right| \leq a_{N+1}=4 /(2 N+3)$. Since we want Error $<10^{-7}$, we should take $N$ large enough to satisfy $4 /(2 N+3)<10^{-7} \Rightarrow 2 N+3>4 \cdot 10^{7} \Rightarrow N>\left(4 \cdot 10^{7}-3\right) / 2=19,999,998.5$. \\
Letting N = 19,999,999, we get MATLAB to perform the summation of the corresponding terms in 
order of increasing magnitude: 
\begin{lstlisting}[numbers=none,frame=none]
>> format long 
>> Sum=0; N=19999999; 
>> for n=N:-l:0 
Sum=Sum+(-1)^n*4/(2*n+l) ; 
end 
>> Sum 
->Sum = 3.14159260358979 (approximation to pi ) 
>> abs(pi-Sum) 
->ans = 4.999999969612645e-008 (exact error of approximation)
\end{lstlisting}
\line(2,0){\textwidth}\\
\textbf{CHAPTER 6: ROOTFINDING} 
\\
\\
\textbf{EFR 6.1:} The accuracy of the approximation \texttt{x7} is actually better than what was guaranteed from 
(1). The actual accuracy is less than 0.001 (this can be shown by continuing with the bisection method 
to produce an approximation \texttt{xn} with guaranteed accuracy less than 0.00001 (how large should n be?) and then estimating $\mid x7-root$ $|\leq| x 7-x n|+| x n-\operatorname{root} \mid \leq 9 \times 10^{-4}+1 \times 10^{-5}<0.001$. So actually, $|f(x 7)|$ is over 30 times as large as $\mid x 7$ - root|. This can be explained by estimating $y^{\prime}($ root $) \geq 30$ (do it graphically, for example). Thus, for small values of $\Delta x \equiv x$-root, $\Delta y / \Delta x$ gets larger than 30 . This is why the $y$-variations turn out to be more than 30 times as large as the $x$-variations, when $x$ gets close to the root.
\\
\\
\textbf{\underline{EFR 6.2:}} (a) Since $f(0)=1-0>0, f(\pi / 2)=0-\pi / 2<0$, and $f(x)$ is continuous, we know from the intermediate value theorem that $f(x)$ has a root in $[0, \pi / 2]$. Since $f^{\prime}(x)=\sin (x)-1<0$ on $(0, \pi / 2), f(x)$ is strictly decreasing so it can have only one root on $[0, \pi / 2]$.
(b) It is easy to check that the first value of $n$ for which $\pi /\left(2 \cdot 2^{n}\right)\left(=(b-a) / 2^{n}\right)$ is less than $0.01$ is $n$ $=8$. Thus by (1), using $x 0=0$, it will be sufticient to nun through $n=8$ iterations of the bisection method to arrive at an approximation $x 8$ of the root that has the desired accuracy. We do this with the following MATLAB loop:
\begin{lstlisting}[numbers=none,frame=none]
>> xn=0; an=0; bn=pi/2 ; n=0; 
>> whil e n<=8 
xn=(an+bn)/2 ; n=n+l; 
if f(x)==0, root = xn; return 
elseif f(x)>0, an=xn; bn=bn; 
else, an=an; bn=xn; 
end 
end 
>> xn 
->xn =0.73937873976088
\end{lstlisting}
c) The following simple MATLAB loop will determine the smallest value of \texttt{n} for which $\pi$/(2$\cdot$2) will be less than $10^{12}$
 (by (1) this would be the smallest number of iterations in the bisection method 
for which we could be guaranteed the indicated accuracy). (This could certainly also be done using logs.) 
\begin{lstlisting}[numbers=none,frame=none]
>> while pi/2/2^n>=le-12 , n=n+l; end 
>> n 
->n = 41 
>> pi/2/2^41, pi/2/2^40 %we perform a check 
->ans = 7.143154683921678e-013 (OK) 1.428630936784336e-012 (too big, so it checks!)
\end{lstlisting}
\textbf{\underline{EFR 6.3 :}} (a) The condition \texttt{yn*ya>0} mathematically translates to yn and ya having the same 
sign, so this is (mathematically) equivalent to our condition \texttt{sign(yn)==sign(ya)}.
\\ 
(b) We are aiming for a root so at each iteration, \texttt{yn and ya} should be getting very small; thus their 
product \texttt{yn*ya} will be getting smaller much faster (e.g., if both are about 1e-175, then their product 
would be close to 1e-350 and this would underflow). Thus, with the modified loop we run the risk of a 
premature underflow destroying any further progress of the bisection method. 
\\
(c) Consider the function $f(x)=(x +.015)^{101}$ , which certainly has a (unique) root x = -0.015 and 
satisfies the requirements for using the bisection method. As soon as the interval containing xn gets 
to within 1 e-2 of the root, both y-values \texttt{yn} and \texttt{ya} would then be less than 1 e-200; so their product 
would be less than 1 e-400 and so would underflow to zero. This starts to occur already when n = 2 (xn= 0), and causes the modified if-branch to default to the else-if option—taking the left half subinterval 
as the new interval. From this point on, all approximations will be less than -0.5, making it impossible 
to reach the 0.001 accuracy goal.
\\
\\
\textbf{\underline{EFR 6.4:}} The distance from \texttt{x} to \texttt{e} is less than MATLAB's unit roundoff and the minimum gap 
between floating point numbers (see Example 5.4 and Exercise for the Reader 5.3). Thus MATLAB 
cannot distinguish between the two numbers \texttt{x} and \texttt{e}, and (in the notation of Chapter 5) we have fl(x) 
= fl(e)=e (since important numbers like e are built in to MATLAB as floating point numbers). As a 
result, when MATLAB evaluates ln(x), it really computes ln(fl(x))=ln(e) and so gets zero. 
\\
\\
\textbf{\underline{EFR 6.5:}} (a) If we try to work with quadratic polynomials (parabolas), cycling cannot occur unless 
the parabola did not touch the x-axis (this is easy to convince oneself of with a picture and not hard to 
show rigorously). If we allow polynomials that do not have roots, then an example with a quadratic 
polynomial is possible, as shown in the left-hand figure below. For a specific example, we could take $f(x)=x^{2}+1$. For cycling as in the picture, we would want $x_{1}=x_{0}$. Putting this into Newton's formula and solving (the resulting quadratic) gives $x_{0}=1 / \sqrt{3}$. One can easily nun a MATLAB program to see that this indeed produces the asserted cycling. To get an example of polynomial cycling with a polynomial that actually has a root we need to use at least a third-degree polynomial. Working with $f(x)=x^{3}-x=x(x-1)(x+1)$, which has the three (equally spaced) roots $x=0, \pm 1$ the graph suggests that we can have a period-two cycling, so we put $x_{1}=x_{0}$ into Newton's formula. The resulting cubic equation is easily solved exactly (it factors) or with the Symbolic Toolbox (see Appendix A) or approximately using Newton's method. The solution $x_{0}=1 / \sqrt{5}$ produces the periodtwo cycling shown in the right-hand figure below, as can be checked by running Newton's method.
\begin{figure}[H]
\includegraphics[width=0.9\linewidth]{42}
	\centering
	\label{pfig:ch13_42}
\end{figure}
(b) On the right is an illustration of a 
period-four cycle in Newton's method. 
An explicit such example is furnished 
by f(x) = $x^3- x - 3 $. The calculations 
would be, of course, more elaborate 
than those of part (a); it turns out that 
x0 should be taken to be a bit less than 
zero. (More precisely, about -0.007446; 
you may wish to run a couple of 
hundred iterations of Newton's method 
using this value for $x_0$ to observe the 
cycling.) By contemplating the picture, 
it becomes clear that this function has 
cycles of any order. Just move 
JC0 closer to the right toward the 
location where f'(x) has a root. 
\begin{figure}[H]
\includegraphics[width=0.9\linewidth]{43}
	\centering
	\label{pfig:ch13_43}
\end{figure}
\textbf{\underline{EFR 6.6 :}} (a) The M-file is boxed below:
\begin{lstlisting}[numbers=none]
function [root, yval,niter] = secant(varfun,x0, xl, tol, nmax) 
% input variables: varfun, x0, x1 tol, nmax 
% output variables: root, yval, niter 
% varfun = the string representing a mathematical function (built-in, 
% M-file, or inline) , x0 and x1 = the two (different) initial 
% approx. 
% The program will perform the Secant method to approximate a root of 
% varfun near x=x0 until either successive approximations differ by 
% less than tol or nmax iterations have been completed, whichever 
% comes first. If the tol and nmax variables are omitted default 
% values of eps (approx. 10^
(-16)) and 30 are used. 
% We assign the default tolerance and maximum number of iterations if 
% none are specified 
if nargin < 4 
tol=eps; nmax=50; 
end 


%we now initialize the iteration 
xn=x0;xnnext=x1; 


%finally we set up a loop to perform the approximations 
for n=1:nmax 
	yn=feval(varfun, xn); ynnext=feval(varfun, xnnext); 
	if ynnext === 0 
		fprintf('Exact root found\r') 
		root = xnnext; yval = 0; niter=n; 
		return 
	end 
	if yn == ynnext 
			error('horizontal secant encountered, Secant method failed, try 
changing x0, x1*) 
	end 
	newx=xnnext-feval(varfun, xnnext)*(xnnext-xn)(feval(varfun,xnnext)-feval(varfun, xn) ) ;
	if abs(newx-xnnext)<tol 
		fprintf('The secant method has converged\r') 
		root = newx; yval = feval(verfun, root); niter=n;
		return
	elseif n==nmax
		fprintf('Maximum number of iterations reached\r')
		root = newx; yval = feval(varfun, root);niter=nmax
		return
	end
	xn=xnnext; xnnext=newx'
end	
\end{lstlisting}
(b) The syntax of this M-file is very close to that of newton: 
\begin{lstlisting}[numbers=none,frame=none]
>> f=inline('x^4-2' ) ; [r y n] = secant(f , 2,1.5 ) 
->The secant method has converged, r = 1.18920711500272, 
y = -2.220446049250313e-016, n = 9 
>> abs(r-2^(l/4 ) ) ->ans = 0 
\end{lstlisting}
In conclusion, the secant method took nine iterations and the approximate root (r) had residual which 
was essentially zero (in floating point arithmetic) and coincided with the exact answer $\sqrt[4]{2}$ (in floating 
point arithmetic).
\\
\\
\textbf{\underline{EFR 6.7:}}mean "the highest order of convergence,* and AEC 
to mean "the asymptotic error constant." For each sequence, we determine these quantities if they 
exist:
\\
(i) HOC = 1; AEC = 1 (linear convergence), (ii) HOC = 1, AEC = 1/2 (linear convergence), (iii) 
HOC = 3/2, AEC = 1, (iv) HOC = 2, AEC = 1 (quadratic convergence), (v) HOC does not exist. 
There is hyperconvergence for every order a < 2, but the sequence does not have quadratic 
convergence
\\
\\
(b) The sequence $e_n$ - $e^{-3^n}$
 has HOC = 3. In general, $e_n = e^{-k^n}$
 has HOC = k whenever it is a positive 
number. 
\\
\\
\\
\textbf{\underline{EFR 6.8:}} Write $f(x) = (x-r)^Mh(x)$, where M is the order of the root (and so h(r)$\neq$0). 
Differentiating, we see that the function F(x)=f(x)/ f'(x) can be written as F(x) = (x - r)H(x), 
where H(x) = h(x) /[Mh(x) + (x- r)h'(x)]. Since H(r)=1/M $\neq$0, we see that x = r is a simple root 
of F(x). Since $F'(x)\equiv[(f'(x))^2-f(x)f''(x)]/(f'(x))^2$
, this method requires computing both 
f'(x) and f''(x). The roundoff errors can also get quite serious. For example, if we are converging to a simple root, then in the iterative computations of $F'(x_n)\equiv[(f'(x_n))^2-f(x_n)f''(x_n)]/(f'(x_n))^2$, 
$(f'(x_n))^2$ will be converging to a positive number, while $f(x_n)f''(x_n)$ will be converging to zero. 
Thus, when these two numbers are subtracted roundoff errors can be insidious. With higher-order roots 
each of $(f'(x_n))^2$
 and $f(x_n)f''(x_n)$ will be getting small very fast and can underflow to zero causing 
Newton's method to stop. If the root is a multiple root and the order is known not to be too high then 
this method performs reasonably well. If the order is known, however, the newtonmr method is a 
better choice. 
\\
\\
\line(2,0){\textwidth}\\
\textbf{CHAPTER 7: MATRICES AND LINEAR SYSTEMS }
\\
\\
\textbf{\underline{EFR 7.1:}} Abbreviate the matrices in (1) by DE = P and write P=[$p_{ij}$]. Now, by definition, 
$p_{ij}$ =(ith row of D)$\cdot$(jth column of E) = $d_i\cdot e_{ij}$(by diagonal form of D). But by the diagonal form of 
E, $e_{ij}$ (and hence also $p_{ij}$) is zero unless i = j , in which case $e_{ij}$ = $e_{i}$. Thus $p_{ij}= d_i\cdot e_{i} if i=j; 0, if i\neq j$ and this is a restatement of (1)
\begin{lstlisting}[numbers=none]
function A=randint(n,m,k)  
%generates an n by m matrix whose entries are random integers whose 
%absolute values do not exceed k 
A=zeros(n,m); 
for i=l:n 
	for j=l:m 
		x=(2*k+l)*rand-k; %produces a random real number in (-k,k+1)
		A(i,j)=floor(x);
	end 
end 
\end{lstlisting}
(b) In the random experiments below, we print out the matrices only in the first trial\\
\texttt{>> A=randint(6,6,9) ; B=randint(6,6,9) ; det(A*B), det(A*B)-det(A)*det(B) }
$$
\begin{array}{rrrrrrr}
\rightarrow A= & 9 & -5 & 2 & 0 & 7 & 5 \\
& -1 & -9 & 6 & -1 & 2 & 6 \\
& 8 & 5 & -6 & -2 & 8 & 8 \\
& -2 & 7 & -8 & -3 & 6 & -9 \\
& -7 & -6 & -6 & 2 & -4 & -6 \\
& -9 & 5 & -1 & 8 & -1 & -2
\end{array}
\begin{array}{rrrrrrr}
\rightarrow B= & 7 & 0 & -6 & 3 & 6 & -9 \\
& 3 & -2 & 6 & 0 & 4 & -1 \\
& -4 & -6 & -6 & 3 & -4 & 1 \\
& -7 & 4 & -2 & 7 & 7 & 2 \\
& 0 & 8 & 6 & 3 & 6 & 3 \\
& -3 & -4 & -3 & 1 & 4 & -4
\end{array}
$$
\texttt{->det(A*B)=~~~ -1.9436e+010 ~~~->ans= ~~~0}
\begin{lstlisting}[numbers=none,frame=none]
>> A=randint(6,6,9); B=randint(6,6,9); det(A*B), det(A*B)-
det(A)*det(B) 
->ans = 6.8755e+009, 0 
>> A=randint(6,6,9) ; B=randint(6,6,9) ; det(A*B), det(A*B)-
d e t (A) Me t (B) 
->ans = 8.6378e+010, 0 
The last output 0 in each of the three experiments indicates that formula (4) checks. 
(c) Here, because of their size, we do not print out any of the matrices. 
>> A=randint(16,16,9) ; B=randint(16,16,9) ; det(A*B), det(A*B)-
det(A)*det(B) 
->ans = -1.2268e+035, 18816e+021 
>> A=randint(16,16,9) ; B=randint(16,16,9) ; det(A*B), det(A*B)-
det(A)*det(B) 
->ans =1.4841 e+035, -6.9913e+021 
>> A=randint(16,16,9) ; B=randint(16,16,9) ; det(A*B), det(A*B)-
det(A)*det(B) 
->ans = 3.3287e+035, ans = 7.0835e+021
\end{lstlisting}
The results in these three experiments are deceptive. In each, it appears that the left and right sides of 
(4) differ by something of magnitude 1021. This discrepancy is entirely due to roundoff errors! 
Indeed, in each trial, the value of the determinant of AB was on the order of 1035. Since MATLAB's 
(double precision IEEE) floating point arithmetic works with only about 15 significant digits, the much 
larger (3 5-digit) numbers appearing on the left and right sides of (4) have about the last 20 digits turned 
into unreliable "noise." This is why the discrepancies are so large (the extra digit lost came from 
roundoff errors in the internal computations of the determinants and the right side of (4)). Note that in 
part (b), the determinants of the smaller matrices in question had only about 10 significant digits, well 
within MATLAB's working precision. 
\\
\\
\textbf{\underline{EFR 7.3:}} Using the f i 11 command as was done in the text to get the gray cat of Figure 7.3(b), you 
can get those other-colored cats by simply replacing the RGB vector for gray by the following: Orange 
->RGB = [1 .5 0], Brown -> RGB = [.5 .25 0], Purple -> RGB = [5 0 .5]. Since each of these 
colors can have varying shades, your answers may vary. Also, the naked eye may not be able to 
distinguish between colors arising from small perturbations of these vectors (say by .001 or even .005). 
The RGB vector representing MATLAB's cyan is RGB = [0 1 1].
\\
\\
\textbf{\underline{EFR 7.4:}} By property (10) (of linear transformations): $L\left(\alpha P_{1}\right)=\alpha L\left(P_{1}\right)$; if we put $\alpha=0$, we get that $L(\overrightarrow{0})=\overrightarrow{0}$ (where $\overrightarrow{0}$ is the zero vector). But a shift transformation $T_{V_{0}}(x, y)=(x, y)+V_{0}$ satisfies $T_{V_{0}}(\overrightarrow{0})=\overrightarrow{0}+V_{0}=V_{0}$. So the shift transformation $T_{V_{0}}$ being linear would force $V_{0}=\overrightarrow{0}$, which is not allowed in the definition of a shift transformation (since then $T_{V_{0}}$ would then just be the identity transformation).
\\
\\
\textbf{\underline{EFR 7.5:}} (a) As in the solution of Example 7.4, we individually multiply out the homogeneous coordinate transformation matrices (as per the instructions in the proof of Theorem 7.2) from right to left. The first transformation is the shift with vector $(1,0)$ with matrix: $T_{(1,0)} \sim\left[\begin{array}{lll}1 & 0 & 1 \\ 0 & 1 & 0 \\ 0 & 0 & 1\end{array}\right]=H_{1}$. After this we apply a scaling $S$ whose matrix is given by $S \sim\left[\begin{array}{lll}2 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1\end{array}\right]=H_{2}$. The homogeneous cooordinate matrix for the composition of these two transformations is: $M=H_{2} H_{1}=\left[\begin{array}{lll}2 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1\end{array}\right]\left[\begin{array}{lll}1 & 0 & 1 \\ 0 & 1 & 0 \\ 0 & 0 & 1\end{array}\right]=\left[\begin{array}{lll}2 & 0 & 2 \\ 0 & 1 & 0 \\ 0 & 0 & 1\end{array}\right]$. We assume (as in the text) that we have left in the graphics window the first (white) cat of Figure 7.3(a) and that the CAT matrix A is still in our 
workspace. The following commands will now produce the new "fat CAT":
\begin{lstlisting}[numbers=none,frame=none]
>> Hl=[l 0 1;0 1 0; 0 0 1] ; H2=[2 0 0;0 1 0;0 0 1] ; M=H2*H1 
>> AH=A; AH(3,:)=ones(1,10); %homogenize the CAT matrix 
>> AH1=M*AH; % homogenized "fat CAT" matrix 
>> hold on 
>> plot(AHl(l,:), AH1(2,:), 'r') 
>> axis ([-2 10 -3 6]) % set wider axes to accommodate "fat CAT" 
>> axis('equal') 
\end{lstlisting}
The resulting plot is shown in the left-hand figure that follows. 
(b) Each of the four cats needs to first get rotated by its specified angle about the same point (1.5,1.5). 
As in the solution to Example 7.4, these rotations can be accomplished by first shifting this point to (0, 
0) with the shift $T_{(1.5,1.5)}$, then performing the rotation, and finally shifting back with the inverse shift $T_{(1.5,1.5)}$. In homogeneous coordinates, the matrix representing this composition is (just like in the 
solution to Example 7.4): 
$$
M=\left[\begin{array}{ccc}
1 & 0 & 1.5 \\
0 & 1 & 1.5 \\
0 & 0 & 1
\end{array}\right]\left[\begin{array}{ccc}
\cos (\theta) & -\sin (\theta) & 0 \\
\sin (\theta) & \cos (\theta) & 0 \\
0 & 0 & 1
\end{array}\right]\left[\begin{array}{ccc}
1 & 0 & -1.5 \\
0 & 1 & -1.5 \\
0 & 0 & 1
\end{array}\right]
$$
After this rotation, each cat gets shifted in the specified direction with $T_{(\pm1,\pm1)}$. For the colors of our 
cats let's use the following: black (rgb = [0 0 0]), light gray (rgb = [.7 .7 .7]), dark gray (rgb = [.3 .3. 
.3]), and brown (rgb = [.5 .25 0]). The following commands will then plot those cats: 
\begin{lstlisting}[numbers=none,frame=none]
>> clf, hold on %prepare graphic window 
>> %upper left cat, theta = pi/6 (30 deg), shift vector = (-3, 3) 
>> c = cos (pi/6); s = sin (pi/6); 
>> M=[l 0 1.5;0 1 1.5;0 0 l]*[c -s 0;s c 0;0 0 1]*[1 0 -1.5;0 1 -
1.5;0 0 1]; 
>> AUL=[1 0 -3;0 1 3;0 0 1]*M*AH; 
>> fill(AUL(l,:), AUL(2,:), [0 0 0]) 
>> %upper right cat, theta = -pi/6 (-30 deg), shift vector = (3, 1) 
>> c = cos(-pi/6); s = sin(-pi/6); 
>> M=[l 0 1.5;0 1 1.5;0 0 l]*[c -s 0;s c 0;0 0 1]*[1 0 -1.5;0 1 -
1.5;0 0]; 
>> AUR=[1 0 1;0 1 1;0 0 1]*M*AH; 
>> filKAURU, :) , AUR(2,:)r [.7 .7 .7]) 
>> %lower left cat, theta = pi/4 (45 deg), shift vector = (-3, -3) 
>> c - cos(pi/4); s = sin(pi/4); 
>> M=[l 0 1.5;0 1 1.5;0 0 l]*[c -s 0;s c 0;0 0 1]*[1 0 -1.5;0 1 -
1.5;0 0 1]; 
>> ALL=[1 0 -3;0 1 -3;0 0 1]*M*AH; 
>> fill(ALL(l,:), ALL(2,:), [.3 .3 .3]) 
>> %lower right cat, theta = -pi/4 (-45 deg), shift vector = (3, -3) 
>> c = cos(-pi/4); s = sin (-pi/4); 
>> M=[l 0 1.5;0 1 1.5;0 0 l]*[c -s 0;s c 0;0 0 1]*[1 0 -1.5;0 1 -
1.5;0 0 1]; 
>> ALR=[1 0 3;0 1 -3;0 0 1]*M*AH; 
>> fill(ALR(l,:), ALR(2,:), [.5 .25 0]) 
>> axis('equal'), axis off %see graphic w/out distraction of axes
\end{lstlisting}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{44}
    \label{pfig:ch13_44}
\end{figure}
\textbf{\underline{EFR 7.6:}} (a) This first M-file is quite straightforward and is boxed below. 
\begin{lstlisting}[numbers=none]
function B=mkhom(A) 
B=A; 
[n m]=size(A); 
B(3,:)=ones(l,m); 
\end{lstlisting}
(b) This M-file is boxed below. 
\begin{lstlisting}[numbers=none]
function Rh=rot(Ah,xO,yO,theta) 
%viz. EFR 7.6; theta should be in radians 
%inputs a 3 by n matrix of homogeneous vertex coordinates, xy 
%coordinates of a point and an angle theta. Output is corresponding 
%matrix of vertices rotated by angle theta about (x0,y0). 

%first construct homogeneous coordinate matrix for shifting (x0,y0) 
to (0,0) 
SZ=[1 0 -x0;0 1 -y0; 0 0 1]; 
%next the rotation matrix at (0,0) 
R=[cos(theta) -sin (theta) 0; sin (theta) cos(theta) 0;0 0 1]; 
%finally the shift back to (x0,y0) 
SB=[1 0 x0;0 1 y0;0 0 1]; 
%now we can obtain the desired rotated vertices: 
Rh=SB*R*S2*Ah; 
\end{lstlisting}
\textbf{\underline{EFR 7.7:}} (a) The main transformation that we need in this movie is vertical scaling. To help make 
the code for this exercise more modular, we first create, as in part (b) of the last EFR, a separate M-file 
for vertical scaling: 
\begin{lstlisting}[numbers=none]
function Rh=vertscale(Ah,b,y0)
%inputs a 3 by n matrix of homogeneous vertex coordinates,a (pos.)
%numbers a for y- scales, and an optional arguments y0 

%for center of scaling.Output is homogeneous coor. matrix of scaled 
%vertices. default value of yO is 0. 

if nargin <3 
	y0=0; 
end 
%first construct homogeneous coordinate matrix for shifting y=y0 to 
%y=0 
SZ=[1 0 0;0 1 -yO; 0 0 1]; 
%next the scaling matrix at (0,0) 
S=[l 0 0; 0 b 0;0 0 1]; 
%finally the shift back to y=0 
SB=[1 0 x0;0 1 y0;0 0 1]; 
%now we can obtain the desired scaled vertices 
Rh=SB*S*SZ*Ah; 
\end{lstlisting}
Making use of the above M-file, the following script recreates the CAT movie of Example 7.4 using 
homogeneous coordinates:
\begin{lstlisting}[numbers=none]
%script for EFR 7.6(a): catmovieNol.m cat movie creation 
%Basic CAT movie, where cat closes and reopens its eyes. 
elf, counter=l; 

A=[0 0 .5 1 2 2.5 3 3 1.5 0; ... 
	0 3 4 3 3 4 3 0- 1 0]; %Basic CAT matrix 
Ah = mkhom(A); %use the M-file from EFR 7.6 

t=0:.02:2*pi; %creates time vector for parametric equations for eyes 
xL=l+.4*cos(t); y=2+.4*sin(t); %creates circle for left eye 
LE=mkhom([xL; y]); %homogeneous coordinates for left eye 
xR=2+.4*cos(t); y=2+.4*sin(t); %creates circle for right eye 
RE=mkhom([xR; y]); %homogeneous coordinates for right eye 
xL=l+.15*cos(t); y=2+.15*sin(t); %creates circle for left pupil 
LP=mkhom((xL; y]); %homogeneous coordinates for left pupil 
xR=2+.15*cos(t); y=2+.15*sin(t); %creates circle for right pupil 
RP=mkhom([xR; y]); %homogeneous coordinates for right pupil
 
for s=0:.2:2*pi 
	factor = (cos(s)+1)/2; 
	plot(A(l,:), A(2,:), 'k'), hold on 
	axis([-2 5 -3 6]), axis('equal') 
	LEtemp=vertscale(LE,factor,2); LPtemp=vertscale(LP,factor,2); 
	REtemp=vertscale(RE,factor,2); RPtemp=vertscale(RP,factor,2); 
	hold on 
	filKLEtempd, :) , LEtemp(2, :) , 'y') , fill(REtemp(1, :) , 
	REtemp(2,:),'y') 
	filKLPtempd, :) , LPtemp(2, :) , " k'), f ill (RPtemp (1, :) , 
	RPtemp(2,:),'k') 
	M(:, counter) = getframe; 
	hold off 
	counter=counter+l; 
end
\end{lstlisting} 
(b) As in part (a), the following script M-file will make use of two supplementary M-files, 
\texttt{AhR=reflx (Ah, x0)} and, \texttt{AhS=shif t (Ah, x0, y0)}, that perform horizontal reflections and 
shifts in homogeneous coordinates, respectively. The syntaxes of these M-files are explained in 
Exercises 5 and 6 of this section. Their codes can be written in a fashion similar to the code 
\texttt{vertscale }but for completeness are can be downloaded from the ftp site for this text (see the 
beginning of this appendix). They can be avoided by simply performing the homogeneous coordinate 
transformations directly, but at a cost of increasing the size of the M-file that we give: 
\begin{lstlisting}[numbers=none]
%coolcatmovie.m: script for making coolcat movie matrix M of EFR 7.7 
%act one: eyes shifting left/right 
t=0:.02:2*pi; counter=l; 
A=[0 0 .5 1 2 2.5 3 3 1.5 0; ... 
	0 3 4 3 3 4 3 0- 1 0] ; 
x=1+.4*cos(t); y=2+.4*sin(t);xp=1+.15*cos(t); yp=2+.15*sin(t); 
LE=[x;y]; LEh=mkhom(LE); LP=[xp;yp]; LPh=mkhom(LP); 
REh=reflx(LEh/ 1.5); RPh=reflx(LPh, 1.5); 
LW=[.3 -1; .2 -.8] ; LW2=[.25 -1.1;.25 -.6] ; %left whiskers 
LWh=mkhom(LW); LW2h=mkhom(LW2); 
RWh=reflx(LWh, 1.5); RW2h=reflx(LW2h, 1.5); %reflect left whiskers 
					%to get right ones 
M=[1 1.5 2;.25 -.25 .25]; Mh=mkhom(M); %matrix & homogenization of 
					%cats mouth 
Mhrefl=refly(Mh,-.25); %homogeneous coordinates for frown 
for n=0:(2*pi)/20:2*pi 
plot(A(1, :) , A(2, :) , 'k') 
axis([-2 5 -3 6]), axis('equal') 
hold on 
plot(LW(1,:), LW(2,:),'k'), plot(LW2 (1,:), LW2(2,:),'k') 
plot(RWh(1,:), RWh(2,:),'k') 
plot(RW2h(1,:), RW2h(2,:),'k') 
plot(Mhrefl(1,:), Mhrefl(2,:),'k') 
fillUEU,:), LE(2,:),'y'), fill(REh(1,:), REh (2, :) , ' y') 
LPshft=shift(LPh,-.25*sin(n),0); RPshft=shift(RPh,-.25*sin (n),0); 
fill(LPshft(l,:), LPshft(2, :) , *k') , fill(RPshft(1,:), 
RPshft(2,:),'k') 
Mov(:, counter)=getframe; 
hold off 
counter = counter +1; 
end 

%act two: eyes shifting up/down 
for n=0:(2*pi)/20:2*pi 
plot(A(l, :) , A(2, :) , 'k') 
axis([-2 5 -3 6]), axis('equal') 
hold on 
plot(LW(l,:), LW(2,:),'k'), plot(LW2(1,:), LW2 (2,:), 'k') 
plot(RWh(l,:), RWh(2,:),'k'
) 
plot(RW2h(l,:), RW2h(2,:),'k') 
plot(Mhrefl(1,:), Mhrefl(2,:),'k') 
fill(LE(l,:), LE(2f:),'y'), fill(REh(lf:), REh(2,:),'y') 
LPshft=shift(LPh,0,.25*sin(n)); RPshft=shift(RPh,0,.25*sin(n)); 
fill(LPshft(1,:), LPshft(2,:),'k'), fill(RPshft(1,:), 
RPshft(2,:),'k') 
Mov(:, counter)=getframe; 
hold off 
counter = counter +1; 
end 

%act three: whisker rotating up/down then smiling 
for n=0:(2*pi)/10:2*pi 
plot(A(1, :) , A(2, :) , 'k') 
axis ([-2 5 -3 6]), axis('equal') 
hold on 
fill(LE(1,:), LE(2,:),'y'),fill(LP(1,:), LP(2f:),'k') 
fill(REh( 1, :) , REh(2, :) , 'y') ,fill(RPh(l , :) , RPh (2, :) , ' k' ) 
LWrot=rot(LWh,.3,. 2 ,-pi/6*sin(n)); LW2rot=rot(LW2h, .25,.25, -
pi/6*sin(n)) ; 
RWrot=reflx(LWrot, 1.5); RW2rot=reflx(LW2rot, 1.5); 
plot(LWrot(l,:), LWrot(2,:), 'k'), plot(LW2rot(1,:),), LW2rot(2,:),'k') 
plot(RWrot(l,:), RWrot(2,:),'k'),plot(RW2rot(lf:)), RW2rot(2,:),'k') 
if n == 2*pi 
	plot(Mh(l,:), Mh(2,:),'k') 
	for n=l:10, L(:,n)=getframe; end 
	Mov(:, counter: (counter+9))=L; 
	break 
else 
	plot(Mhref1(1,:), Mhref1(2,:),'k')
	 
end 
Mov(:, counter)=getframe; 

hold off 
counter = counter +1; 
end 

%THE END 

\end{lstlisting}
\textbf{\underline{EFR 7.8:}} (a) Certainly the zeroth generation consists of $1=3^{0}$ triangles. Since the sidelength is one, and the triangle has each of its angles being $\pi / 3$, its altitude must be $\sin (\pi / 3)=\sqrt{3} / 2$. Thus, the area of the single zeroth generation triangle is $\sqrt{3} / 4$. Now, each time we pass to a new generation, each triangle splits into three (equilateral) triangles of half the length of the triangles of the current generation. Thus, by induction, the $n$th generation will have $3^{n}$ equilateral triangles of sidelength $1 / 2^{n}$ and hence each of these has area $(1 / 2) \cdot 1 / 2^{n} \cdot[\sqrt{3} / 2] / 2^{n}=\sqrt{3} / 4^{n+1}$.\\
(b) From part (a), the $n$th generation of the Sierpinski carpet consists of $3^{n}$ equilateral triangles each having area $\sqrt{3} / 4^{n+1}$. Hence the total area of this $m$ th generation is $\sqrt{3}(3 / 4)^{n} / 4$. Since this expression goes to zero as $n \rightarrow \infty$, and since the Sierpinski carpet is contained in each of the generation sets, it follows that the area of the Sierpinski carpet must be zero.
\\
\\
\textbf{\underline{EFR 7.9:}} (a) The $2 \times 2$ matrices representing dilations: $\left[\begin{array}{ll}s & 0 \\ 0 & s\end{array}\right](s>0)$, and reflections with respect to the $x$-axis: $\left[\begin{array}{cc}-1 & 0 \\ 0 & 1\end{array}\right]$ or $y$-axis: $\left[\begin{array}{cc}1 & 0 \\ 0 & -1\end{array}\right]$ are both diagonal matrices and thus commute with any other $2 \times 2$ matrices; i.e., if $D$ is any diagonal matrix and $A$ is any other $2 \times 2$ matrix, then $A D=D A$. In particular, these matrices commute with each other and with the matrix representing a rotation through the angle $\theta:\left[\begin{array}{rr}\cos \theta & -\sin \theta \\ \sin \theta & \cos \theta\end{array}\right]$. By composing rotations and reflections, we can obtain transformations that will reflect about any line passing through $(0,0)$. Once we throw in translations, we can reflect about any line in the plane and (as we have already seen) rotate with any angle about any point in the plane. By the definition of similitudes, we now see that compositions of these general transformations can produce the most general similitudes. Translating into homogeneous coordinates (using the proof of Theorem 7.2) we see that the matrix for such a composition can be expressed as $\left[\begin{array}{ccc}s \cos \theta & -s \sin \theta & x_{0} \\ \pm s \sin \theta & \pm s \cos \theta & y_{0} \\ 0 & 0 & 1\end{array}\right]$ where $s$ now is allowed to be any nonzero number. If the sign in the second
row is negative, we have a reflection: If $s>0$, it is a $y$-axis reflection; if $s<0$, it is an $x$-axis reflection.
(b) Let $T_{1}$ and $T_{2}$ be two similar triangles in the plane. Apply a dilation, if necessary, to $T_{1}$ so that it has the same sidelengths as $T_{2}$. Next, apply a shift transformation to $T_{1}$ so that a vertex gets shifted to a corresponding vertex of $T_{2}$, and then apply a rotation to $T_{1}$ about this vertex so that a side of $T_{1}$ 
transforms into a corresponding side of $T_{2}$ \\
At this point, either $T_{1}$ and $T_{2}$ are now the same triangle, 
or they are reflections of one another across the common 
side. A final reflection about this line, if necessary, will 
thus complete the transformation of $T_{1}$ into $T_{2}$ by a similitude. \\
(c) It is clear that dilations, rotations, and shifts are 
essential. For an example to see why reflection is needed, 
simply take $T_{1}$ to be any triangle with three different 
angles and $T_{2}$ to be its reflection about one of the edges (see figure). It is clearly not possible to 
transform one of these two triangles into the other using any combination of dilations, rotations, and 
shifts. 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.3\linewidth]{45}
    \label{pfig:ch13_45}
\end{figure}
\textbf{\underline{EFR 7.10:}}(a) There will be only one generation; here are the outputs that were asked for (in 
format short): 
$$
\begin{array}{cccc}
A \rightarrow & 0 & 1.0000 & 2.0000 \\
& 0 & 1.7321 & 0 \\
& 1.0000 & 1.0000 & 1.0000
\end{array}\\
\begin{array}{llcc}
\mathrm{A} 1 \rightarrow & 0 & 0.5000 & 1.0000 \\
& 0 & 0.8660 & 0 \\
& 1.0000 & 1.0000 & 1.0000
\end{array}
$$
$$
\begin{array}{cccc}
A \rightarrow & 1.0000 & 1.5000 & 2.0000 \\
& 0 & 0.8660 & 0 \\
& 1.0000 & 1.0000 & 1.0000
\end{array}\\
\begin{array}{llcc}
\mathrm{A} 1 \rightarrow & 0.5000 & 1.0000 & 1.5000 \\
& 0.8660 & 1.7321 & 0.8660 \\
& 1.0000 & 1.0000 & 1.0000
\end{array}
$$
$$
A 1\left(\left[\begin{array}{ll}
1 & 2
\end{array}\right], 2\right) \rightarrow \begin{array}{r}
0.5000 \\
0.8660
\end{array}
A 3\left(\left[\begin{array}{ll}
1 & 2
\end{array}\right], 2\right) \rightarrow \begin{array}{r}
1.5000 \\
0.8660
\end{array}
$$
(b) Since the program calls on itself and does so more than once (as long as \texttt{niter} is greater than 
zero), placing a \texttt{hold off} anywhere in the program will cause graphics created on previous runs to 
be lost, so such a feature could not be incorporated into the program. \\
(c) Since we want the program to call on itself iteratively with different vertex sets, we really need to 
allow vertex sets to be inputted. Different vertex inputs are possible, but in order for the program to 
function effectively, they should be vertices of a triangle to which the similitudes in the program 
correspond, (e.g., any of the triangles in any generation of the Sierpinski gasket). 
\\
\\
\textbf{\underline{EFR 7.11:}} (a)S2,Sl,S3,S2,S3,S2 \\
b) We list the sequence of float points in nonhomogeneous coordinates and in forma t short : 
[0.5000 0.8660], [0.2500 0.4330], [1.1250 0.2165], [1.0625 0.9743], [1.5313 0.4871], 
[1.2656 1.1096]. \\
(c) The program is designed to work for any triangle in the plane. The reader can check that the three 
similitudes are constructed in a way that uses midpoints of the triangle and the resulting diagram will 
look like that of Figure 7.15. 
\\
\\
\textbf{\underline{EFR 7.12:}} (a) As with \texttt{sgasket2} , the program sgasket 3 contructs future-generation triangles 
simply from the vertices and (computed) midpoints of the current-generation triangles. Thus, it can 
deal effectively with any triangle and produce Sierpinski-type fractal generations. \\
(b) For illustration purposes, the following trials were run on MATLAB's Version 5, so as to illustrate 
the flop count differences. The code is easily modified to work on newer versions of MATLAB by 
simply deleting the "\texttt{flops}" commands. 
\\
\\
\texttt{V1=[0 0]; V2=[l sqrt(3)]; V3=[2 0] ; '\%vertices of an equilateral 
triangle }\\
\texttt{test=[1 3 6 8 10]}
\begin{center}
\begin{tabular}{|l|l|}
\hline
\texttt{>> for i=l:5 }&\texttt{>> for i=l:5 }\\
\texttt{flops(0), tic, }&\texttt{flops(0), tic, }\\
\hline
\texttt{sgasketl(VI,V2,V3,test(i)), toe, 
flops 
}&\texttt{sgasketl(VI,V2,V3,test(i)), toe, 
flops 
}\\
\texttt{end}&\texttt{end}\\
\begin{lstlisting}[numbers=none,frame=none]
> (ngen =1) elapsedJime = 0.0600, 
ans =191 
	(ngen =3) elapsedjime = 0.2500, 
ans =2243 
	(ngen =6) elapsedjime = 0.8510, 
ans =62264 
	(ngen =8) elapsedjime = 7.2310, 
ans =560900 
	(ngen =10) elapsed time = 65.4640, 
ans =5048624 
\end{lstlisting}&\begin{lstlisting}[numbers=none,frame=none]
> (ngen =1) elapsedjime = 0.1400, 
ans = 45 
	(ngen =3) elapsedjime = 0.1310, 
ans =369 
	(ngen =6) elapsedjime = 0.7210, 
ans =9846 
	(ngen =8) elapsedjime = 6.2990, 
ans =88578 
	(ngen =10) elapsedjime = 46.7260, 
ans =797166 
\end{lstlisting}\\
\hline
\end{tabular}
\end{center}
We remind the reader that the times will vary, depending on the machine being used and other 
processes being run. The above tests were run on a rather slow machine, so the resulting times are 
longer than typical.
\\
\\
\textbf{\underline{EFR 7.13:}} The M-file is boxed below: 
\begin{lstlisting}[numbers=none]
function []=snow(n) 
S=[0 1 2 0;0 sqrt(3) 0 0]; 
index=l; 
while index <=n 
	len=length(S(1,:)); 
	for i = l:(len-1) 
delta=S(:,i+l)-S(:,i) ; 
perp=[0 -l;l 0]*delta; 
T(:,4*(i-1)+D=S(:,i); 
T(:,4*(i-1)+2)=S(:,i) + (l/3)*delta; 
T(:,4*(i-1)+3)=S(:,i) + (l/2)*delta-(1/3)*perp; 
T(:,4*(i-1)+4)=S(:,i) + (2/3)*delta; 
T(:,4*(i-1)+5)=S(:,i+1); 
end 
index=index+l; 
S=T; 
end 
plot (S(1,;),S(2,:)), axis('equal')
\end{lstlisting}
The outputs of snow (1), snow (2), and snow (6) are illustrated in Figures 7.17 and 7.18.
\\
\\
\textbf{\underline{EFR 7.14:}} For any pair of nonparallel lines represented by a two-dimensional linear system: $\left[\begin{array}{ll}a & b \\ c & d\end{array}\right]\left[\begin{array}{l}x \\ y\end{array}\right]=\left[\begin{array}{l}e \\ f\end{array}\right]$, the coefficient matrix will have nonzero determinant $\alpha=a d-b c$. The lines are also represented by the equivalent system $\left[\begin{array}{cc}a / \alpha & b / \alpha \\ c & d\end{array}\right]\left[\begin{array}{l}x \\ y\end{array}\right]=\left[\begin{array}{c}e / \alpha \\ f\end{array}\right]$, where now the coefficient matrix has determinant $(a / \alpha) d-(b / \alpha) c=1$. This change simply amounts to dividing the first equation by $\boldsymbol{\alpha}$.
\\
\\
\textbf{\underline{EFR 7.15:}} (a) As in the solution of Example 7.7, the interpolation equations $p(-2)=4, p(1)=3$, $p(2)=5$, and $p(5)=-22$ (where $p(x)=a x^{3}+b x^{2}+c x+d$ ) translate into the linear system: $\left[\begin{array}{cccc}-8 & 4 & -2 & 1 \\ 1 & 1 & 1 & 1 \\ 8 & 4 & 2 & 1 \\ 125 & 25 & 5 & 1\end{array}\right]\left[\begin{array}{l}a \\ b \\ c \\ d\end{array}\right]=\left[\begin{array}{c}4 \\ 3 \\ 5 \\ -22\end{array}\right]$. We solve this using left division, as in Method 1 of the solution of Example 7.7: 
\begin{lstlisting}[numbers=none,frame=none]
>> forma t lon g 
>> A=[-8 4 -2 1;1 1 1 1;8 4 2 1;125 25 5 1]; b=[4 3 5 -22 ]';
>> X =A\b 
->x=	0.47619047619048 (=a) 
			1.05952380952381 (= b) 
			2.15476190476190 (= c) 
			0.26190476190476 (=d) 
\end{lstlisting}
(b) As in part (a) and the solution of Example 7.7, we create the matrix A and vector b of the 
corresponding linear system: Ax = b. A loop will facilitate the construction of A: 
\begin{lstlisting}[numbers=none,frame=none]
>> xvals = -3:5; A = zeros(9) %initialize the 9 by 9 matrix A 
>> for i =1:length(xvals) 
A(i,:)=xvals(i). (8:-1:0); 
end 
>> b = [-14.5 -12 15.5 2 -22.5 -112 -224.5 318 3729.5]' 
\end{lstlisting}
We next go through each of the three methods of solving the linear system that were introduced in the 
solution of Example 7.7. We are working on an older and slower computer with MATLAB Version 5, 
so we will have flop counts, but the times will be slower than typical. The code is easily modified to 
work on the new version of MATLAB by simply deleting the flop s commands. We show the output 
for x only for Method 1 (in \texttt{format long}) as the answers with the other two methods are essentially 
the same
\\
\textbf{\underline{Method 1:}}
\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
\texttt{>> flops(0), tic,}&$->x$ &$-0.00000000000000$&$->elapsed\_time = 0.1300$\\
\texttt{x=A/b, toe, flops }&=&0.00000000000000&->ans = 1125 (flops)\\
&&0.50000000000000 &\\
&&-0.00000000000001 &\\
&& -6.00000000000000&\\
&&-1.99999999999996  &\\
&& 0.00000000000000&\\
&&-17.00000000000003  &\\
&&2.00000000000000 &\\
\hline
\end{tabular}
\end{center}
\textbf{\underline{Method 2:}}
\begin{center}
\begin{tabular}{|l|l|}
\hline
\texttt{>> flops (0), tic, x=inv(A)*b, 
}&\texttt{->elapsed\_time = 0.3010}\\
\texttt{toe, flops }&\texttt{->ans = 1935 (flops) }\\
\hline
\end{tabular}
\end{center}
\textbf{\underline{Method 3:}}
\begin{center}
\begin{tabular}{|l|l|}
\hline
\texttt{>> Ab=A; Ab(:,10)=b; 
}&\texttt{->elapsed\_time = 3.3150}\\
\texttt{>> flops(0), tic, rref(Ab), toe, 
 }&\texttt{->ans = 2175 (flops) }\\
 flops&\\
\hline
\end{tabular}
\end{center}
The size of this problem is small enough so that all three methods produce essentially the same vector 
x. The computation times and flop counts begin to demonstrate the relative efficiency of the three 
methods. Reading off the coefficients of the polynomial in order (from x), we get (after taking into 
account machine precision and rounding): a = b = d = g = 0, c = 1/2, e = -6, f = -2, h = -17, and k = 2, so that the interpolating polynomial is given by $p(x) =\frac{1}{2}x^6-6x^4-2x^3-17x+2$ It is readily checked that this function satisfies all of the interpolation requirements. 
\\
\\
\textbf{\underline{EFR 7.16:}} As in Example 7.8, for a fixed n, if we let x denote the exact solution, we then have $b_n = H_nx=c(n)(1\frac{1}{2}\frac{1}{3}\cdots\frac{1}{n-1}\frac{1}{n})'$ In order for bn to have all integer coordinates, we need to have c(n) be a multiple of each of the integers 1, 2, 3, ..., n. The smallest such c(n) is thus the least 
common multiple of these numbers. We can use MATLAB's \texttt{lcm (a, b)} to find the 1cm of any set of 
integers with a loop. Here is how it would work to find c(n) = lcm(l,2,..., n): \\
\texttt{>> cn=l \%initialize }\\
\texttt{>> for k=l:n, c(n)=lcm(cn, k), end}\\
The remaining code for constructing the exact solution x, the numerical solution of Method 1, 
\texttt{x\_meth1}, and the numerical solution of Method 2 \texttt{x\_meth2} are just as in Example 7.9. The flop s 
commands in these codes should be omitted if you are using Version 6 or later. Also, since these 
computations were run on an older machine, the elapsed times will be larger than what is typical (but their ratios should be reasonably consistent). The loop below will give us the data we need for both 
parts (a) and (b):
\begin{lstlisting}
>> for n=20:10:3 0 
cn=l; %initialize 
for k=l:nf c(n)=lcm(cn, k); end 
x = zeros(n,l); x(l)=cn; 
bn = hilb(n)*x; 
flops(0), tic, x_methl=hilb(n)\bn; toc, flops 
flops(0), tic, x_meth2=inv(hilb(n))*bn; toc, flops 
Pct_err_methl=100*max(abs(x-x_methl))/cn, 
Pct_err_meth2=100*max(abs(x-x_meth2))/cn 
end
\end{lstlisting}
Along with the expected output, we also got some warnings from MATLAB that the matrix is either 
singular or poorly conditioned (to be expected). The output is summarized in the following table: 
\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{46}
    \label{pfig:ch13_46}
\end{figure}
\textbf{Note:} The errors may vary depending on which version of MATLAB you are using. 
(c) The errors with Method 1 turn out to be undetectable as n runs well over 1000. The computation 
times become more of a problem than the errors. MATLAB's "left divide" is based on Gaussian 
elimination with partial pivoting. After we study this algorithm in the next section, the effectiveness of 
this algorithm on the problem at hand will become clear. 
\\
\\
\textbf{\underline{EFR 7.17:}}(a)\&(b): The first two are in reduced row echelon form. The corresponding general 
solutions are as follows: (for $M_1$): $x_1=3, x_2 = 2; (for M2 ): x_1=2s-3t-2, x_2=s, x_3=5t+1, 
x4=t$, where s and t are any real numbers
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\texttt{>>rref([ 1  3  2  0  3;2  6  2 -8  4])}&->ans&1  3  0 -8  1\\
&&0  0  1  4 1 \\
\hline
\end{tabular}
\end{center}
(c) From the outputted reduced row echelon form, we obtain the following general solution of the first 
system: $x_1 = 1 - 3s + 8f, x_2 = s, x_3 = 1 - 4t, x_4 = t$ , where s and t are any real numbers. Because of 
the arithmetic nature of the algorithm being used (as we will learn in the next section), it is often 
advantageous to work in \texttt{format} ra t in cases where the linear system being solved is not too large 
and has integer or fraction coefficients. We do this for the second system:
\\
\\
\textbf{\underline{EFR 7,18:}} (a) The algorithm for forward substitution:$x_{1}=b_{1} / a_{11}, \quad x_{j}=\left(b_{j}-\sum_{k=1}^{j-1} a_{j k} x_{k}\right) / a_{jj}$(the first formula is redundant since the latter includes it as a special case) is easily translated into the 
following MATLAB code (cf. Program 7.4):
\begin{lstlisting}[numbers=none]
function x=fwdsubst(L,b) 
%Solves the lower triangular system Lx=b by forward substitution 
%Inputs: L = lower triangular matrix, b = column vector of same 
%dimension 
%Output: x = column vector (solution) 
[n m]=size(L); 
x(l)=b(l)/L(l,l); 
\end{lstlisting}
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\begin{lstlisting}[numbers=none,frame=none]
 for j=2: n 
x(j) = (b(j)-L(j,l:j-l)*x(l:j-l)')/L(j,j) ; 
end 
x=x'; 
\end{lstlisting}&&\\
\hline
\texttt{>>L[1 2 3 4;0 2 3 4;0 0 3 4;0 0 0 4]';}&->ans&4\\
\texttt{>> b=[4 3 2 1]'; }&&-5/2\\
\texttt{>> format rat}&&-5/6 \\
\texttt{>> fwdsubst(L,b)}&&-5/12\\
\hline
\end{tabular}
\end{center}
\textbf{\underline{EFR 7.19}} : The two M-files are boxed below:
\begin{center}
\begin{tabular}{|l|}
\hline
\begin{lstlisting}[numbers=none,frame=none]
function B-rowmult(A,i,c) 
% Inputs: A = any matrix, i = any row index, c = any nonzero number 
% Output: B = matrix resulting from A by replacing row i by this row 
% multiplied by c. 
[m,n]=size(A); 
if i<l|i>m 
	error(*Invalid index') 
end 
B=A; 
B(i, :)=c*A(i, :); 
\end{lstlisting}\\
\hline
\begin{lstlisting}[numbers=none,frame=none]
 function B-rowcomb(A,i,j,c) 
% Inputs: A = any matrix, i, j - row indices, c = a number 
% Output: B = matrix resulting from A by adding to row j the number 
% c times row i. 
[m,n]=size(A); 
if i<l|i>m|j<l|j>m 
	error('Invalid index') 
end 
if i-j 
	error('Invalid row operation') 
end 
B=A; 
B(j, :)=c*A(i, :)+A(j, :) ; 
\end{lstlisting}\\
\hline
\end{tabular}
\end{center}
\textbf{\underline{EFR 7.20:}} If we use \texttt{gausslim} to solve the system of Example 7.13, we get the correct answer 
(with lightning speed) with a flop count of 104 (if you have access to Version 5). In the table below, 
we give the corresponding data for the linear systems of parts (a) and (b) of EFR 7.16 (compare with 
the table in the solution ofthat exercise):
\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{47}
    \label{pfig:ch13_47}
\end{figure} 
We observe that the time is detectable, although it was not when we used MATLAB's "left divide". 
Similarly, if we solve the larger systems of part (c) of EFR 7.16, we still get 0\% errors for large values 
of n, but the times needed for \texttt{gausseiim} to do the job are much greater than they were for "left 
divide''. MATLAB's "left divide'' is perhaps its most important program. It is based on Gaussian 
elimination, but also relies on numerous other results and techniques from numerical linear algebra. A 
full description of "left divide'' would be beyond the scope of this book; for the requisite mathematics, 
we refer to [GoVL-83]. 
\\
\\
\textbf{\underline{EFR 7.21:}} Working just as in Example 7.14, but this time in rounded floating point arithmetic, the answers are as follows:\\
(a) $x_1 = 1, x_2 =.999 and (b) x_1 = .001, x2 = .999.$
\\
\\
\textbf{\underline{EFR 7.22:}}  Looking at (28) we see that solving for $x_j$ takes: 1 division + (n -j) multiplications + 
(n -j - 1) additions (if j < n) + 1 subtraction (if/ < n). 
Summing from j = n to y = 1, we deduce that: \\
\\
Total multiplications/divisions $=\sum_{j=1}^{n} n-j+1=n^{2}+n-n(n+1) / 2=\left(n^{2}+n\right) / 2$,
\\
\\
Total additions/subtractions $=\sum_{j=1}^{n-1}[n-j-1+1]=\sum_{j=1}^{n-1}[n-j]=\sum_{j=1}^{n-1} j=\left(n^{2}-n\right) / 2$.\\
\\
Adding gives the grand total of $n_2$ flops, as asserted.
\\
\\
\textbf{\underline{EFR 7.23:}} Here we let $x=\left(x_{1}, x_{2}, \cdots, x_{n}\right)$ denote any $n$-dimensional vector and $\|x\|$ denote its max norm $\|x\|_{\infty}=\max \left\{\left|x_{1}\right|,\left|x_{2}\right|, \cdots,\left|x_{n}\right|\right\}$. The first norm axiom $(36 \mathrm{~A})$ is clear from the definition of the max norm. The second axiom (36B) is also immediate: $\|c x\|=\max \left\{\left|c x_{1}\right|,\left|c x_{2}\right|, \cdots,\left|c x_{n}\right|\right\}$ $=|c| \max \left\{\left|x_{1}\right|,\left|x_{2}\right|, \cdots,\left|x_{n}\right|\right\}=|c|\|x\|$. Finally, the triangle inequality (36C) for the max norm readily follows from the ordinary triangle inequality for real numbers:
$$
\begin{aligned}
\|x+y\| &=\max \left\{\left|x_{1}+y_{1}\right|,\left|x_{2}+y_{2}\right|, \cdots,\left|x_{n}+y_{n}\right|\right\} \\
&=\max \left\{\left|x_{1}\right|+\left|y_{1}\right|,\left|x_{2}\right|+\left|y_{2}\right|, \cdots,\left|x_{n}\right|+\left|y_{n}\right|\right\} \leq\|x\|+\|y\|
\end{aligned}
$$
EFR 7.24: (a) We may assume that $B \neq 0$, since otherwise both sides of the inequality are zero. Using definition (38), we compute:
$$
\begin{aligned}
\|A B\|=\max \left\{\frac{\|A B x\|}{\|x\|}, x \neq 0 \text { (vector) }\right\}=\max &\left\{\frac{\|A(B x)\|}{\|x\|} \cdot \frac{\|B x\|}{\|B x\|}, B x \neq 0 \text { (vector) }\right\} \\
&=\max \left\{\frac{\|A(B x)}{\|B x\|} \cdot \frac{\|Bx\|}{\|x\|}, B x \text { (vector) }\right\} \leq\|A\| B \|
\end{aligned}
$$
(b) First note that for any vector $x \neq 0$, the vector $y=A x$ is also nonzero (since $A$ is nonsingular), and $A^{-1} y=x$. Using this notation along with definition (38), we obtain:
$$
\begin{aligned}
\left\|A^{-1}\right\|=\max \left\{\frac{\left\|A^{-1} y\right\|}{\|y\|},\right.&y \neq 0(\text { vector })\}=\left(\min \left\{\frac{\|y\|}{\left\|A^{-1} y\right\|}, y \neq 0(\text { vector })\right\}\right)^{-1} \\
=&\left.\underset{y=A x}{ } \min \left\{\frac{\|A x\|}{\|x\|}, x \neq 0(\text { vector })\right\}\right)^{-1} .
\end{aligned}
$$
\textbf{\underline{EFR 7.25:}} (a) We first store the matrix A with the following loop, and then ask MATLAB for its condition number:
\begin{lstlisting}[numbers=none,frame=none]
>> norm(z , in f )->ans =8.7156e+004 
At first glance, the accuracy looks quite decent. The warnings, however, remove any guarantees that 
Theorem 7.7 would otherwise allow us to have. 
(d) >> z2=inv(A)*b; r2=b-A*z2; -> Warning: Matrix is close to singular or badly 
scaled. Results may be inaccurate. RCOND = 8.296438e-017. 
>> errest2=cl*nor m (r2 , inf) /norm (A, inf) ->errest2 = 2.3494 
(e) As in Example 7.23, we solve the system symbolically and then get the norms that we asked for: 
>> S=sym(A); x=S\b ; x=double(x); 
>> norm (x-z , inf) ->ans =3.0347e-005 
>> norm (x-z2 , inf) ->ans =3.0347e-005 
\end{lstlisting}
Thus, despite the warning we received, the numerical results are much more accurate than the estimates 
of Theorem 7.7 had indicated. 
\\
\\
\textbf{\underline{EFR 7.26:}} (a) Since $\lambda I$ - A is a triangular matrix, Proposition 7.3 tells us that the determinant 
$p_A(X)$ = det($\lambda I - A$) is simply the product of the diagonal entries: $p_A(\lambda) = (\lambda - 2)^2(\Lambda -1)^2$. Thus A 
has two eigenvalues: $\lambda=1,2$ , each having algebraic multiplicity 2. \\
(b)\texttt{>> [V, D] = eig([ 2 1 0 0;0 2 0 0;0 0 1 0;0 0 0 1]) }\\
\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
->V=&1.0000  -1.0000  0  0&->D=&2 0 0 0\\
&0  0.0000  0  0&&0 2 0 0\\
&0  0  1.0000  0&&0 0 1 0\\
&0  0  0  1.0000&&0 0 0 1\\
\hline
\end{tabular}
\end{center}
From the output of \texttt{eig} , we see that the eigenvalue $\lambda$ = 1 has two linearly independent eigenvectors: 
[0 0 1 0]' and [0 0 0 1]', and so has geometric multiplicity 2, while the eigenvalue $\lambda$ = 2 has only one 
independent eigenvector [2 0 0 0]', and so has geometric multiplicity 1. \\
(c) From the way in which part (a) was done, we see that the eigenvalues of any triangular matrix are 
simply the diagonal entries (with repetitions indicating algebraic multiplicities). 
\\
\\
\textbf{\underline{EFR 7.27:}} (a) The M-file is boxed below:
\begin{lstlisting}[numbers=none]
functio n [x, k, cliff] = jacobi (A,b, x0, tol , kmax) 
% performs the Jacob i iteration on the linear system Ax=b. 
% Inputs: the coefficient matrix 'A' , th einhomogeneity (column) 
% vecto r 'b' , the seed (column) vector 'x0' for the iteration 
% process, the tolerance 'tol which will causethe iteration to stop 
% if the 2-norms of differences of successive iterates becomes 
% smaller than 'tol' , and 'kmax which is the maximum number of 
% iterations to perform. 
% Outputs: the final iterate 'x' , the number of iteration sperformed 
% 'k' , and a vector *diff which records the 2-norms of successive 
% differences of iterates. 
% If any of the last three input variables are not specified , default 
% value s of x0= zero column vector , tol=1e-10 and kmax=100 ar e used .
 
%assign defaul t inpu t variables , a s necessar y 
if nargin<3 , x0=zeros(size(b)) ; end 
if nargin<4 , tol=1e-10 ; end 
if nargin<5 , kmax=100; end 
if min(abs(diag(A)))<eps 
	error('Coefficient matrix has zero diagonal entries, iteration 
cannot be performed.\r' ) 
end 

[n m]=size(A); 
xold=x0 ; 
k=l ; diff=[] ; 

while k<=kmax
	xnew=b; 
	for i=l:n 
		for j=l:n 
			if j~=i 
				xnew(i)=xnew(i)-A(i,j)*xold(j); 
			end 
		end 
		xnew(i)=xnew(i)/A(i,i); 
	end 
	diff(k)=norm(xnew-xold,2); 
	if diff(k)<tol 
	 fprintf('Jacobi iteration has converged in %d iterations.\r', k) 
			x=xnew; 
			return 
	end 
	k=k+l; xold=xnew; 
end 
fprintf('Jacobi iteration failed to converge.\r') 
x=xnew; 
\end{lstlisting}
\begin{lstlisting}[numbers=none]
(b)>> A=[3 1 -1;4 -10 1;2 1 5); b=[-3 28 20]' ; 
>> [x, k, diff] = jacobi(A,b,[0 0 0]',le-6) ; 
-> Jacobi iteration has converged in 26 iterations. 
>> norm(x-[l -2 4]' , 2)->ans = 3.9913e-007 (Error is in agreement with Example 7.26.) 
>> di f f (2 6)->ans = 8.9241e-007 (Last successive difference is in agreement with Example 7.26.) 
>> [x, k, diff] = jacobi(A,b,[0 0 0]') ; 
->Jacobi iteration has converged in 41 iterations. (With default error tolerance 1e-10) 
\end{lstlisting}
\textbf{\underline{EFR 7.28:}} (a) The M-file is boxed below:
\begin{lstlisting}[numbers=none]
function [x, k, diff] = sorit(A,b,omega, x0,tol,kmax) 
% performs the SOR iteration on the linear system Ax=b. 
% Inputs: the coefficient matrix 'A', the inhomogeneity (column) 
% vector 'b', the relaxation paramter 'omega', the seed (column) 
% 'x0 for the iteration process, the tolerance 'tol vector which 
% will cause the iteration to stop if the 2-norms of successive 
% iterates becomes smaller than 'tol*, and 'kmax which is the 
% maximum number of iterations to perform. 
% Outputs: the final iterate 'x', the number of iterations performed 
% 'k', and a vector 'diff which records the 2-norms of successive 
% differences of iterates. 
% If any of the last three input variables are not specified, default 
% values of x0= zero column vector, tol=le-10 and kmax=100 are used. 

%assign default input variables, as necessary 
if nargin<4, x0=zeros(size(b)); end 
if nargin<5, tol=le-10; end 
if nargin<6, kmax=100; end 

if min(abs(diag(A)))<eps 
	error('Coefficient matrix has zero diagonal entries, iteration 
cannot be performed.\r') 
end 

[n m]=size(A); 
xold=x0; 
k=l; diff=[]; 

while k<=kmax 
	xnew~b; 
	for i=1:n  
		for j=l:n
			if j<i 
				xnew(i)=xnew(i)-A(i,j)*xnew(j); 
			elseif j>i 
				xnew(i)=xnew(i)-A(i,j)*xold(j) ; 
			end 
		end 
		xnew(i)=xnew(i)/A(i, i); 
		xnew(i)=omega*xnew(i) + (1-omega)*xold(i); 
	end
	diff(k)=norm(xnew-xold,2) ; 
	if diff(k)<tol 
		fprintf('SOR iteration has converged in %diterations\r,k) 
			x=xnew; 
			return 
	end
	k=k+l; xold=xnew; 
end 
fprintf(*SOR iteration failed to converge.\r'
) 
x=xnew; 
\end{lstlisting}
(b) We set the relaxation parameter equal to 1 for SOR to reduce to Gauss-Seidel: 
\begin{lstlisting}[numbers=none,frame=none]
>> A=[3 1 -1/ 4 -10 1;2 1 5) ; b=[- 3 28 20]' ; 
>>[x, k, diff ] = sorit(A,b,l , [0 0 0] \le-6 ) 
-> SOR iteration has converged in 17 iterations 
>> norm(x-[l -2 4]',2 ) 
->ans =1.4177e-007 (This agrees exactly with the error estimate of Example 7.27.) 
>> (x, k, diff ] = sorit(A,b,.9,[ 0 0 0]',le-6) ; 
->	SOR iteration has converged in 9 iterations
\end{lstlisting}
\textbf{\underline{EFR 7.29:}} Below is the complete code needed to recreate Figure 7.41. After running this code, 
follow the instructions of the exercise to create the key.
\begin{lstlisting}[numbers=none,frame=none]
>> jerr-1 ; n=1 ; 
>> while jerr>=1e-6 
x=jacobi(A,b,[0 0 0]'1e-7,n); 
Jerr(n)=norm(x-(1 -2 4]', 2); jerr=Jerr(n); n=n + 1; 
end 
>> semilogy(1:n-1,Jerr,'bo-') 
>> hold on 

>> gserr=1; n-1; 
>> while gserr>=1e-6 
x=gaussseidel(A,b,[0 0 0]',1e-7,n); 
GSerr(n)=norm(x-[1 -2 4]',2); gserr=GSerr(n); n=n+1; 
end 
>> semilogy(1:n-1,GSerr,'gp-') 

>> sorerr=1; n=1; 
>> while sorerr>=le-6 
x=sorit(A,b,0.9, [0 0 0]',1e-1,n); 
SORerr(n)=norm(x-[1 -2 4]',2); sorerr=SORerr(n); n=n+1; 
end 
>> semilogy(1:n-1,SORerr, 'rx-') 
>> xlabel('Number of iterations'), ylabel('Error') 
\end{lstlisting} 
\textbf{\underline{EFR 7.30:}} (a) By writing out the matrix multiplication and observing repeated patterns we arrive 
at the following formula for the vector b$\equiv$Ax of size 2500x1. Introduce first the following two 
1x50 vectors b' $\bar{b}$: 
$$
\begin{aligned}
&b^{\prime}=\left[\begin{array}{lllllllll}
1 & 4 & -1 & 4 & -1 & \cdots & 4 & -1 & 5
\end{array}\right] \text {, }\\
&\bar{b}=\left[\begin{array}{lllllllll}
0 & 2 & -2 & 2 & -2 & \cdots & 2 & -2 & 3
\end{array}\right] \text {. }\\
\end{aligned}
$$
 In terms of copies of these vectors, we can express b as the transpose of the following vector: 
 $$
 b = [b' ~\tilde{b}~ \tilde{b}~ \cdots ~\tilde{b} ~\tilde{b }~b'].
 $$
 (b) We need first to store the matrix A . Because of its special form, this can be expeditiously 
accomplished using some loops and the \texttt{diag} command as follows:
\begin{lstlisting}[numbers=none,frame=none]
>> x=ones(2500,1); x(2:2:2500,1)=2 ; 
>> tic , A=4*eye(2500); toc 
->elapsed_time =0.6090 
>> vl=-1*ones (49,1); v1=[v1;0]; %seed vector for sub/super diagonals 
tic, secdiag=v1; 
for i=l:49 
if i<49 
secdiag=[secdiag;v1]; 
else 
secdiag=[secdiag;v1(1:49)]; 
end 
end, toc 
->elapsed_time =0.1250 
>> tic, A=A+diag(secdiag,-1)+diag(secdiag,-1)-diag(ones(2450,1),50)-diag(ones(2450,1),-50); toc 
->elapsed_time =12.7660 
>> tic, bslow=A*x; toc 
->elapsed_time = 0.2340
\end{lstlisting}
(c): To see the general concepts behind the following code, read Lemma 7.16 (and the notes that 
precede it). 
\begin{lstlisting}[numbers=none,frame=none]
tic , bfast=4*x+[secdiag;0].*[x(2:2500);0]+... 
[0;secdiag].*[0 ; x (1:2499)]-[x(51:2500) ; zeros(50,1)]-.. . 
[zero s (50,1) ; x(l:2450)] ; toc ->elapsed_time = 0.0310
\end{lstlisting}
(d) If we take N = 100, the size of A will be 10,000 $\times$ 10,000, and this is too large for MATLAB to 
store directly, so Part (b) cannot be done. Part (a) can be done in a similar fashion to how it was done 
when N was 50. The method of part (c), however, still works in about 1/100th of a second. Here is the 
corresponding code:
\begin{lstlisting}[numbers=none,frame=none]
>>x=one s (10000,1) ; x (2 :2 :10000,1 ) =2; 
>>vl=-l*ones(99,1); vl=[vl;0); %seed vector for sub/super diagonals 
>>tic, secdiag=vl; for i=l:99, if i<99, secdiag=[secdiag;vl]; 
else, secdiag=[secdiag;vl(1:99)]; end 
end, toc 
>> tic , bfast=4*x+[secdiag;0].*[x(2:10000);0 ] +... 
[0;secdiag ] .* [0; x (1:9999)]-[ x (101:10000); zeros(100,1)]-... 
[zeros (100, 1) ; x (1:9900)] ; toc ->elapsed_time = 0.0100
\end{lstlisting}
\textbf{\underline{EFR 7.31:}} (a) The M-file is boxed below: 
\begin{lstlisting}[numbers=none]
function [x, k, diff] = sorsparsediag(diags, inds,b,omega, 
x0, tol,kmax) 
% performs the SOR iteration on the linear system Ax=b in cases where 
% the n by n coefficient matrix A has entries only on a sparse set of 
% diagonals. 
% Inputs: The input variables are 'diags', an n by J matrix where 
% eachcolumn consists of the entries of one of A's diagonals. The 
% first column of diags is the main diagonal of A (even if all zeros) 
% and 'inds' , a 1 by n vector of the corresponding set of indices 
% for the diagonals (index zero corresponds to the main diagonal). 
% the relaxation paramter 'omega', the seed (column) vector 'x0' for 
% the iteration process, the tolerance 'tol which will cause the 
% iteration to stop if the infinity-norms of successive iterates 
% become smaller than 'tol', and 'kmax which is the maximum number
% of iterations to perform. 
% Outputs: the final iterate 'x', the number of iterations performed 
% 'k', and a vector 'diff which records the 2-norms of successive 
% differences of iterates. 
% If any of the last three input variables are not specified, default 
% values of x0= zero column vector, tol=1e-10 and kmax=1000 are used. 

%assign default input variables, as necessary 
if nargin<5, xO=zeros(size(b)); end 
if nargin<6, tol=1e-10; end 
if nargin<7, kmax=1000; end 

if min(abs(diags(:,1)))<eps 
	error('Coefficient matrix has zero diagonal entries, iteration 
cannot be performed.\r') 
end 

[n D]=size(diags); 
xold=x0; 
k=l; diff=[]; 

while k<=kmax 
	xnew=b; 
	for i=l:n 
		for d=2:D %run thru non-main diagonals and scan for entries that effect xnew(i) 
			ind=inds(d); 
			if ind<0&i>-ind %diagonal below main and j<i case 
				aij=diags(i+ind,d); 
				xnew(i)=xnew(i)-aij*xnew(i+ind); 
			elseif ind>0&i<=n-ind %diagonal above main and j>i case 
				aij=diags(i,d); 
				xnew(i)=xnew(i)-aij*xold(i + ind) ; 
			end 
		end 
		xnew(i)=xnew(i)/diags(i, 1) ; 
		xnew(i)=omega*xnew(i)+(1-omega)*xold(i); 
	end 
	diff(k)=norm(xnew-xold, inf) ; 
	if diff(k)<tol 
		fprintf('SOR iteration has converged in %d iterations\r', k) 
			x=xnew; 
			return 
	end 
	k=k+l; xold=xnew; 
end 
fprintf('SOR iteration failed to converge. \r') 
x=xnew; 
\end{lstlisting}
(b) In order to use this program, we must create the input matrix diag s from the nontrivial diagonals 
of the matrix A. The needed vectors were constructed in the solution of EFR 7.30(b); we reproduce the 
relevant code: 
\begin{lstlisting}[numbers=none,frame=none]
>> vl=-l*ones(49,1); vl=[vl;0]; %seed vector for sub/super diagonals 
secdiag=v1; 
for i=l:49 
if i<49 
secdiag=[secdiag;v1]; 
else 
secdiag=[secdiag;vl(1:4 9)]; 
end 
end
\end{lstlisting}
We now construct the columns of diag s to be the nontrivial diagonals of A taken in the order of the 
vector: 
\begin{lstlisting}[numbers=none,frame=none]
>> ind s =[ 0 1- 1 50 -50] 
>> diag s = zeros(2500,5) ; 
>> diags(:,1)=4 ; diags(1:2499,[ 2 3])=[secdiag secdiag] ; 
>> diags(l:2450 , [4 5])= [-ones(2450,1 ) -ones(2450,1)] ;
\end{lstlisting}
We will also need the vectors x and b; we assume they have been obtained (and entered in the 
workspace) in one of the ways shown in the solution of EFR 7.30. We now apply our new SOR 
program on this problem using the default tolerance: 
\begin{lstlisting}[numbers=none,frame=none]
>> tic 
>> [xsor, k, diff]=sorsparsediag(diags, inds,b,2/(1+sin(pi/51)), 
zeros(size(b))); toc 
->SOR iteration has converged in 222 iterations 
->elapsed_time = 0.6510 
>> max(abs(xsor-x)) 
->ans = 6.1213e-010 
\end{lstlisting}

%Kl


\noindent\hrulefill\\
\textbf{CHAPER 8: INTRODUCTION TO DIFFERENTIAL EQUATIONS}\\
\textbf{\texttt{EFR 8.1:}}
In general, if a vector x is constructed with the MATLAB command \begin{math}x=a : h: b\end{math}, where a 
< b and h > 0 is the step size, then we can write: \begin{math}x (n) = a + (n - 1)h\end{math}. In the example on hand, $a = 0$, 
and $h = 0.01$, so x \begin{math}(n) = (n - 1)0.01\end{math} which gives $n = 100*x(n)+l$. Therefore, to use MATLAB to find.y 
when $x = 3$, we should use the index \begin{math}n = 100\cdot3 + 1 = 301\end{math} and enter:
>> $y(301) \overrightarrow{ans} = 1.7736$\\
\textbf{\texttt{EFR 8.2:}}
A calculus proof that the values where $P = k/2$ correspond to inflection points of solutions 
is given in the text (see the paragraph immediately following this EFR). There it is shown that 
\begin{math}P'(t) = r(1 - 2P/k)f(P)\end{math} where \begin{math}f(P) = rP(1-P/k)\end{math}. From this formula, we see that $P'(t)$ can vanish 
at no other (nonzero) values of P; there are no other inflection points. In fact, even if we allowed 
$P \geq 0$, there would be no more.\\ 
\textbf{\texttt{EFR 8.3:}}
\includegraphics{fig1}
(a) In the figure on the 
right, we have graphed the right side 
of the Gompertz equation 
\begin{math}P'(t) = -sln(P/k)\end{math} and classified 
the unique equilibrium point. 
(b) The plots can be accomplished 
using a loop analogous to that 
employed in the solution of Example 
8.6. 
>> \begin{math}f=inline('-0.024*P* 
log(P/l)', 't', 'Ρ')\end{math}; 
>> hold on 
>> for P0=0.1:.2:1.1 
\begin{math}[t, y] = euler(f,0,200, 
ΡΟ,Ο.Ι); plot(t,y)\end{math} 
end 
The resulting plot is shown in the 
lower figure. Each of the six graphs 
maintains the same concavity; the 
lack of inflection points can be deduced from the lack of local extreme values in the graph of part (a). 
Also, as expected from the stability graph of part (a), each of the solutions approaches the stable 
equilibrium solution \begin{math}P\equiv 1(= k)\end{math} . 


(c)
\includegraphics{fig2}
Following the suggestion, we intrcoduce the new variable: $y=ln(P/k)$. Since \begin{math}ke^y = P\end{math}
different-tiation with respect to t gives:
\begin{math}-ske^y =
\frac{dP}{dt} = \frac{dP}{dy}y'\end{math}(we have taken
into account the Gompertz equation). 
Equating the first and last terms and 
canceling common factors gives us 
$y' = -sy$. Thus y satisfies the Malthus 
growth equation, and we can write down 
its general solution:    \begin{math}y=y_{0}e^-st\end{math}  
Consequently,\begin{math}P=ke^y=kexp(y_{0}e^-st)\end{math}, 
and so \begin{math}P'(t)=Py_{0}^-st(\sim s)=ae^-btP\end{math},
where \begin{math}a=-sy_0\end{math} and $b=s$, as asserted.\\

\textbf{\texttt{EFR 8.4:}}
Simply change h to 0.01 and let the loops for the improved Euler and Runge-Kutta 
methods run from 1:200. (The correct size can again be seen by looking at size(t) after Euler 
program is run with this step size). Here now are the commands to get the plot of Figure 8.12b: 
\\subplot(2,2,1), $s=1$:.01:3; plot(s,yexact(s)), hold on, 
\\plot(t,ye,'bo') 
\\subplot(2,2,2), plot(t,abs(yexact(t)-ye), 'bo'), hold on, 
\\plot(t,abs(yexact(t)-yie), 'gx') 
\\subplot(2,2,3), plot(t,abs(yexact(t)-yie), 'gx'), hold on, 
\\plot(t,abs(yexact(t)-yrk) ,'r+') 
\\subplot(2,2,4), plot(t,abs(yexact(t)-yrk), 'r+')\\
\textbf{\texttt{EFR 8.5:}}
\begin{math}\frac{dy}{dt}=2ty\Rightarrow\int\frac{dy}{y}=\int{2tdt}\Rightarrow ln|y|=t^2+C\Rightarrow = \pm e^C exp(t^2)=Aexp(t^2)\end{math}\\

\textbf{\texttt{EFR 8.6:}}
The M-file is boxed below:
\begin{lstlisting}[frame=single, numbers=none]
functio n (t,y]-impeuler(f,a,b,y0,hstep )
% input variables: f, a, b, yO, hstep
% output variables: t, y
% f is a function of two variables f(t,y). The program will apply
% the improved Euler method to solve the IVP: (DE): y'=f(t,y), (IC)
% y(a)=y0 on the t-interval [a,b] with step size hstep. The output
% will be a vector of t's and corresponding y's t(1)=a; y(1)=yO;
nmax=ceil((b-a)/hstep);
for n=1:nmax
	t (n+1)=t(n)+hstep;
	y(n+1)=y(n)+.5*hstep*(feval(f,t(n) ,y(n) )...
	+ feval(f,t(n+1) ,y(n)...
	+hstep*feval(f,t(n),y(n))));
end 
\end{lstlisting}


\textbf{\texttt{EFR 8.7:}}
\includegraphics{fig3}
The code is below and the resulting graph of the
error is shown on the right. From the graph, we see that the
maximum error is less than 1/1Oth of what was guaranteed by
Theorem 8.2.
\begin{lstlisting}[frame=none, numbers=none]
>> f=inline('0.05*y','t','y');
>> [t, y]=euler(f,0,5,10,0.046);
>> yexact=inline('10*exp(.05*t)','t'); 
>> plot(t,abs(y-yexact(t)))
\end{lstlisting}


\textbf{\texttt{EFR 8.8:}}
(a) The M-filc is boxed below: 
\begin{lstlisting}[frame=single, numbers=none]
function [t, y] = rkf45(varf, a, b, yO, tol, hinit, hmin, hmax) 
% input variables: varf, a, b, yO, tol, hinit, hmin, hmax
% output variables: t, y, varf is a function of two variables
% varf (t,y).
% The program will apply the Runge-Kutta-Fehlberg (RKF45) method to
% solve the IVP: (DE): y'=varf(t,y) , (IC)
% y(a)=yO on the t-interval [a,b] with step size hstep. The output
% will be a vector of t's and corresponding y's the last four input
% variables are optional and are as follows:
% tol = the target goal for the global error, default = le-5
% hinit = initial step size, default = 0.1
% hmin = minimum allowable step size, default = le-5
% hmax = maximum allowable step size, default = 1
% program will terminate with an error flag if it is necessary to
% use a step size smaller than hmin

%set default input variables as needed
if nargin<5, tol=le-5; end
if nargin<6, hinit=O.1; end
if nargin<7, hmin=1e-5; end
if nargin<8, hmax=1; end 

t(1)=a; y(1)=y0; n=1;
h=hinit;
flag =0; %this flag will keep track if maximum step size has been
reached.
flag2 =0; %this flag will keep track if minimum step size has been
reached. 

while t(n)<b
	k1=h*feval(varf,t(n),y(n));
	k2=h*feval(varf,t(n)+h/4,y(n)+k1/4);
	k3=h*feval(varf,t(n)+3*h/8,y(n)+3*k1/32+9*k2/32);
	k4=h*feval(varf,t(n)+12*h/13,y(n)+(1932*k1-7200*k2+72 96*k3)/2197);
	k5=h*feval(varf,t(n)+h,y(n)+439*k1/216-8*k2+3680*k3/513-
845*k4/4104);
	k6=h*feval(varf,t(n)+h/2,y(n)-8*k1/27+2*k2-
3544*k3/2565+1859*k4/4104-11*k5/40);
	E=abs(k1/360-128*k3/4275-2197*k4/75240+k5/50+2*k6/55);
	
	if E > h*tol %step size is too large, reduce to half and try
again
	hnew=h/2;
		if hnew<hmin %minimum step size has been reached, accept
approximation but set
% warning flag2
			flag2=1;
			t(n+1)=t(n)+h;
			y(n+1)=y(n)+16*k1/135+6656*k3/12825+28561*k4/56430-
9*k5/50+2*k6/55;
			n=n+1;
			h=hmin;
		else
			h=hnew;
		end
	elseif E < h*tol/4 %step size is too small, accept approximation
but double next step %size
		t(n+1)=t(n)+h;
		y(n+1)=y(n)-H6*k1/1354-6656*k3/12825+28561 *k4/56430-
9*k5/50+2*k6/55;
		n=n+1;
		h=2*h;
		if h>=hmax
			flag=1;
			h=hmax;
		end
	else %accept approximation and proceed
		t(n+1)=t(n)+h;
		y(n+1)=y(n)+16*k1/135+6656*k3/12825+28561*k4/56430-
9*k5/50+2*k6/55;
		n=n+1; 
	end
end
if flag ==1
	fprintf('In the course of the RKF45 program, the maximum step
size has been ... reached.')
end
if flag2 ==1
	fprintf('WARNING: Minimum step size has been reached; it is
recommended to run ...
the \r')
	fprintf('program again with a smaller hmin and or a larger tol')
end 
\end{lstlisting}


\begin{wrapfigure}{i}{0.55\textwidth} %this figure will be at the right
    \centering
    \includegraphics[width=0.55\textwidth]{fig4}
\end{wrapfigure}

(b) The following commands will run
the RKF45 program on the IVP of
Example 8.7 with the default settings,
and plot the error against the exact
solution given in that example. The
error plot is shown on the right. 
\begin{lstlisting}[frame=none, numbers=none]
>>
f=inline('2*t*y','t','y');
>>yexact = inline('exp(t.^2-1)');
>>[t,yrkf]=rkf45(f,1,3,1);
>>plot(t,abs(yrkfyexact(t))) 
>>plot(t,abs(yrkfyexact(t)), 'rx') 
>>xlabel('x-values'),ylabel('y-values'), 
>>title('Error for the RKF45 method')
>>size (t)->ans = 1 187 
\end{lstlisting}
The last command shows us that RKF45 used 187 plotting points; and the figure shows that the density of them increases in the region on the right where the solution experiences its most rapid growth. Comparing with Figure 8.12b, we see that this error is about 10 times less than that of the Runge-Kutta method when the latter used 200 plotting points.\\

\textbf{\texttt{EFR 8.9:}}
From the result of Example $8.19$ (with $r=2$ ), the region of numerical stability for Euler's method is $h<1$, so any step size larger than one will eventually experience instability. The plot of Figure 18.21(a) resulted from using $h=1.03$. With the same step size, the Runge-Kutta method gives a numerical solution that converges to zero, but (as is easily checked) is not very accurate. The plot of Figure $8.21(b)$ resulted from using a step size of $h=1.43$ with the Runge-Kutta method.\\

\textbf{\texttt{EFR 8.10:}}
EFR 8.10: Substituting $f(t, y)=r y$ (from the IVP (14)) and a constant step size $h_{n}=h$ into the recursion formula (17) $y_{n+1}=y_{n}+h_{n}\left[f\left(t_{n}, y_{n}\right)+f\left(t_{n+1}, y_{n+1}\right)\right] / 2$ produces: $y_{n+1}=y_{n}(1+h r / 2)+$ $(h r / 2) y_{n+1}$, or $y_{n+1}=\frac{(1+h r / 2)}{(1-h r / 2)} y_{n}$. Equivalently, $y_{n+1}=\mu^{n} y_{0}$, where $\mu \equiv \frac{1+h r / 2}{1-h r / 2}$. Since $h$ is positive and $r$ is negative, we always have $\mu<1$ and so $y_{n} \rightarrow 0$ as $n \rightarrow \infty$, regardless of the step size $h$. This proves the asserted unconditional numerical stability.\\

\textbf{\texttt{EFR 8.11:}}
(a) The M-file is boxed below:
\begin{lstlisting}[frame=single, numbers=none]
function [t, y] = adamsbash5(varf, a, b, y0, h)
% Performs the Adams-Bashforth fifth-order scheme to solve an IVP
% Calls on fifth-order Runge-Kutta scheme (rk5) to create the seed
% iterates.
% Input variables: varf a function of two variables f(t,y)
% describing the ODE y' = f(t,y). Can be an inline function or an M-
% file a, b = the left and right endpoints for the time interval of
% the IVP yO the intial value y(a) given in the intial condition
% h = the step size to be used
% Output variables: t = the vector of equally spaced time values for
% the numerical solution, y $\thickappro$ the corresponding vector of y
% coordinates.

nmax=ceil((b-a)/h);
%first form the seed iterates using single step Runge-Kutta
[t,y]=rk5(varf,a,a+4*h,y0,h);

for n=5:nmax
	t(n+l)=t(n)+h;
	y(n+l)=y(n)+h/720*(1901*feval(varf,t(n),y(n))-2774*feval(varf,t(nl),y(n-l))...
+2 616*feval(varf,t(n-2),y(n-2))-1274*feval(varfft(n-3)ry(n3))+251*feval(varf,t(n-4),y(n-4)));
end 
\end{lstlisting}
(b) The M-file is boxed below:
\begin{lstlisting}[frame=single, numbers=none]
function [t, y] = adamspc5(varf, a, b, yO, h)
% Performs the Adams-Bashforth-Moulton fifth-order predictor-
% corrector scheme to solve an IVP.
% Calls on fifth-order Runge-Kutta scheme (rk5) to create the seed
% iterates.
% Input variables: varf a function of two variables f(t,y)
% describing the ODE y' = f(t,y). Can be an inline function or an M-
% file a, b = the left and right endpoints for the time interval of
% the IVP yO the intial value y(a) given in the intial condition
% h = the step size to be used
% Output variables: t = the vector of equally spaced time values for
% the numerical solution, y = the corresponding vector of y
% coordinates.
nmax=ceil((b-a)/h);
%first form the seed iterates using single step Runge-Kutta
[t,y]=rk5(varf,a,a+4*h,y0,h);

for n=5:nmax
	t (n + 1)=t(n)+h;
	%predictor
	y(n+1)=y(n)+h/720*(1901*feval(varf,t(n),y(n))-2774*feval(varf,...
	t(n-1),y(n-1))+2616*feval(varf,t(n-2),y(n-2))-1274*feval...
	(varf,t(n-3), y(n-3))+251*feval(varf,t(n-4),y(n-4)));
	%corrector
	y(n+1)-y(n)+h/720(251*feval(varf,t(n+1),y(n+1))+646*feval ..
	(varf,t(n),y(n))-264 feval(varf,t(n-1),y(n-1))+106*feval ...
	(varf,t(n-2),y(n-2))-19*feval(varf,t(n-3),y(n-3)));
end
\end{lstlisting}

\textbf{\texttt{EFR 8.12:}}
(a) It is required to show that (assuming the differentiability assumptions of Taylor's theorem hold): $y(t+h)-y(t-h)-2 f(t, y)=O\left(h^{2}\right)$. Indeed using Taylor's theorem for the first two expressions on the left and the DE for the third, we obtain: $y(t+h)-y(t-h)-2 f(t, y)$ $=\left(y(t)+h y^{\prime}(t)+O\left(h^{2}\right)\right)-\left(y(t)-h y^{\prime}(t)+O\left(h^{2}\right)\right)-2 h y^{\prime}(t)=O\left(h^{2}\right)$.
\\(b) In the notation of (18), the parameters for the midpoint method are: $K=2, \alpha_{1}=0, \alpha_{2}=0$, $\beta_{0}=0$ (explicit), and $\beta_{1}=2$, and so the characteristic polynomial is given by: $P(\lambda)=\lambda^{2}-\left(0 \cdot \lambda^{1}+1 \cdot \lambda^{0}\right)=\lambda^{2}-1$. Since the roots are $\lambda=\pm 1$, the stability theorem in the text implies that the midpoint method is weakly stable.
\\(c) The following code was used to produce Figure 8.25.
\begin{lstlisting}[frame=none, numbers=none]
>>y(1)-1;t(1)-0; h=0.0001;
>>t(2)-t(1)+h; y(2)-y(1)+h*(20-4*y(1));
n=2;
whilet(n)<=4
  t(n+1)=t(n)+h;
  y(n+1)-y(n-1)+h*(20-4*y(n));
  n=n+1:
end
plot(t,y), axis([04071), title('Weak Stability')
\end{lstlisting}

\noindent\hrulefill\\
\textbf{SYSTEMS OF FIRST-ORDER DIFFERENTIAL EQUATIONS AND HIGHER-ORDER DIFFERENTIAL EQUATIONS}\\

\textbf{\texttt{EFR 9.1:}}
(a) Letting $y_{1}(t)=y^{\prime}(t)$ and $y_{2}(t)=y^{\prime \prime}(t)$, the given IVP is equivalent to the following first-order system:
$$
\begin{cases}y^{\prime}(t)=y_{1}, & y(0)=1 \\ y_{1}^{\prime}(t)=y_{2}, & y_{1}(0)=2 . \\ y_{2}^{\prime}(t)=\sin (3 t)-y_{2}-e^{\prime} y, & y_{2}(0)=3\end{cases}
$$
(b) Introducing $R_{1}(t)=R^{\prime}(t)$ allows us to translate the second-order system into the following firstorder system:
$$
\begin{cases}R^{\prime}(x)=R_{1}, & R(10)=4 \\ R_{1}^{\prime}(x)=R S+\sqrt{x^{2}+1}, & R_{1}(10)=-1 \\ S^{\prime}(t)=R_{1} \cos (S), & S(10)=1\end{cases}
$$\\
\textbf{\texttt{EFR 9.2:}}
The M-file is boxed below:
\begin{lstlisting}[frame=single, numbers=none]
function [t,x,y]=runkut2d (f, g, a,b, x0, y0, hstep)
%This M-file performs the Runge-Kutta method to solve a two-
%dimensional system of form:
%Dx(t)=f(t,x, y),x(a)=x0, Dy(t)=g(t,x,y), y(a) = y0, on the
%interval a <= t <= b.
%Input variables: f and g inline functions (or M-files)for the
%derivatives of the unknown functions x(t) and y(t). These must be
%specified as functions of the three variables: t, x, and y (in
%this order)a and b: endpoints for the time interval on which the
%solution is sought x0, and y0, initial conditions for the unknown
%functions at t = a hstep, the step size (any positive number)
%output variables are three vectors of the same size:t, x and y,
%for the numerical solution.
                  
t=a:hstep:b;x(1)=x0; y(1)=y0;
[mnmax]=size(t);
for n=1:(nmax-1)
	k1x feval(f,t(n),x(n),y(n));
	k1y-feval(g,t(n),x(n),y(n));
	k2x=feval(f,t(n)+.5*hstep,x(n)+.5*hstep*k1x,y(n)+.5*hstep*kly);
	k2y=feval(g,t(n)+.5*hstep,x(n)+.5*hstep*k1x,y(n)+.5*hstep*kly);
	k3x=feval(f,t(n)+.5*hstep,x(n)+.5*hstep*k2x,y(n)+.5*hstep*k2y);
	k3y=feval(g,t(n)+.5*hstep,x(n)+.5*hstep*k2x,y(n)+.5*hstep*k2y);
	k4x=feval(f,t(n)+hstep,x(n)+hstep*k3x,y(n)+hstep*k3y);
	k4y=feval(g,t(n)+hstep,x(n)+hstep*k3x,y(n)+hstep*k3y);
	x(n+1)=x(n)+1/6*hstep*(k1x+2*k2x+2*k3x+k4x);
	y(n+1)=y(n)+1/6*hstep*(k1y+2*k2y+2*k3y+k4y);
end
\end{lstlisting}
\textbf{\texttt{EFR 9.3:}}
\begin{wrapfigure}{r}{0.7\linewidth}
\includegraphics[width=\linewidth]{fig5}
\end{wrapfigure}
The MATLAB code that produced the plot on the right is given below. To see the flow direction along these solution curves, we fix one of them, and consider the (unique) point $(1, y)$ with $y<1$ on the graph (directly below the equilibrium solution $(1,1)$ ). At this point the first differential equation of the system, $x^{\prime}=-x+x y$, tells us that $x^{\prime}$ is negative, so $x$ is decreasing and this forces a clockwise flow orientation. A more general phase-plane analysis technique will be presented Section $9.2$.
\begin{lstlisting}[frame=none, numbers=none]
>> xp=inline('-x+x*y',
't','x','y');
>> yp=inline('y-x*y','t','x','y');
>> for x0=linspace(.05,.95,20)
    (t,xrk,yrk]=runkut2d(xp,yp,0,10,x0,x0,0.01);
    plot(xrk,yrk),hold on
end
>> xlabel('x(t)'),ylabel('y(t)')
\end{lstlisting}

\textbf{\texttt{EFR 9.4:}}
EFR 9.4: (a) Having $f>1$ would correspond to removing more fish than are available, which is impossible.
(b) $x^{\prime}=0 \Rightarrow x(y-1-f)=0$ and $y^{\prime}=0 \Rightarrow y(1-x-f)=0$ so if we also require $x, y \neq 0$ this gives $x=1-f$ and $y=1+f$ as the only (nontrivial) equilibrium point.\\

\textbf{\texttt{EFR 9.5:}}
(a) From (6) we get that $\frac{d I}{d S}=\frac{d I / d t}{d S / d t}=\frac{l(r S-a)}{-r I S}=-1+\frac{\rho}{S}$, provided $I \neq 0$. Viewed in the $(I, S)$ plane, this DE is separable; integrating yields: $I(t)-I(0)=-S(t)+S(0)+\rho \ln (S(t) / S(0))$. Since $I^{\prime}=I(r S-a)=\operatorname{lr}(S-\rho)$, we see that if $S(0)>\rho$, then $I^{\prime}(0)>0$ and $I$ increases until $S=\rho$, after which $I$ decreases (note by (6) that $S$ is decreasing). Therefore, $\max I=\left.I\right|_{S=\rho}=I(0)-\rho$ $+S(0)+\rho \ln (\rho / S(0))=N-\rho+\rho \ln (\rho / S(0))$, as asserted.
(b) As in part (a), we deduce that $d S / d R=-S / \rho$ so that $S$ and $R$ are related by Malthusian growth and thus $S(t)=S(0) e^{-R(t) / \rho}$. Since $R \leq N$, we get $S(t) \geq S(0) e^{-N / \rho}>0$ so that $S(\infty)>0$.
(c) We first observe that since eventually $S(t)<\rho$ the DE for $l$ in (6) implies that eventually $/$ will have exponential decay and so $I(t) \rightarrow 0$ as $t \rightarrow \infty$. Using (5), we can rewrite the equation $S(t)=S(0) e^{-R(t) \rho}$ obtained in part (b) as $S(t)=S(0) e^{-\{N-S(t)-l(t)] \rho \rho}$. If we take the limit of this equation as $t \rightarrow \infty$, it becomes: $S(\infty)=S(0) e^{-\{N-S(\infty)] / \rho}$. We have so far shown that $S(\infty)$ is a (positive) root of the equation $x=S(0) \exp [-(N-x) / \rho]$, Consider the two sides of this equation as functions of $x>0$ : $f(x) \geq x$ and $g(x)=S(0) \exp [-(N-x) / \rho]$. Since $g^{\prime}(x)=g(x) / \rho>0$ and $g^{\prime \prime}(x)=g(x) / \rho^{2}>0$ we see that $g(x)$ is increasing and concave upward. Thus the equation $f(x)=g(x)$ can have at most two positive roots (draw a picture to see this). If there is only one root, we have nothing to prove, so assume there are two roots: $x_{1}<x_{2}$ such that $g\left(x_{i}\right)=x_{i}$. For the larger root, we must have $g^{\prime}\left(x_{2}\right)>f^{\prime}\left(x_{2}\right)$, or $x_{2} / \rho>1$, or $x_{2}>\rho$ (draw a picture or use concavity to see this). But $S(\infty)$ cannot be greater than $\rho$ since if it were then $I(t)$ would still be increasing. Therefore $S(\infty)=x_{1}$, as was to be proved.
To apply Newton's method (Program 6.2) we are seeking a root of $F(x)=S(0) \exp (-(N-x) / \rho)-x$ and in our example, $N=763, S(0)=762, a=.44036, r=2.18 e-3$, so $\rho=a / r=202$ :
\begin{lstlisting}[frame=none, numbers=none]
>> f=inline('762*exp(-(763-x)/202)-x');
>> fp=inline('762*exp(-(763-x)/202)/202-1');
>> newton(f,fp,202)
 ->Exact root found
  ->19.1758
\end{lstlisting}
Compare this with the approximately 22 susceptibles predicted from the PDE model after 14 days.
Thus, theoretically, out of the 762 original susceptibles, all but about 3 who will contract the disease
will have done so after 14 days.\\
 
\textbf{\texttt{EFR 9.6:}}
\begin{wrapfigure}{r}{0.6\linewidth}
\begin{center}
\includegraphics[width=0.6\linewidth]{fig6}
\end{center}
\end{wrapfigure}
(a) $x^{\prime}=x(1-x-y / 2) \Rightarrow$
$x$-nullclines: $x=0, y=2(1-x)$.
$$
y^{\prime}=y(1-y-x / 2) \Rightarrow
$$
$y$-nullclines: $y=0, y=1-x / 2$.
Equilibrium solutions: $(x, y)=(0,0),(1,0)$, $(0,1),(2 / 3,2 / 3)$.
In the phase plane diagram on the right, the two $x$-nullclines (passing through $(0,2)$ ) are shown along with the $y$-nullclines (passing through $(2,0)$ ).
\\(b) The following code is similar to that employed in the solution of Example 9.5, and will produce a phase portrait similar to that of Figure 9.12.
\begin{lstlisting}[frame=none, numbers=none]
>> dx-inline('x-x^2-x*y/2',
't','x','y');
>> dy=inline('y-y^2-x*y/2',
't','x','y');
>> x1=linspace(.5,1.8,11);
y1=2-x1;
>> x2=linspace(.2,.7,11); y2=.75-x2;
>> x0=(x1 x2);y0=[yl y2);
>> size(x0)
->ans = 1    22
hold on
for k=1:22
[t,x,y]=runkut2d(dx,dy,0,20,x0(k),y0(k),0.01); plot(x,y)
end
\end{lstlisting}

\textbf{\texttt{EFR 9.7:}}
Equilibrium solutions of (14) are solutions of $X^{\prime}(t)=0$ and thus are solutions of the matrix equation $A X=\left[\begin{array}{l}0 \\ 0\end{array}\right]$. From linear algebra (see Sections 7.1 and 7.2) the origin $\left[\begin{array}{l}0 \\ 0\end{array}\right]$ will be a unique solution if $A$ is invertible. If $A$ is not invertible, the solutions will consist of a line through the origin and hence the origin will not be isolated.\\

\textbf{\texttt{EFR 9.8:}}
EFR 9.8: (a) In general, the SIRS system (7) yields the following $S$-I nullclines: $S^{\prime}=-r I S+b R$ $=-r I S+b(N-I-S) \Rightarrow S$-nullelines: $\quad 0=-r I S-b I+b N-b S, \quad$ or $\quad(r S+b) I=b(N-S)$, or
\begin{wrapfigure}{r}{0.6\linewidth}
\begin{center}
\includegraphics[width=0.6\linewidth]{fig7}
\end{center}
\end{wrapfigure}
$I=b(N-S) /(r S+b)=(N-S) /(r S / b+1)$,
$I^{\prime}=r I S-a l \Rightarrow I$-nullclines: $0=r / S-a I$ $=r I(S-\rho) \quad(\rho=a / r) \Rightarrow I=0$ and $S=\rho$. In the setting of Example 9.4, the parameters are as follows: $N=10,000, r=$ $2 \mathrm{e}-4, a=4, b=0.25$, and so $\rho=\mathrm{a} / \mathrm{r}=$ 20,000 and we get these specific nullclines:
$S$-nullcline: $I=(10000-S) /\left(8 \mathrm{e}-4^{*} \mathrm{~S}+1\right), I$ nullclines: $I=0, S=20000$. By testing the signs of the derivatives of $S$ and $I$ on the regions between nullclines, we obtain the phase-plane diagram shown on the right, where we have drawn the $S$-nullcline (curved) and the two $I$-nullclines (lines). The only equilibrium solution is $(10000,0)$.
(b) and (c): To apply Theorem 9.3, we need to know that the equilibrium solution is isolated. This can be seen by extending the phase-plane diagram just drawn to include some values in the fourth quadrant (i.e., negative $I$-values and positive $S$-values), even though this quadrant bares no physical significance to the model at hand. Indeed, if we were to extend the phase-plane analysis to the whole fourth quadrant, the blue curve and vertical red line would intersect below to form only one new equilibrium solution leaving $(10000,0)$ as isolated. We first use $(7)$ to compute the form of the Jacobian matrix:
$$
A=\left[\begin{array}{ll}
S_{S} & S_{I} \\
I_{S} & I_{l}
\end{array}\right]=\left[\begin{array}{cc}
-r I-b & -r S-b \\
r I & r S-a
\end{array}\right]
$$
From this we compute $t r(A)=r(S-I)-b-a$ and $\operatorname{det}(A)=(-r I-b)(r S-a)+r I(r S+b)=r b(I-S)$ $+a r I+a b$. We will be keeping the values of $b=0.25$ and $r=2 \mathrm{e}-4$ fixed in this part. From the analysis in part (a), $(10,000,0)$ will be the only (isolated) equilibrium solution as long as $\rho=a / r>$ 10,000 , or $a \geq 2$ (corresponding to the average infection lasting for $1 / 2$ year, or 6 months rather than three months). In all of these cases, we may write: $\operatorname{tr}(A)=7 / 4-a$, $\operatorname{det}(A)=a / 4-1 / 2$. Thus, in the range $2<a \leq 4$, $\operatorname{det}(A)$ is always positive and $\operatorname{tr}(A)$ remains negative. We compute $\operatorname{tr}(A)^{2} / 4-\operatorname{det}(A)=a^{2} / 4-9 a / 8+81 / 64$ and see that this parabola has a minimum value of zero at $a=$ $2.25$ (this computation is done easily using MATLAB's Symbolic Toolbox). Thus, by part (b) of Theorem $9.3$, the equilibrium solution $(10000,0)$ will always be a stable node (this is corroborated with Figure $9.12$ in the text in case $a=4$ ), whenver $2<a \leq 4$ and $a \neq 2.25$. In the special case $a=2.25$, part (d) of that theorem tells us that we have either a stable node or spiral (a MATLAB plot would not be a reliable way to further determine the type of node due to the sensitivity of the problem to small changes in data). In case $a=2$, det $(A)=0$, and Theorem $9.3$ is inconclusive. Finally, in the range $0<a<2$ (corresponding to the average infection lasting more than $1 / 2$ a year, and lasting indefinitely longer as the paramter $a$ approaches zero), there will now be 2 equilibrium solutions: the original $P_{1}=$ $(10,000,0)$ and a new one $P_{2}=(\rho,(10,000-\rho) /(4 a+1))$, where $\rho=a / r=5000 a$. For $P_{1}$ we have $\operatorname{det}(A)<0$ throughout the range $0<a<2$ so that by part (a) of Theorem $9.3, P_{1}$ will be an unstable saddle point. For $P_{2}$ we will use the Symbolic Toolbox for the calculations.
\begin{lstlisting}[frame=none, numbers=none]
>>b=1/4; r=2e-4; rho syms a, rho=a/r; S=rho;
>>I = (10000-rho)/(4*a+1);
>> trA=r*(S-I)-b-a; bdetA = r*b*(I-S)+a*r*I+a*b;
>> ezplot(detA,[0,2]) %plot(not shown here) tells us the determinant
is always positive when 0<a<2.
>> ezplot(trA,[0,2]) %plot (not shown here) tells us the trace is
always negative when 0<a<2.
\end{lstlisting} 

\begin{wrapfigure}{r}{0.6\linewidth}
\begin{center}
\includegraphics[width=0.8\linewidth]{fig8}
\end{center}
\end{wrapfigure}

Thus we already know (from Theorem $9.3$ or its corollary) that the equilibrium point $P_{2}$ is stable. To see the character of this stable equilibrium, we examine the graph of $\operatorname{tr}(A)^{2} / 4-\operatorname{det}(A)$ over our indicated range:
\begin{lstlisting}[frame=none, numbers=none]
>>ezplot(trA^2/4-detA,[0,2]) %plot is shown at right
\end{lstlisting}
From the plot we see that there are two
places where a sign change occurs. We
can solve for these numbers as follows:
\begin{lstlisting}[frame=none, numbers=none]
>> double(solve(trA^2/4 - detA,a))
->ans =1.9336, -0.5989, 0.1653
\end{lstlisting}
Only the first and last of these are relevant
for us; we add these special points on our graph:
\begin{lstlisting}[frame=none, numbers=none]
>> hold on, plot(1.9336,0,'rp'), plot(.1653,0,'rp')
>> xlabel('a'), title('Plot of tr(A)^2/4 - det(A)')
\end{lstlisting}
Theorem $9.3$ tells us that when $a$ is between these two points (marked with pentacles in the figure), the equilibrium point will be a stable spiral, and when it is to the left or right of them, it will be a stable node. When a coincides with one of these, the theorem tells us that $P_{2}$ will either be a spiral or a node. We point out that it would not be feasible to solve the problem numerically at one of these borderline values to determine if there is a spiral or a node. This is because the problem is extremely unstable and sensitive to perturbations.\\

\textbf{\texttt{EFR 9.9:}}

\begin{wrapfigure}{r}{0.6\linewidth}
\begin{center}
\includegraphics[width=0.8\linewidth]{fig9}
\end{center}
\end{wrapfigure}


$$
\begin{aligned}
&x^{\prime}=x\left\{\frac{2}{3}(1-x / 4)-y /(1+x)\right\} \\
&\Rightarrow x \text {-nullclines: } \quad y=\frac{2}{3}(1-x / 4)(1+x), \\
&y^{\prime}=s y(1-y / x) \\
&\Rightarrow y \text {-nullclines: } y=0, \quad y=x .
\end{aligned}
$$
Note that $x=0$ is not an $x$-nullcline since $y^{\prime}$ is undefined at $x=0$. Equilibrium solutions: $(x, y)=(1,1),(4,0)$. In the phase portrait diagram on the right, the $x$ nullclines is shown (curved) along with the the two $y$-nullclines (lines).

(b)To determine the character of the equilibrium solution(1,1),we will employ Theorem 9.3.Since
the computations are long,we will use the Symbolic Toolbox.

\begin{lstlisting}[frame=none, numbers=none]
>> syms x y s
>> xp = 2*x*(1-x/4)/3-x*y/(1+x); yp = s*y*(1-y/x);
>> A = [diff(xp,x) diff(xp,y); diff(yp, x) diff(yp, y)] %Jacobian
matrix
>> subs(det(A), [x y], [1 1])
->ans=5/12*s (This is always positive for s > 0.)
>> subs (Trace(A), [x y], [1 1])
->ans=1/12-s
\end{lstlisting}
Note that the latter (trace of the Jacobian) is positive whenever $s<1 / 12$, and by Theorem $9.3$, for such values of s, the equilibrium point $(1,1)$ is an unstable node or spiral. In particular, it is repelling. Similarly, when $s>1 / 12$, the theorem tells us that $(1,1)$ is a stable node or spiral so is not repelling. When $s=1 / 12$, Theorem $9.3$ tells us that $(1,1)$ is either a vortex or a spiral, but gives no additional information so we cannot use it to decide if $(1,1)$ is repelling or not. Numerical computations of the solution would not be useful here because of the sensitivity of the problem to $s$ being slightly less than $1 / 12$ or slightly greater than $1 / 12$.
(c) On all but the left side of the square $R$, the phase portrait of the solution of part (a) above shows that the direction fields never point outward, so it remains to deal with the left side. As $(x, y)$ approaches the left side, we see from the system of DEs that $x^{\prime} \rightarrow 0$ and $y^{\prime} \rightarrow-\infty$. It follows that orbits that start in $R$ can never reach the left side of $R$; they will first hit (from above) the green parabola, after which their horizontal velocity component will be positive. We have shown that no orbit that originates within the square $R$ can ever exit $R$ (i.e., $R$ is a basin of attraction).


\newpage
\textbf{\texttt{EFR 9.10:}}

\begin{wrapfigure}{r}{0.8\linewidth}
\begin{center}
\includegraphics[width=0.8\linewidth]{fig10}
\end{center}
\end{wrapfigure}



\begin{lstlisting}[frame=none, numbers=none]
>>[t,X]=rksys('lorenz',0,50,[-8 8 27 ],0.1);
>> x=X(:,1); x-x';
>> for i=1:8
[ti,Xi]=rksys('lorenz',0,50,[-8 8 27],0.1/2^i);
for j=1:501
xi(j)=Xi(2^i*j-2^i+1,1);
end
subplot(3,2,i)
plot(t,x-xi)
x=xi;
end
\end{lstlisting}
The successive difference plots on the right clearly indicate how the quality of the solutions improve with smaller step sizes.\\









\textbf{\texttt{EFR 9.11}} (a) The code of part (a) of Example $9.8$ needs only a very minor modification, namely the line defining $d z$ should be modified to: $d z=i n l i n e\left(1-32.174 / 1.5^{*} \sin (t h)^{\prime}\right.$, $\left.' t ', t h ', z^{\prime}\right)$;
(b) The linear model can be explicity solved using the Symbolic Toolbox:
$>>$ syms th $L$ g
$>$ dsolve ('D2th $+g^{*} t h=0^{\prime}, ' t$ ')
$\rightarrow$ ans $=\mathrm{C1}^{*} \cos \left(\mathrm{g}^{\wedge}(1 / 2)^{*} \mathrm{t}\right)+\mathrm{C} 2^{*} \sin \left(\mathrm{g}^{\wedge}(1 / 2)^{*} \mathrm{t}\right)$
The general solution, being a combination of cosines and sines with the same period, is certainly periodic.
For the nonlinear pendulum it is more difficult to prove periodicity. A phase-plane plot can be done with MABLAB (on increasingly longer long time intervals) to show that it is plausible that the solution is periodic, but this does not constitute a proof. The proof we give is motivated by considerations from physics, namely the conservation of energy in mechanics. The pendulum has two types of energies: kinetic and potential. The kinetic energy in physics is defined to be $K=\frac{1}{2} m v^{2}$ (where $v$ is the velocity of the mass), so that for the pendulum, we have $K=\frac{1}{2} m\left(L \theta^{\prime}\right)^{2}=\frac{L^{2} m}{2}\left(\theta^{\prime}\right)^{2}$. The potential energy in physics is defined (up to an additive constant) as $L=m g h$ where $h$ is the height of the mass, so that for the pendulum, $L=m g L(1-\cos \theta)$. The conservation of energy states that the total energy $E(t)=K+$ $L=$ constant. It would suffice to prove this, since, when the pendulum comes back on the return trip, it will eventually have to stop (before bobbing back). At this time $T$, its kinetic energy will equal zero
(as it was at time $=0$ ), therefore, by the conservation of energy, the potential energy and hence $\theta$ would be the same value when time was zero. Thus, from time $t=T$ onward, the motion of the pendulum is identical (by the uniqueness theorem) to what it was from time $t=0$ (since the IVPs are identical). This proves that $T$ is the period of the pendulum. To make this rigorous, we need only prove the conservation of energy, i.e., that $E^{\prime}(t)=0$. Indeed, $E^{\prime}(t)=K^{\prime}(t)+L^{\prime}(t)=L^{2} m \theta^{\prime} \theta^{*}+$ $m g L \sin \theta \theta^{\prime}=L m \theta^{\prime}\left[L \theta^{*}+g \sin \theta\right]$. The bracketed expression is zero because of the $\mathrm{DE}$ : $L \theta^{\alpha}+g \sin \theta=0$. Related problems on periodicity of more general pendulum-like DEs have been the subject of much investigation; for some interesting surveys in this area we refer to the following two articles: [Maw-82] and [Maw-97].\\





\noindent\hrulefill\\
\textbf{BOUNDARY VALUE PROBLEMS FOR ORDINARY DIFFERENTIAL EQUATIONS}\\
\textbf{\texttt{EFR 10.1:}}(a) Differentiating (3)
$$
y(x)=C \sinh (\theta x)+D \sinh (\theta(L-x))+w L x / 2 T-w / \theta^{2} T-w x^{2} / 2 T,
$$
To check the DE (2), we compute:
$$
\begin{aligned}
\frac{T}{E I} y+\frac{w x(x-L)}{2 E I} &=\frac{T}{E I}\left[C \sinh (\theta x)+D \sinh (\theta(L-x))+w L x / 2 T-w / \theta^{2} T-w x^{2} / 2 T\right]+\frac{w x(x-L)}{2 E I} \\
&=\frac{T C}{E I} \sinh (\theta x)+\frac{T D}{E I} \sinh (\theta(L-x))-\frac{w}{\theta^{2} E I} .
\end{aligned}
$$
The latter expression coincides with $y^{\prime \prime}(x)$ if $\theta^{2}=T / E I$. Having two arbitrary constants, this must be the general solution of the second-order equation.
(b) Using (3), we compute: $y(0)=D \sinh (\theta L)-w / \theta^{2} T, y(L)=C \sinh (\theta L)-w / \theta^{2} T$ and the indicated values for $C$ and $D$ make these values vanish.\\

\textbf{\texttt{EFR 10.2:}} No. An inhomogeneous $\mathrm{DE}$ has the form $L[y]=r(x)$ for some nonzero function $r(x)$. If we have two solutions, $y_{1}, y_{2}$ then $L\left[c y_{1}+d y_{2}\right]=(c+d) r(x)$.\\
\textbf{\texttt{EFR 10.3:}} (a) Nonlinear. (b) Linear, not homogeneous.

\textbf{\texttt{EFR 10.4:}} Nonlinear. $f_{y}=2 y$ takes on negative values in $R=\left\{a \leq t \leq b,-\infty<y, y^{\prime}<\infty\right\}$, so Theorem $15.1$ does not apply. (b) Nonlinear. $f_{y}=t$ is not always positive in $R=\left\{a \leq t \leq b,-\infty<y, y^{\prime}<\infty\right\}$ since $a=0$, so Theorem $15.1$ does not apply.\\


\textbf{\texttt{EFR 10.5:}}\\

\begin{wrapfigure}{r}{0.6\linewidth}
\begin{center}
\includegraphics[width=0.6\linewidth]{fig11}
\end{center}
\end{wrapfigure}



The two associated IVPs of the given linear BVP are as follows:
$(\mathrm{IVP}-1)\left\{\begin{array}{ll}y_{1}^{\prime \prime}(x)=\frac{1}{x} y_{1}^{\prime}+x^{4} & (\mathrm{DE}) \\ y_{1}(1)=1, y_{1}^{\prime}(1)=0 & \text { (1C-1) }\end{array}\right.$,
and
(IVP-2) $\left\{\begin{array}{l}y_{2}^{\prime \prime}(x)=\frac{1}{x} y_{1}^{\prime} \\ y_{2}(1)=0, y_{2}^{\prime}(1)=1 \quad(\mathrm{DE})\end{array}\right.$
Setting these up as two-dimensional linear systems and using the Runge-Kutta method
will be accomplished by the following MATLAB code: 

\begin{lstlisting}[frame=none, numbers=none]
>> f1=inline('u','x','y','u');
>> g1=inline('u/x+x^4','x','y','u');
>> f2=f1;
>> g2=inline('u/x','x','y','u');
>> [x,y1,u1]=runkut2d(fl,g1,1,2,1,0,.01);
>> [x,y2,u2]=runkut2d(f2,g2,1,2,0,1,.01);
\end{lstlisting}
To obtain the desired plots,we first verify the sizes of the solution vectors:
\begin{lstlisting}[frame=none, numbers=none]
>> size(x) ->ans=1 101
>> plot(x(1:10:101),y1(1:10:101),'gx'),hold on,
plot(x(1:10:101),y2(1:10:101),'go')
>> ybvp=y1+(4-y1(101))/y2(101)*y2; plot(x,ybvp)
>> ybvp(find(x==1.5))->ans=1.5892(=value of solution whenx=1.5)                                 
\end{lstlisting}

\textbf{\texttt{EFR 10.6:}}
(a) The M-file is boxed below. In order to facilitate the internal construction of the needed inline functions in terms of the inputted data for $p(t), q(t)$, and $r(t)$, we have set up the program to input these functions as strings (so in single quotes) and with the independent variable being $t$. Inline functions cannot be constructed in terms of other inline functions, so if we had instead inputted $p, q$, and $r$ as inline functions, we would have not been able to internally construct the needed inline functions to call on the Runge-Kutta program runkut $2 \mathrm{~d}$. Thus, if we had gone this route, it would have been necessary to recode the Runge-Kutta program inside of this one.

\begin{lstlisting}[frame=single, numbers=none]
function [t, y] = linearshooting(pstring, qstring, rstring, a, alpha, b, beta, hstep)
%M-file for EFR 10.6
%This program will use the linear shooting method to solve a linear
%BVP of the following form: y''(t)=p(t)y'+q(t)y+r(t)y, y(a)=alpha,
%y(b)=beta
%Input variables: pstring = string for the function for p(t),
%qstring string for the function for q(t),rstring = string for
%r(t), a, alpha, b, beta are numbers as in the BVP,hstep is a
%positive number to be used in the Runge-Kutta method.
%Output variables: tandy, vectors of the same size that give the
%time values and associated numerical solution values.
%NOTE:The first three input variables must be put in single quotes
%(so MATLAB will assign their data types to be strings). Within the
%program,we will need to create inline functions in terms of the
%formulas for p(t), g(t),and r(t).This would not be possible if
%instead we had these three functions inputted as inline functions.
%IMPORTANT:the independent variable of the inputted strings for p,
%q and r must be t.

%Step 1: Set up the functions for the linear systems corresponding
%two associated IVPs and solve each one.
%to the IVP-1: y1''(t)=p(t)y1'+q(t)y1+r(t), y1(a)=alpha, y1'(a)=0
y1p = inline('u', 't', 'y', 'u'); 
u1p = inline(['(', pstring, ')*u+(', qstring, ')*y+'
rstring],'t','y','u');
[t,y1,u1]=runkut2d(y1p,u1p,a,b,alpha,0,hstep); 
%IVP-2: y2''(t)=p(t)y2'+q(t)y2, y2(a)=0, y2'(a)=1
y2p = inline('u', 't', 'y', 'u');
u2p = inline(['(', pstring, ')*u+', qstring,'*y'],'t', 'y', 'u');
[t,y2,u2]=runkut2d(y2p,u2p,a,b,0,1,hstep);

%Step 2: Construct solution of BVP
y=y1+(beta-y1(find(t==b)))/y2(find(t==b))*y2;                           
\end{lstlisting}


(b) Looking at the BVP in Example 10.3, we see that the coefficient functions are as follows: $p(t)=0$, $q(t)=6.25 \mathrm{e}-6$, and $r(t)=50 t(t-50) / 96000000$. Thus, we can solve and plot the solution of this problem using the program of part (a) as follows:
\begin{lstlisting}[frame=none, numbers=none]
>>ft, y] = linearshooting('O', '6.25e-6', '50*t*(t-50)/96000000', 0, 0, 50, 0, .1);
>>plot(t, y)
\end{lstlisting}
The resulting plot is identical to that of Figure 10.2. 

\textbf{\texttt{EFR 10.7:}}
(a) In order to make this program more elegant, we would like to be able to call on Program 9.2, which has the following call format: $[t, x]=$ rksys (vector $f, a, b$, vecx, hstep). In order for this to be feasible, we will need to internally construct an inline function for vectore that consists of the right sides of the four DEs of the system that we will need to be (iteratively) solving. To make make the task more clear, we write down the system in terms of the variables that we will use in the program:
$$
\left\{\begin{array}{l}
y^{\prime}(t)=y p, \quad y(a)=\text { alpha } \\
y p^{\prime}(t)=f(t, y, y p), \quad y p(a)=m k \\
z^{\prime}(t)=z p, \quad z(a)=0 \\
z p^{\prime}(t)=z f_{y}(t, y, y p)+z p f_{p}(t, y, y p), \quad z p(a)=1
\end{array}\right.
$$
Thus the inline function vector $f$ should have inputs $t$ (a number) and $x v e c=[y, y p, z, z p]$ (a vector) and output the vector $\left[y p, f(t, y, y p)\right.$, $z p, z^{*} f y(t, y, y p)$, $\left.z p^{*} f j(t, y, y p)\right]$ (gotten from the right sides of the 4 DEs in the system). The problem is that, although we will be inputting the strings for $f, f y$ and $f y p$ with variables $t, y$, and $y$, these will need to internally be changed to $t$, xvec $(1)$ and xvec(2), respectively, so that vectorf's output will be expressed in terms of its input variables (the number $t$ and the vector vecx). Thus, it will be convenient to make some string substitutions within the M-file; there is a useful command for this type of operation:


\begin{tabular}{|r|l|}
\hline 
  \begin{lstlisting}[frame=none, numbers=none]
  newstring=
  strrep(oldstring,'s1', 't1')
 				->
  \end{lstlisting}  
  
   &
   \begin{lstlisting}[frame=none, numbers=none] 
If oldstrin g is any character string and s1
and t1 are string portions, this command will
create another string newstrin g gotten by
replacing all occurrences of s1 by t1 .
	\end{lstlisting} \\
  \hline
\end{tabular} 
Here are some simple examples of the use of this command:

\begin{lstlisting}[frame=none, numbers=none] 
>> string = 'Jenny went out to dinner with Billy';strrep(string, 'to
dinner', 'dancing')
\end{lstlisting}
\mycode{->ans =Jenny went out dancing with Billy}
\begin{lstlisting}[frame=none, numbers=none] 
>> strrep ('t*cos (yp) + (y+2) Λ 2', 'yp', 'xvec (2) ') -> ans =t*cos(xvec(2))+(y+2)^2
\end{lstlisting}
String manipulations can be a useful skill in writing certain types of programs; to see a brief synopsis
of the numerous string related functions that MATLAB has, simply enter: help strfun . The
annotated M-file is boxed below:


\begin{lstlisting}[frame=single, numbers=none] 
function [t, y, nshots] = nonlinshoot(a, alpha, b, beta, fstring, fystring, fypstring, tol, hstep, mk)
%M-file for EFR 10.7
%This program will apply the non linear shooting method to
%solve the BVP: y''(t)=f(t,y,y'), y(a) = alpha, y(b) = beta
%Input variables: a = left endpoint, alpha = left boundary value
%b = right endpoint, beta = right boundary value, fscript = 
%inhomogeneity function, inputted as a script (in single quotes) with
%varriables t, y and yp (y'), the next two input variables are the
%partial derivatives of f(t, y, y') with respect to y and y' 
%tol = tolerance, a positive number. When successive approximations
%differ by less than tol at right endpoint, iterations stop. 
%hstep = the step size to use in the Runge-Kutta method
%m0 = initial (shooting) slope; if this variable is not inputted
%the default value for mO is (beta-alpha)/(b-a)
%Output variables: t and y, two same sized vectors containing the 
%time values and corresponding values of the numerical solution of
%the BVP, nshots, the number of iterations (shots) that were used in
%the nonlinear shooting method.
%This program internally will call on Program 9.2: rksys

%set default if necessary
if nargin < 10
	mk = (beta-alpha)/(b-a); 
end

%set up a vector-valued inline function for the 4 equation linear
%system that needs to be iteratively solved:
%Dy = yp, y(a)=alpha, Dyp = f(t,y,yp), yp(a) = mk
%Dz = zp, z(a)=0, Dzp = zfy(t,y,yp) + zpfyp(t,y,yp), zp(a) = 1
%fvec will have 4 components [Dy Dyp Dz Dzp] and will be an inline
%function of the 2 variables t (a number) and vec (a vector) 
% representing the four numbers y, yp, z, and zp in this order:
%vec(1) = y, vec(2) = yp, vec(3) = z, and vec(4) = zp
%we first change the inputted strings to conform to these new
variables:
fstring=strrep(fstring,'yp','vec(2)');
fstring=strrep(fstring,'y','vec(1)');
fystring=strrep(fystring,'yp','vec(2)');
fystring=strrep(fystring,'y','vec(1)');
fypstring=strrep(fypstring,'y','vec(1)');
fypstring=strrep(fypstring,'yp','vec(2)');
fvec = inline(['[vec(2) ',fstring, ' vec(4) ', 'vec(3)*(',
fystring, ')+... vec(4)*(', fypstring, ')]'], 't', 'vec'); 
%Note: Some of the blank spaces left above were intentional and
%important to separate the four components of this vector valued
%function.

%start iterative loop
nshots = 1;
while 1
	[t, X] =rksys(fvec, a, b, [alpha mk 0 1], hstep);
	y = X(:,1); z=Z(:,3);  %peel off the vectors we need
	Diff=y(length(y))-beta;
	if abs(Diff)<tol
	return
	end
	mk=mk-Diff/z(length(z)); nshots=nshots+1; %update slope and shot
counter
end
\end{lstlisting}

(b) The BVP of Example 10.4 is now easily solved with this program; we run it with the two
tolerances 0.01 and le-7 given in parts (a) and (b) of the example. 
\begin{lstlisting}[frame=none, numbers=none]
>>[t, y, n] = nonlinshoot(1,0,2,-2,'-2*(y*yp+t*yp+y+t)', ... 
			'-2*yp-2','-2*y - 2*t',0.01,0.01); n ->n=3
>>[t, y, n] = nonlinshoot(1,0,2,-2,'-2*(y*yp+t*yp+y+t)', ... 
			'-2*yp-2','-2*y - 2*t',1e-7,0.01);
>>n ->n=5
\end{lstlisting}
The number of shots agrees with what we had in that example, and the plots also agree (simply enter plot(t,y)) .
(c) In this BVP, we have $f\left(t, y, y^{\prime}\right)=t e^{y}-\sin (\cos (t)) y^{\prime}$. We will need $f_{y}\left(t, y, y^{\prime}\right)=t e^{y}$ and $f_{y^{\prime}}\left(t, y^{\prime}, y^{\prime}\right)=-\sin (\cos (t))$. Since $f_{y}$ is positive when $t$ is and $f_{y^{\prime}}$ is bounded, Theorem $10.1$ tells us that the BVP has a unique solution. If we try to use the nonlinear shooting program of part (a) to solve the problem numerically with a tolerance of $h=0.01$ (and the same Runge-Kutta step size), the program hangs, and actually enters into an infinite loop. To gain some insight on what has happened, we modify the program of part (a) so that it will display the variable Di $\mathrm{f}$ at each iteration (simply remove the semicolon at the end of the line that defines this variable). With this modification, here are the first several lines of output that we get:
\begin{lstlisting}[frame=none, numbers=none]
>> [t, y, n] = nonlinshoot(1,0,3,-1,'t*exp(y) sin(cos(t))*yp', ...
't*exp(y)', '-sin(cos(t)) ',1,0.01,0);
-> Diff = Inf, Diff = NaN, Diff = NaN, Diff = NaN, ...
\end{lstlisting}
We briefly explain what has happened. We let MATLAB choose the initial value of the slope $m k$ to be the default value $(y(3)-y(1)) /(3-1)=-1 / 2$. What has happened is that the resulting IVP blew up to infinity too quickly due to the potentially very large $te^{y}$ term present in the DE. Both $y$ and $z$ have become infinite at $t=3$, and in computing mk MATLAB needed to divide an infinite quantity by another. This forced $m k$ to be defined as $\mathrm{NaN}$ (not a number) and from that point on the iterations became meaningless and we entered into an infinite loop. It is not difficult to modify the program to force quit and give an appropriate error message in such an occurrence. Here, we simply experiment with different (more negative) initial values of $m k$ so as to prevent such blowing up. We have quickly found that if we use $m k=-2$, things work fine:

\begin{lstlisting}[frame=none, numbers=none]
>>[t, y, n] = nonlinshoot(1,0,3,-1,'t*exp(y)-sin(cos(t))*yp', ...
			  't*exp(y)', '-sin(cos(t))',.01,0.01,-2);
>>n ->n=3
>>[t, y, n] = nonlinshoot(1,0,3,-1,'t*exp(y)-sin(cos(t))*yp', ...
			  't*exp(y)', '-sin(cos(t))',1e-7,0.01,-2);
>>n ->n=5(only five shots needed.)
>>plot(t,y), grid on %plot is shown below 
\end{lstlisting}
\includegraphics[scale=0.8]{fig12}
\\The second plot shows the pathology just discussed, and why nonlinearity made it necessary to
"undershoot" the first shot, lest the solutions blow up in finite time. The code below constructs the
second plot (without the embellishments):

\begin{lstlisting}[frame=none, numbers=none]
>> f = inline('y',  't', 'x', 'y'); g = inline('t*exp(x)-...
			sin(cos(t))*y', 't','x','y');
>> clf, hold on
>> for mk=1:-.5:-4
	[t,x,y]=runkut2d(f,g,1,3,0,mk,0.01); plot(t,x)
end, axis([1 3 -2 2]) 
\end{lstlisting}



\textbf{\texttt{EFR 10.8:}}
Using Taylor's theorem, we obtain:
$$
\begin{gathered}
f(a+h)=f(a)+h f^{\prime}(a)+h^{2} f^{\prime \prime}(a) / 2+h^{3} f^{\prime \prime \prime}(a) / 6+O\left(h^{4}\right) \text {, and } \\
f(a-h)=f(a)-h f^{\prime}(a)+h^{2} f^{\prime \prime}(a) / 2-h^{3} f^{\prime \prime \prime}(a) / 6+O\left(h^{4}\right)
\end{gathered}
$$
From these we obtain that: $\frac{f(a+h)-2 f(a)+f(a-h)}{h^{2}}$
$$
\begin{gathered}
=\frac{f(a)+h f^{\prime}(a)+h^{2} f^{\prime \prime}(a) / 2+h^{3} f^{\prime \prime \prime}(a) / 6+O\left(h^{4}\right)-2 f(a)}{h^{2}} \\
-\frac{-\left[f(a)-h f^{\prime}(a)+h^{2} f^{\prime \prime}(a) / 2-h^{3} f^{\prime \prime \prime}(a) / 6+O\left(h^{4}\right)\right]}{h^{2}} \\
=\frac{2 h^{2} f^{\prime \prime}(a) / 2+O\left(h^{4}\right)}{h^{2}}=f^{\prime \prime}(a)+O\left(h^{2}\right)
\end{gathered}
$$,
as asserted.\\


\textbf{\texttt{EFR 10.9:}} Since each $p_{i}$ is a value of the function $p(t)$, we have $\left|p_{i} h / 2\right|<M(2 / M) / 2=1$. Therefore, each of the nondiagonal entries of $A$ is positive. Also, since each $q_{i}$ is positive, each diagonal entry $a_{k k}$ has absolute value greater than 2 , so it suffices to show that the sum of the absolute values of the nondiagonal entries of any row is less than or equal to 2 . Since all nondiagonal entries are positive they equal their absolute values. For the first and the last rows, there is only one nondiagonal entry which equals $1 \pm p_{i} h / 2<2$. For all other rows, the sum of the nondiagonal entries equals $1+p_{i} h / 2+1+p_{i} h / 2=2$. This completes the proof.\\


\textbf{\texttt{EFR 10.10:}}
If $v, w \in \mathcal{A}$ then both are continuous and so must be their sum $v+w$, as well as any scalar multiple $\alpha v$. Let $\mathscr{P}_{1}: 0=a_{0}<a_{1}<\cdots<a_{n+1}=1$ and $\mathscr{P}_{2}: 0=b_{0}<b_{1}<\cdots<b_{m+1}=1$ be two partitions of $[0,1]$ over which $v^{\prime}(x)$ and $w^{\prime}(x)$ are continuous, respectively. It follows that $(v+w)^{\prime}(x)=v^{\prime}(x)+w^{\prime}(x)$ is continuous with respect to the common refinement $\mathscr{P}_{1} \cup \mathscr{P}_{2}$ of these partitions, and this function is bounded by the sum of the bounds for $v^{\prime}(x)$ and $w^{\prime}(x)$. More easily, the function $\alpha v$ has a piecewise continuous derivative with respect to $\mathscr{P}$, and is bounded by $|\alpha|$ times the corresponding bound for $v^{\prime}(x)$. Finally since both of the functions $v, w$ vanish at $x=0$ and $x=1$, so must the two functions: $v+w$ and $\alpha v$, and we have thus proved that these latter two functions satisfy all of the requirements for membership in $\mathcal{A}$.\\



\textbf{\texttt{EFR 10.11:}}
The proof of the last EFR easily translates over to prove this result. The only change needed here is that the sum of two piecewise linear functions will also be piecewise linear (with respect to the common refinement partition).\\



\textbf{\texttt{EFR 12.12:}}
(a) The proof we give works for any set of basis functions $\left\{\varphi_{i}(x)\right\}_{i=1}^{n}$ that are continuous, piecewise differentiable, and vanish at the endpoints $x=0$ and $x=1$. Since $a_{i j}=\left\langle\varphi_{i}^{\prime}, \varphi_{j}^{\prime}\right\rangle=\int_{0}^{1} \varphi_{i}^{\prime}(x) \cdot \varphi_{j}^{\prime}(x) d x$, we can use linearity of integration to write:
$$
\begin{aligned}
&c^{\prime} A c=\left[c_{1}, c_{2}, \cdots, c_{n}\right] \cdot\left[\sum_{j=1}^{n} a_{1 j} c_{j}, \sum_{j=1}^{n} a_{2 j} c_{j}, \cdots, \sum_{j=1}^{n} a_{n j} c_{j}\right] \\
&=\left[c_{1}, c_{2}, \cdots, c_{n}\right] \cdot\left[\sum_{j=1}^{n} \int_{0}^{1} \varphi_{1}^{\prime}(x) \varphi_{j}^{\prime}(x) d x c_{j}, \sum_{j=1}^{n} \int_{0}^{1} \varphi_{2}^{\prime}(x) \varphi_{j}^{\prime}(x) d x c_{j},\right. \\
&=\left[c_{1}, c_{2}, \cdots, c_{n}\right] \cdot\left[\int_{0}^{1}\left(\varphi_{1}^{\prime}(x) \cdot \sum_{j=1}^{1} c_{j} \varphi_{n}^{\prime}(x) \varphi_{j}^{\prime}(x) d x c_{j}\right] d x, \int_{0}^{1}\left(\varphi_{2}^{\prime}(x) \cdot \sum_{j=1}^{n} c_{j} \varphi_{j}^{\prime}(x)\right) d x, \int_{0}^{1}\left(\varphi_{n}^{\prime}(x) \cdot \sum_{j=1}^{n} c_{j} \varphi_{j}^{\prime}(x)\right) d x\right] \\
&=\sum_{i=1}^{n} c_{i} \cdot \int_{0}^{1}\left(\varphi_{i}^{\prime}(x) \cdot \sum_{j=1}^{n} c_{j} \varphi_{j}^{\prime}(x)\right) d x \\
&=\int_{0}^{1}\left(\sum_{i=1}^{n} c_{i} \varphi_{i}^{\prime}(x) \cdot \sum_{j=1}^{n} c_{j} \varphi_{j}^{\prime}(x)\right) d x \\
&=\int_{0}^{1}\left(\sum_{i=1}^{n} c_{i} \varphi_{i}(x)\right)^{\prime} \cdot\left(\sum_{j=1}^{n} c_{j} \varphi_{j}(x)\right)^{\prime} d x .
\end{aligned}
$$
We have shown that $c^{\prime} A c=\left\langle\Phi^{\prime}, \Phi^{\prime}\right\rangle$, where $\Phi=\sum_{i=1}^{n} c_{l} \varphi_{i}(x)$ so that $c^{\prime} A c \geq 0$. Next assume that $c^{\prime} A c=0$. By positive definiteness of the inner product, we may conclude that $\Phi^{\prime}(x)=0$ at all values of $x$ except for the finite set of points where at least one of the $\varphi_{i}^{\prime}(x)$ is not continuous. Since $\Phi$, being admissible, vanishes at the endpoints, it follows that $\Phi(x)=0$ for all $x$. But by linear independence of $\left\{\varphi_{i}(x)\right\}_{i=1}^{n}$, this forces the vector $c$ to be zero. This completes the proof that the stiffness matrix is positive definite.
\\(b) In case of equal grid spacing $h_{i}=h$, by (38) and (39), the main diagonal entries of the stiffness matrix are all equal to $2 / \mathrm{h}$, while the super and sub diagonal entries of this tridiagonal matrix equal $-1 / \mathrm{h}$. Note that when the DE of $(24)$ is put into form $(5)$, we have $p=q=0$, and $r(x)=-f(x)$. The linear systems $A x=b$, for the two methods are compared below:


\begin{center}
\begin{tabular}{|r|l|}
  \hline 
  Linear Rayleigh-Ritz:
\begin{math}
\begin{gathered}
A^{R R}=(1 / h)\left[\begin{array}{ccccc}
2 & -1 & & &\\
-1 & 2 & -1 & \\
& -1 & 2 & 0 & \\
& 0 & & \ddots & -1 \\
& & & -1 & 2
\end{array}\right], \\
b^{R R}=\left[\begin{array}{c}
\left\langle f, \phi_{1}\right\rangle \\
\left\langle f, \phi_{2}\right. \\
\left\langle f, \phi_{3}\right\rangle \\
\vdots \\
\left\langle f, \phi_{n}\right\rangle
\end{array}\right]
\end{gathered}
\end{math}

   & 
   
  Finite Difference:
\begin{math}
\begin{gathered}
A^{F D}=\left[\begin{array}{ccccc}
-2 & 1 & & \\
1 & -2 & 1 & \\
& 1 & -2  & 0 \\
& 0 & & \ddots & 1 \\
& & & 1 & -2
\end{array}\right] \\
b^{F D}=h^{2}\left[\begin{array}{c}
-f(h) \\
-f(2 h) \\
-f(3 h) \\
\vdots \\
-f([n-1] h)
\end{array}\right]
\end{gathered}
\end{math}\\
  \hline
\end{tabular} 
\end{center}
If we multiply the left linear system by $h$ and the right one by $-1$, then the matrices equate, and the ith term of the inhomogeneities on the right sides become $h\left\langle f, \phi_{i}\right\rangle=h \int_{0}^{1} f(x) \phi_{i}(x) d x$ and $h^{2} f(i h)$, respectively. By the mean value theorem for integrals, we can write $\int_{0}^{1} f(x) \phi_{i}(x) d x$ $=f\left(\tilde{x}_{i}\right) \int_{0}^{1} \phi_{i}(x) d x$, where $\tilde{x}_{i}$ is some number inside the interval $[i h-h, i h+h]$ (on which the hat function $\phi_{1}(x)$ lives). But (from Figure 10.11, for example), $\int_{0}^{1} \phi_{i}(x) d x=h$, so we may conclude that $h\left\langle f, \phi_{i}\right\rangle=h^{2} f\left(\tilde{x}_{i}\right)$, which now looks a lot like $h^{2} f(i h)$. Thus the finite difference linear system looks very close to the linear Rayleigh-Ritz system. The latter uses an averaging process to measure $f(x)$ on each subinterval, whereas the former simply takes a point value.



\textbf{\texttt{EFR 12.13:}}
With any linearly independent set of basis functions $\left\{\phi_{k}(x)\right\}_{k=1}^{n}$ the Galerkin method for the BVP gives the numerical solution $u=\sum_{k=1}^{n} c_{k} \phi_{k}(x)$ where the coefficients are determined by the matrix equation (36): $\sum_{j=1}^{n}\left\langle\phi_{k}^{\prime}, \phi_{j}^{\prime}\right\rangle c_{j}=\left\langle f, \phi_{k}\right\rangle(1 \leq k \leq n)$. Since $\phi_{k}(x)=\sin (k \pi x)$ we have $\phi_{k}^{\prime}(x)=k \pi \cos (k \pi x)$, and we can use the angle addition formulas for sine and cosine from trig (or appeal to the Symbolic Toolbox) to verify the following orthogonality relations:
$$
\left\langle\phi_{k}^{\prime}, \phi_{j}^{\prime}\right\rangle= \begin{cases}k^{2} \pi^{2} / 2, & \text { if } j=k \\ 0, & \text { if } j \neq k\end{cases}
$$
Thus, the stiffness matrix is a diagonal matrix, and the system is very easy to solve: $c_{k}=2\left\langle f, \phi_{k}\right\rangle /\left(\pi^{2} k^{2}\right)$ so we need only actually compute $\left\langle f, \phi_{k}\right\rangle$. As a slightly different approach to what was used in the solution of Example 10.7, we solve these equations using a "for loop" with internally constructed inline functions. This approach may seem simpler to program but it uses more resources since a new (and complicated) function needs to be constructed at each iteration. The size of this problem is small enough so that computing time will not be a consideration.
To compare with the solution obtained in Example 10.7, we compute this Galerkin solution using the same vector $x$ of 52 equally spaced points in $[0,1]$. The following code computes the corresponding $y$ coordinates, and plots the two graphs along with the error (we assume that the code of Example $10.7$ has been run in this session and the solution was again plotted).
\begin{lstlisting}[frame=none, numbers=none]
>> xG = linspace(0,1,52);
for k=1:50
	kst = num2str(k,2); 
fphik = inline (['sin(sign(x-.5).*exp(1./(4*abs(x-.5).^1.05+.3))).*...
exp(1./(4*abs(x- .5).^1.2+.2)-100*(x-.5).^2).*sin(', kst, 'pi*x)']);
cG(k)=2*quad1(fphik,0,1)/pi^2/k^2;
end
>> y = zeros(size(x));
>> for k=1:50
	y = y + cG(k)*sin(k*pi*x);	
end
>> hold on, plot(x,y), plot(x,abs(c-y),'rx')
\end{lstlisting}
\mycode{The graph on the left shows the three plots. Since for this example, the Rayleigh-Ritz method is exact,
the red error graph is actually the error for the Galerkin method. To see it better, we plot it separately
on the right, having used the following commands:}
\begin{lstlisting}[frame=none, numbers=none]
>> hold off, plot(x, abs(c-y), 'r-x'), title('Galerkin Error')
\end{lstlisting}

\begin{center}
\includegraphics{fig13}
\end{center}

\mycode{The error of the Galerkin method is relatively large in the middle portion. This is to be expected due to
the highly oscillatory behavior of f in this region. We could attain better accuracy, of course, by using
a larger value of n.}\\



\textbf{\texttt{EFR 10.14:}}
(a) First observe that the since w satisfies the BC of (42a), the function $u(x) \equiv$ $w(x)-(1-x) \alpha-\beta x$ satisfies the $\mathrm{BC}$ of $(42): u(0) \equiv w(0)-\alpha=0$ and $u(1) \equiv w(1)-\beta=0$. Next we compute the left side of the DE of (42): $-\left(p u^{\prime}\right)^{\prime}+q u=-\left(p\left(w^{\prime}-(\alpha-\beta)\right)\right)^{\prime}+q(w-(1-x) \alpha-\beta x)$ $=-\left(p^{\prime}\left(w^{\prime}-(\alpha-\beta)\right)\right)-p w^{\prime}+q w-(1-x) \alpha q-\beta q x=-p^{\prime} w^{\prime}-p^{\prime} w^{\prime \prime}+q w+(\alpha-\beta) p^{\prime}-(1-x) \alpha q-\beta q x$ $=-\left(p w^{\prime}\right)^{\prime}+q w+F(x)=f(x)+F(x)$, where $F(x) \equiv p^{\prime}(\alpha-\beta)-(1-x) \alpha q-\beta x q$. Thus $u(x)$ satisfies the BVP (42) with $f(x)$ being replaced by $f(x)+F(x)$.
\\(b) Define $\bar{w}(x)=w(t)=w(a+x(b-a))$, and similarly define $\bar{p}(x)=p(t)$, and in the same fashion the functions $\bar{q}(x)$, and $\bar{f}(x)$. By the chain rule, we can write $\bar{w}^{\prime}(x)=(b-a) w^{\prime}(t)$ and $\bar{w}^{\prime \prime}(x)=(b-a)^{2} w^{\prime \prime}(t)$ where the derivatives of the barred function are with respect to $x$ and those of the unbarred function are with respect to $t$. The same derivative relationships hold, of course, for the other matching pairs of barred and unbarred functions. If we take the $D E$ of $(42 b)$, and change variables from $t$ to $x$, we obtain:
$$
\begin{aligned}
-\left(p(t) w^{\prime}(t)\right)^{\prime}+q(t) w(t)=f(t) \Rightarrow &-p^{\prime}(t) w^{\prime}(t)-p(t) w^{\prime \prime}(t)+q(t) w(t)=f(t) \\
& \Rightarrow-\frac{\bar{p}^{\prime}(x)}{b-a} \frac{w^{\prime}(x)}{b-a}-\bar{p}(x) \frac{\bar{w}^{\prime}(x)}{(b-a)^{2}}+\bar{q}(x) \bar{w}(x)=\bar{f}(x) \\
& \Rightarrow-\bar{p}^{\prime}(x) \bar{w}^{\prime}(x)-\bar{p}(x) \bar{w}^{\prime \prime}(x)+(b-a)^{2} \bar{q}(x) \bar{w}(x)=(b-a)^{2} \bar{f}(x) \\
& \Rightarrow-\left(\bar{p}(x) \bar{w}^{\prime}(x)\right)^{\prime}+\bar{Q}(x) \bar{w}(x)=\bar{F}(x),
\end{aligned}
$$
where $\bar{Q}(x)=(b-a)^{2} \bar{q}(x)$ and $\bar{F}(x)=(b-a)^{2} \bar{f}(x)$. Thus the function $\bar{w}(x)$ satisfies a BVP of the form (42a).\\

\textbf{\texttt{EFR 10.15:}} (a) The M-file is boxed below:
\begin{lstlisting}[frame=single, numbers=none]
function [x,u] = rayritz(p, q, f, n)
% This program will implement the piecewise linear Rayleigh-Ritz
% method to solve the BVP: -(p(x)u'(x))*+q(x)u(x)=f(x), u(0)=0,
% u(1)=0. The integral approximations (48) through (50) of Chapter
% 10 will be used. Input variables: the first three: p, q and f are
% inline functions representing the the DE, n = the number of
% interior x-grid values to employ. A uniform grid is used.
% NOTE: The program is set up to require that the functions p, q,
% and f take vector arguments.
% Output variables: x and u are same sized vectors representing the
% x grid and the numerical solution values respectively

x=linspace(0,1,n+2); h = x(2)-x(1);
% Use (48) and (49) of Chapter 10 to assemble diagonals of the
% symmetric tridiagonal stiffness matrix:
d = 1/(2*h)*(feval(p, x(1:n))+2*feval(p, x(2:n+1))+feval(p, ...
x(3:n+2)))+ h/12*(feval(q, x(1:n))+6*feval(q, x(2:n+1))+ ...
fevaKq, x(3:n+2)));
% for off diagonals
offdiag= -1/(2*h)*(feval(p,x(2:n))+feval(p,x(3:n+1)))+...
h/12*(feval(q,x(2:n))+feval(q,x(3:n + 1))) ;
% by symmetry and to conform to syntax of 'thomas.m'
da = [offdiag 0]; %above diagonal
db = [0 offdiag]; %below diagonal

% Use (50) of Chapter 10 to construct vector b
b = h/6*(feval(f,x(1:n))+4*feval(f,x(2:n+1))+feval(f,x(3:n+2)));

% Use the Thomas method to solve the system Au=b and get solution
u = thomas(da,d,db,b);
u = [0 u 0]; %adjoin boundary values 
\end{lstlisting}
(b) With the program above, the task is easily completed. We first store the coefficient functions for the $D E$ (capable of taking vector inputs as stipulated in the notes of the code in part (a)), next we obtain the first three numerical solutions and then we look at successive differences on common $x$-grid values. Note that, for example, in passing from $\times 1$ to $\times 2$, since the step size is getting cut in half, the first internal grid value for $x 1$ (in MATLAB notation $\times 1(2)$ ) will be the second internal grid value for $x 2$, (in MATLAB notation $\times 2(3)$ ) and, hereafter, the indices of successive internal grid values for $x 1$ will jump by 2 's when looked at as indices of $\times 2$.




\begin{lstlisting}[frame=none, numbers=none]
>> p = inline('ones(size(x))'); q = inline('6*ones(size(x))');
>> f = inline(,
exp(10*x).*cos(12*x)');
>> [x1, y1] = rayritz(p,q,f,99) ;
>> [x2, y2] = rayritz(p,q,f, 199) ;
>> size(y1), size(y2) %Check the sizes of the vectors
->ans=1 101, ans = 1 201
>> max(abs(y 1 (2:100)-y 2 (3:2:200 ) ))->ans= 0.1019
>> 1x3, y3] = rayritz(p,q , f,399) ;
>> size(y3)->ans= 1 401
>> max (abs (y2 (2 : 200) -y 3 (3:2 : 400) )) ->ans = 0.0255
The following loop will now continue such iterations until the error of these successive differences
gets less than 5e-5:
>> ynew = y3 ; coun t =3 ;
>> while Error > 5e-5
yold = ynew; count = count +1, numx = 2*numx;
[xnew, ynew] = rayritz(p,q,f,numx-1); Error = max(abs(yold(2:numx/2)-
ynew(3:2:numx)))
end
-> count =4, Error = 3.9833e-004
count =5, Error = 9.9578e-005
count =6, Error = 2.4896e-005 
\end{lstlisting}
From the results we see that the difference of y6=ynew and y5 is less than 5e-5. We now get the
exact error of y 6 by invoking the Symbolic Toolbox to solve the DE exactly (as in the example):
\begin{lstlisting}[frame=none, numbers=none]
>> yexact=dsolve('-D2y+6*y=exp(10*t)*cos(12*t) ', 'y(0)= 0 ', 'y(1)=0') ;
>> Yexac t = double(subs(yexact,xnew));
>> max(abs(Yexact-ynew)) ->ans= 8.3034e-006
\end{lstlisting}
Thus the successive differences turned out to give a good predictor of when we should stop the iteration
process to meet the desired error goal. In the absence of exact solutions, this technique is used quite
often in practice.

\textbf{\texttt{EFR 10.16:}} (a) Condition (i) states that we can write:
$$
B S(x)= \begin{cases}a_{1} x^{3}+b_{1} x^{2}+c_{1} x+d_{1}, & \text { if } x \in[-2,-1], \\ a_{2} x^{3}+b_{2} x^{2}+c_{2} x+d_{2}, & \text { if } x \in[-1,0], \\ a_{3} x^{3}+b_{3} x^{2}+c_{3} x+d_{3}, & \text { if } x \in[0,1], \\ a_{4} x^{3}+b_{4} x^{2}+c_{4} x+d_{4}, & \text { if } x \in[1,2] .\end{cases}
$$
The will show that the 16 parameters $a_{i}, b_{i}, c_{i}, d_{i}$ will be uniquely determined by the other three conditions. Our strategy will be to first take all opportunities to either solve or eliminate any parameters, and then for the parameters that remain we will determine them by solving a linear system. Condition (ii) at the internal node $x=0$, gives that $d_{2}=d_{3}, c_{2}=c_{3}$, and $b_{2}=b_{3}$. The interpolation requirement that $\mathrm{BS}(0)=1$ tells us that $d_{2}=d_{3}=1$. We now use the remaining conditions to obtain 12 linear equations for the remaining 12 parameters: $a_{1}, b_{1}, c_{1}, d_{1}, a_{2}, b_{2}, c_{2}, a_{3}, a_{4}, b_{4}, c_{4}, d_{4}$. From (ii), we get the following six linear equations:
(continuity of BS at $-1$ ):
$$
-a_{1}+b_{1}-c_{1}+d_{1}=-a_{2}+b_{2}-c_{2}+1 \text {, (and at 1) } a_{3}+b_{2}+c_{2}+1=a_{4}+b_{4}+c_{4}+d_{4} \text {. }
$$
(continuity of $\mathrm{BS}^{\prime}$ at -1):
$$
3 a_{1}-2 b_{1}+c_{1}=3 a_{2}-2 b_{2}+c_{2} \text {, (and at 1) } 3 a_{3}+2 b_{2}+c_{2}=3 a_{4}+2 b_{4}+c_{4} \text {. }
$$
(continuity of $\mathrm{BS}^{\prime}$ at $-1$ ):
$$
-6 a_{1}+2 b_{1}=-6 a_{2}+2 b_{2} \text {, (and at 1) } 6 a_{3}+2 b_{2}=6 a_{4}+2 b_{4}
$$
From (iii) we get two equations:
$$
(\mathrm{BS}(-2)=0):-8 a_{1}+4 b_{1}-2 c_{1}+d_{1}=0, \quad(\mathrm{BS}(2)=0) 8 a_{4}+4 b_{4}+2 c_{4}+d_{4}=0 .
$$
From (iv) we get the remaining 4 equations:
$$
\begin{gathered}
\left(\mathrm{BS}^{\prime}(-2)=0\right) \quad 12 a_{1}-4 b_{1}+c_{1}=0, \quad\left(\mathrm{BS}^{\prime}(2)=0\right) 12 a_{4}+4 b_{4}+c_{4}=0, \\
\left(\mathrm{BS}^{\prime}(-2)=0\right)-12 a_{1}+2 b_{1}=0 \text {, and }\left(\mathrm{BS}^{\prime}(2)=0\right) 12 a_{4}+2 b_{4}=0 .
\end{gathered}
$$
\newline
Moving all variables to the lefl side and numbers to the right (and using the order of the 12 parameters listed above), leads to a matrix equation (for the 12 parameters represented by the vector $x$ ); $A x=b$. We now use MATLAB to enter $A$ and $b$ and then to solve the system:


\begin{lstlisting}[frame=none, numbers=none]
A = zeros(12); b=zeros(12,1); A(1,[1 3 6])=-1; A(1,[2 4 5 7])=1;
b(1)=1; A(2,[8 6 7])=1; A(2,[9 10 11 12])=—1; b(2)=-1; A(3,1)=3;
A(3,2)=—2; A(3,3)=1; A(3, 5)=-3; A(3,6)=2; A(3,7)=-1; A(4,8)=3;
A(4,6)=2; A(4,7)=1; A(4, 9)=-3; A (4, 10)=-2; A(4,11)=-1; A(5,1)=-6;
A(5,2)=2; A(5,5)=6; A(5,6)=-2; A(6,8)=6; A(6,6)=2; A(6,9)=-6;
A(6,10)=-2; A(7,1)=-8; A(7,2)=4; A(7,3)=-2; A(7,4)=1; A(8,9)=8;
A(8,10)=4; A(8,11)=2; A(8,12)=1; A(9,1)=12; A(9,2)=-4; A(9,3)=1;
A(10,9)=12; A(10,10)=4; A(10,11)=1; A(11,1)=-12; A(11,2)=2;
A(12,9)=12; A(12,10)=2; 
>> format long
>> x=A\b; x, format rat, x
->x =		0.25000000000000		1/4
			1.50000000000000		3/2
			3.00000000000000		3
			2.00000000000000		2
			-0.75000000000000		-3/4
			-1.50000000000000		-3/2
			-0.00000000000000		-1/4503599627370498
			0.75000000000000		3/4
			-0.25000000000000		-1/4
			1.50000000000000		3/2
			-3.00000000000000		-3
			2.00000000000000		2
\end{lstlisting}
(The very small fraction in the second column is just roundoff error.) From these coefficients, we can express $\mathrm{BS}(x)$ as follows:

\begin{math}B S(x)= \begin{cases}\frac{1}{4} x^{3}+\frac{3}{2} x^{2}+3 x+2, & \text { if } x \in[-2,-1]   -\frac{3}{4} x^{3}-\frac{3}{2} x^{2}+1, \quad \text { if } x \in[-1,0]\\ \frac{3}{4} x^{3}-\frac{3}{2} x^{2}+1, & \text { if } x \in[0,1]    -\frac{1}{4} x^{3}+\frac{3}{2} x^{2}-3 x+2, \text { if } x \in[1,2]\end{cases}\end{math}

It is readily checked (by hand or with the Symbolic Toolbox) that these formulas agree with the corresponding ones in the formula stated in the text.
(b) We create an M-file for the function $\mathrm{BS}(x)$ : the following code oroduced the plot on the right.\\
\begin{tabular}{|r|l|}
  \hline 
\begin{lstlisting}[frame=none, numbers=none]
function y = BSSpline(x)
%Basic cubic spline function
of %
%Chapter 10, (51),built to
accept %vector arguments.
for i=1:length(x)
	if x(i)>=0 & x(i)<=1
		y(i)=((2-x(i))^3-4*(1-
χ(ί))^3)/4;
	elseif x(i)>1 & x(i)<=2
		y(i) = (2-x(i))^3/4;
	elseif x(i)>2
		y(i)=0;
	else, y(i) = BSSpline(-
x(i));
	end
end }
\end{lstlisting}

 &  
 \includegraphics{fig14}
\\
  \hline
\end{tabular} 

\begin{lstlisting}[frame=none, numbers=none]
>> x=-5:.01:5; plot(x,BSSpline(x)), grid on
>> axis([-3 3 -.5 1.5]), title('Basic Cubic Spline') 
\end{lstlisting}

\textbf{\texttt{EFR 10.17:}}

\begin{minipage}[t]{0.45\textwidth}
It is perhaps more helpful to do part (b) first, so we can get an idea of the functions that we need to answer some questions about. We proceed in this way. Using formula (52) in conjuction with the Mfile for the basic cubic spline $B S(x)$ constructed in the preceding EFR, the following code will produce the plots of the cubic spline basis functions when $n=5$ (shown on the right):\\
\begin{lstlisting}[frame=none, numbers=none]
>> x=-5:.01:5 ;
>> n=5; h=1/(n+1) ;
>> x=linspace(0,1,n+2)
>> t=0:.01:1 ;
>> phil=BSSpline((t-h)/h) - .. .
BSSpline((t+h)/h) ;
>> phi2=BSSpline((t-2*h)/h)(
>> phi3=BSSpline((t-3*h)/h) ;
>> phi4=BSSpline((t-4*h)/h)j
\end{lstlisting}
\end{minipage}
\begin{minipage}[i]{0.55\textwidth}
 \includegraphics{fig15}
\end{minipage}
Note: On MATLAB's graphics window, we used the "Axis Properties" subwindow from the "Edit" menu to change the $x$-axis tick marks to be at $0,1 / 6,2 / 6, \ldots$ and changed the corresponding labels to $x 0$ $=0, x 1, x 2, \ldots$

All of the properties stated about the cubic spline basis functions, except their linear independence, are directly inherited from those of $\mathrm{BS}(x)$. Linear independence will take a bit more work to show than for the hat functions, but is not very difficult since the supports of the cubic spline basis functions (i.e., the intervals on which they are nonzero) do not have much overlap. Indeed, assume that for a fixed $n$, we have (*) $\sum_{i=1}^{n} c_{i} \phi_{i}(x) \equiv 0$ (for all $x$ in $[0,1]$ ) for some constants $c_{i} \ldots$ We must show that $c_{i}=0$ for each $i$. Consider first $x$ to be in the interval $[0, x 1]$. Here, only the first two $\phi$ 's are nonzero, so (*) becomes $c_{1} \phi(x)+c_{2} \phi_{2}(x) \equiv 0$. If either of $c_{1}$ or $c_{2}$ were nonzero, then we could solve for the corresponding $\phi_{r}$ in terms of being a constant multiple of the other one. This is clearly not possible, since (among many other reasons, just look at the picture) one of them has a zero derivative at $x=x$ l and the other does not. Consequently we may conclude that $c_{1}=c_{2}=0$. The rest is now easy: On the next interval $[\times 2, x 3]$, only $\phi_{1}, \phi_{2}$ and $\phi_{3}$ can be nonzero, but since we know already $c_{1}=c_{2}=0$, $(*)$ becomes $c_{3} \phi_{3}(x) \equiv 0$ and this certainly forces $c_{3}=0$. We may continue this argument moving one new interval to the right at each step and concluding the successive $c_{i}$ 's must be zero. This completes the linear independence proof.\\



\noindent\hrulefill\\
\textbf{CHAPTER 11: INTRODUCTION TO PARTIAL DIFFERENTIAL EQUATIONS}\\
\textbf{\underline{EFR 11.1:}}\texttt{linespace(-2,3,11)} \\
\text { (a) \& (b): }: We do the plots only for surf; to create corresponding mesh plots simply
replace all occurrences of su r f below by mesh. 
\begin{lstlisting}[frame=none, numbers=none]
>> x=linspace(-5,5,30); y=x; [X,Y]=meshgrid(x, y) ;
>> Z=sin(X)*sin(Y)*exp(-sqrt(X.^2+Y.^2)/4);
>> surf(x,y,Z)
>> xlabel('x-values'), ylabel('y-values'), zlabel('z-values')
>> grid off %default view shown below left
>> view(90,0) %view from positive x-axis, shown below right
>> view(45, -30) %view shown from 30 degrees below xy-plane, shown on
>>									 %top of next page
\end{lstlisting}
\begin{center}
\includegraphics{fig16}
\end{center}


\begin{minipage}[t]{0.45\textwidth}

\begin{lstlisting}[frame=none, numbers=none]
>> Z=sin(Y+cos(X));
>> clf
>> surf(x,y,Z)
>> xlabel('x-values') ,
ylabel('y-values'), zlabel('z-
values')
>> grid off %default view,
shown below left
>> view(80,20) %view from 10
degrees from pos. x-axis and
20 degrees below xy-plane,
%shown below right
>> view(45, 80) %View from 80
degrees above xy-plane, shown
at bottom.
\end{lstlisting}
\end{minipage}
\begin{minipage}[i]{0.55\textwidth}
 \includegraphics{fig17}
\end{minipage}

\begin{center}
\includegraphics{fig18}
\end{center}

\textbf{\underline{EFR 11.2:}}\texttt{linespace(-2,3,11)} \\
Let $L[u]$ denote the operator on the left side of (11). That $L$ is a linear operator follows from the fact that partial derivatives are linear operators. For example, consider just the second term of $L[u]$, call this $S[u]=b(x, y) u_{x y}$. Since derivatives of sums equal the sums of the derivatives, we have, $S[u+v]=b(x, y)[u+v]_{x y}=b(x, y)\left(u_{x y}+v_{x y}\right)=b(x, y) u_{x y}+b(x, y) v_{x y}=S[u]+S[\mathrm{v}]$. Since the same is true for each term of $L[u]$, it follows that $L[u+v]=L[u]+L[v]$. Similarly, since constants can be
pulled out of derivatives: for any constant $c$ we have $S[c u]=b(x, y)[c u]_{x y}=c b(x, y) u_{x y}=c S[u]$, and because this is true for each term of $L[u]$, we get in the same fashion that $L[c u]=c L[u]$. Thus $L[u]$ is indeed a linear operator.

\textbf{\underline{EFR 11.3:}}\texttt{linespace(-2,3,11)} \\
Computing the partial derivates directly (or using the Symbolic Toolbox), we get the following expressions for $\Delta u$ :\\
(a) $\Delta u=0+0=0$ so $u$ is harmonic (same for any linear function).\\
(b) $\Delta u=2+2=4 \neq 0$ so $u$ is not harmonic.\\
(c) $\Delta u=2-2=0$ so $u$ is harmonic.\\
(d) $u(x, y)$ is only defined if $(x, y) \neq 0$ and in this region we have\\
$$
\Delta u=\left[\frac{2}{x^{2}+y^{2}}-\frac{4 y^{2}}{\left(x^{2}+y^{2}\right)}\right]+\left[\frac{2}{x^{2}+y^{2}}-\frac{4 x^{2}}{\left(x^{2}+y^{2}\right)}\right]=0 \text {, }
$$
so $u(x, y)$ is harmonic on its domain.



\textbf{\underline{EFR 11.4:}}\texttt{linespace(-2,3,11)} \\

\begin{multicols}{2}

(a) Following the method and using the notation of Example 11.5, we skim through the details for the present example. Using (21)
$$
4 u_{i, j}-u_{i+1, j}-u_{i-1, j}-u_{i, j+1}-u_{i, j-1}=-h^{2} q_{i, j},
$$
we can write the 16 equations for the 16 unknown functional values; here are several of them (refer to the figure on the right):

Examining this linear system shows that the coefficient matrix $A$ of the linear system to be solved $(A U=C)$ has exactly the same form as the one in the solution of Example 11.5, except now its size is $16 \times 16$. As in (19), we introduce vectors $L, R, B$, and $T$ for the boundary data. It is also convenient to\\
\begin{center}
\includegraphics[scale=0.8]{fig20}
\end{center}


\begin{center}
\includegraphics{fig19}
\end{center}
introduce a length 16 vector $Q$ whose values are the internal $q_{i, j}$-values given in the reading order (with the same relationship U has to $u_{i, j}$ ). Invoking
MATLAB's index notation, the vector $C$ of the system can be read off from the linear system on the left to take the following form:
$$
\begin{aligned}
C=&-h^{2} Q+[L(5)+T(2)\\
& T(3), T(4), R(5)+T(5) \\
& L(4), 0,0, \quad R(4), L(3) \\
& 0,0, R(3), L(2)+B(2), \ldots \\
&B(3), B(4), R(2)+B(5)]^{\prime}
\end{aligned}
$$
Based on the above development, the following code will find the associated finite difference solution and create a surface plot of it.
\end{multicols}

\begin{lstlisting}[frame=none, numbers=none]
%EFR11_4 
%Script for solving the Poisson problem of EFR 11_4a 
N=4; M=4; h = 1/(N+1); x=linspace(0,1,N+2); y=x; A=4*eye(N^2);
%form sub/super diagonals
alrep=[0 -1 -1 -1] ; a1=[-1 -1 -1] ; 
for i=1:3, a1=[a1 alrep]; end, a4=-1*ones(1,12); 
%put these diagonal entries on A
A=A+diag(a1,-1)+ diag(a1,1)+diag(a4,-4)+diag(a4,4); 
% key in vectors for boundary values: 
L = zeros(size(y)); R = L; B = sin(pi*x); T = B/exp(2);
% Now (for the most complicated part), we construct the vector C 
% First we construct a row vector for Q arising from the source term: 
% We do this by creating an inline function for the inhomogeneity and 
% then collecting the needed entries in the required reading order 
% (using an appropriately designed loop). 
q=inline('3*exp(-2*y).*sin(pi*x)', 'x', 'y')
row = 1; 
for j-5:-1:2
	count=(row-1)*4+1; 
	Q (: ,count:count + 3)=q(x(2:5),y(j)); row = row+1;
end
%By combining with the appropriate boundary values, we now construct 
C: 
C= -h^2 *Q + [L(5)+T(2) T(3) T(4) R(5)+T(5) L(4) 0 0 R(4) L(3) 0 0...
	R(3) L(2)+B(2) B(3) B(4) R(2)+B(5)]; C=C ; 
%Now we are ready to solve the system, form the mesh, and plot
U=A\C; Z=zeros(4); Z(:)=U; Z=Z'; Z=(T(2:5); Z; B(2:5)]; 
for i=1:6, Lrev(i)=L(7-i); end 
Z=(Lrev; Z'; R]';
for 1=1:6, yrev(i)=y(7-i); end 
surf(x, yrev ,Z) , xlabel('x-values'), ylabel('y-values'), zlabel('u-
values')
\end{lstlisting}
\mycode{The plot is the left-hand one shown below.}\\
\begin{center}
\includegraphics[scale=0.65]{fig21}
\end{center}

\begin{lstlisting}[frame=none, numbers=none]
[X, Y] = meshgrid(x,yrev); 
Zexact=exp(-2*Y).*sin(pi*X); 
Max_Error = max(max(abs(Z(2:N+1,2:N+1)-Zexact(2:N+1,2:N+1)))) 
Max_Relative_Error = max(max(abs(Z(2:N+1,2:N+1)-... 
Zexact(2:N+1,2:N+1) )./abs(Zexact (2:N+1,2:N+1)))) 
	0.2064 
->Max_Error = 0.2064
->Max_Relative_Error = 0.5891
\end{lstlisting}

(c) The above code is easily modified to deal with the finer grid. We give it in a slightly more general 
context than was presented in part (a) and we omit the comments to save space. The resulting plot is 
the one on the above right. 

\begin{lstlisting}[frame=none, numbers=none]
N=8; M=8; h = 1/ (N1l); 
x=linspace(0,1,N+2); y=x;
A=4*eye(N^2); 
alrep=[0 -1 -1 -1 -1 -1 -1 -1]; 
a1=[-1 -1 -1 -1 -1 -1 -1]; 
for i=1:7, a1=[a1 alrep]; end 
aN=-1*ones(1,N^2-N); 
A=A+diag(a1,-1)+ diag (a1,1)+diag(aN,-N)+diag(aN,N); 
L = zeros(size(y)); R = L; 
B = sin(pi*x); T = B/exp(2);
q=inline('(4-pi^2)*exp(-2*y).*sin(pi*x)', 'x', 'y') ; 
row = 1; 
for j=N+1:-1:2
	count=(row-1)*N+1; 
	Q(:,count:count+N-1)=q(x(2:N+1),y(j)); row = row+1;
end 
zer = zeros(1, N-2); %useful vector for constructing C
C= -h^2*Q + [L(9)+T(2) Τ(3) Τ(4) Τ(5) Τ(6) Τ(7) Τ(8) R(9) + T(9) ...
	L(8) zer R(8) L(7) zer R(7) L(6) zer R (6) L(5) zer R(5) L(4)
	zer R(4) L(3) zer R(3) L(2) +B(2) B(3) B(4) B(5) B(6) B(7) B(8)...
	R(2)+B(9)];
C=C';
U=A\C
Z=zeros(N);
Z(:)=U:
Z=Z'
Z=[T (2:N+1); Z: B(2:N+1)]:
for i-1:N+2, Lrev(i)=L(N+3-i): end
Z=[Lrev; Z'; R]':
for i=1:N+2, yrev(i)=y(N+3-i); end
surf (x, yrev ,Z), xlabel('x-values'), ylabel('y-values'),
zlabel('u-values')
The codes of part (b) for computing the errors will work here as well; the results, shown below, 
indicate significant improvements in the quality of the solution (both decrease nearly 100-fold!): 
->Max_Error = 0.0030 
->Max Relative Error = 0.0081
\end{lstlisting}

\textbf{\underline{EFR 11.5:}}\texttt{linespace(-2,3,11)} (a) In (21), 
\begin{multicols}{2}
$$
4 u_{i, j}-u_{i+1, j}-u_{i-1, j}-u_{i, j+1}-u_{i, j-1}=-h^{2} q_{i, j} \text {, }
$$
since all boundary terms are zero, whenever a boundary term is present on the left it can be deleted (rather than moved to the right side). Thus, the right sides of these equations will always take the same form, so we just have to describe how the left sides look. We use the grid-numbering scheme introduced in the section. For each node $P_{k}$, (21) gives an equation for the corresponding unknown function value $U_{k}=u\left(P_{k}\right)$. With the aid of the generic grid diagram on the right, we describe the various forms of the left sides of these equations:


\begin{center}
\includegraphics[scale=0.8]{fig22}
\end{center}
\end{multicols}

\begin{math}
\begin{array}{ll}
k=1: & 4 U_{1}-U_{2}-U_{N+1} \\
k=2: N-1 & 4 U_{k}-U_{k+1}-U_{k-1}-U_{N+k} \\
k=N: & 4 U_{N}-U_{N-1}-U_{2 N} \\
k=N+1,2 N+1, \ldots,(M-2) N+1: & 4 U_{k}-U_{k+1}-U_{k-N}-U_{k+N} \\
k=2 N, 3 N, \ldots,(M-1) N: & 4 U_{k}-U_{k-1}-U_{k-N}-U_{k+N}
\end{array}
\end{math}
\\

$k$ between $N+1$ and $(M-1) N$,
but not of last two types:

\begin{math}
\begin{aligned}
&4 U_{k}-U_{k+1}-U_{k-1}-U_{k-N}-U_{k+N} \\
&4 U_{k}-U_{k+1}-U_{k-N} \\
&4 U_{k}-U_{k+1}-U_{k-1}-U_{k-N} \\
&4 U_{k}-U_{k-1}-U_{k-N}
\end{aligned}
\end{math}
\begin{math}
\begin{array}{ll}
k=(M-1) N+1: & 4 U_{k}-U_{k+1}-U_{k-N} \\
k=(M-1) N+2: M N-1: & 4 U_{k}-U_{k+1}-U_{k-1}-U_{k-N} \\
k=M N: & 4 U_{k}-U_{k-1}-U_{k-N}
\end{array}
\end{math}

Contemplating this linear system and putting it into matrix form: $A U=C$, we see that $C$ is simply the column vector $-h^{2} Q$ and $\mathrm{A}$ is the $N M \times N M$ banded matrix having the following 5 bands: 4 's down the main diagonal, $-1$ 's down the diagonals at levels $N$ (above main) and $-N$ (below main). At levels 1 and $-1$, the following vector appears: It begins with a sequence of $N-1,-1$ 's, then the vector $[0-1-1$ $\ldots-1]$ with $-1$ repeated $N-1$ times is tacked on $M-1$ times. This being done, the following $M$-file is a straightforward modification of the code used in Example 11.5:

\begin{lstlisting}[frame=single, numbers=none]
function [xgrid, ygrid, Zsol] = poissonsolver(q,a,b,c,d,h) 
%M-file for EFR 11.5. This program is designed to find the finite 
%difference solution of the Poisson problem with zero Dirichlet 
%boundary conditions on any rectangle R={a<s
x<=b, c<=y<=d}: 
%u_xx + u_yy = q(x,y) on R 
%u(x,y) = 0 on bdy R 
%Input variables: q = inline function (or M-file) for inhomogeneity 
%a,b,c,d = endpoints of the rectangle R (a<b and c<d), and h = 
%uniform step size (x step = y step). It is assumed that h divides 
%into both b-a and d-c with an integer quotient. 
%Output variables: xgrid, ygrid, and Zsol, the first two are 
%vectors corresponding to the partition of [a, b] and [c, d],
%respectively determined by the step size h. Zsol is the 
%corresponding matrix of values over the rectangular grid, set up so 
%that surf(xgrid, ygrid, Zsol) will result in a surface plot of the 
%numerical solution.

%first check to see if h is a permissible step size: 
if ((b-a)/h>floor((b-a)/h+eps))|((d-c)/h>floor((d-c)/h+eps)) 
	error('Inputted step size does not evenly divide into both side 
lengths; try another step size') 
end 

N=floor((b-a)/h)-1; %number of internal x-grid points 
M=floor((d-c)/h)-1; %number of internal y-grid points 
xgrid=linspace(a,b,N+2); ygrid=linspace(c,d,M+2);  

A=4*eye(N*M)/ 
%form sub/super diagonals 
al=-ones(1,N-1); alrep = [0 a1]; 
for i=1:M-1, a1=[a1 alrep]; end 
aN=-1*ones(1,N*M-N); 
%put these diagonal entries on A 
A=A+diag(a1,-1)+ diag(a1,1)+diag(aN,-N)+diag(aN,N); 
% First we construct a row vector for Q, arising from the source
term:
% We do this by collecting the needed entries in the required reading 
order (using an 
% appropriately designed loop). 
row =1;
for j=M+1:-1:2 
	count=(row-1)*N+1; 
	Q(:,count:count+N-1)=q(xgrid(2:N+1),ygrid(j)); row = row+1; 
end 
C= -h^2*Q; , C=C'; 
%Now we are ready to solve the system
\end{lstlisting}

\begin{lstlisting}[frame=single, numbers=none]
U=A\C; 
Z=zeros(N,M); 
Z(:)=U; 
Z=Z'; 

Z=[zeros(1,N); Z; zeros (1, N)]:
Zsol=[zeros(1, M+2); Z': zeros (1, M+2)]':
%rather than reverse the order of ygrid, we leave it in the usual
order,
%but change the ordering in Zsol to make it amenable to 3D plotting.
%Znew= zeros (size (Zsol));
for i=1:M+2, Znew(i,:)=Zsol(M+3-i,:); end, Zsol = Znew;
\end{lstlisting}
\mycode{This M-file is very simple to implement. Both numerical solutions that we obtain are graphically 
indistinguishable from the exact solution, so we will show a plot of the latter (finer grid) numerical 
solution and also both error graphs. }

\begin{multicols}{2}
\begin{lstlisting}[frame=None, numbers=none]
>> q = inline('sin(2*pi*y).*(4*pi^2*(x-x.^3)+6*x)','x','y'); 
[x1,y1,Z1]=poissonsolver... 
(q,0,1,0,1,.1); 
[x,y,Z]=poissonsolver... 
(q,0,1,0,1,.02); 
>> surf(x,y,Z), 
xlabel('x-values'), 
ylabel('y-values'), 
zlabel('u-values') 
>> %Plot shown at right.

>> uExact=inline((x.^3-... 
x) .*sin(2*pi*y)', 'x', 'y'); 
>> Zexact= (X. 3-... 
X).*sin(2*pi*Y); 
>> [X1,Y1]=meshgrid(x1,y1);
\end{lstlisting}


\begin{center}
\includegraphics[scale=0.7]{fig23}
\end{center}
\end{multicols}
\begin{lstlisting}[frame=None, numbers=none]
>> Zlexact= (X1.^3-Χ1).*sin(2*pi*Y1); 
>> surf(x1,y1,abs(Z1-Zlexact)) 
>> xlabel('x-values'), ylabel('y-values'), 
>> zlabel('Error') 
>> %first error plot, below left 
>> [X,Y]=meshgrid(x,y); 
>> Zexact= (X.^3-X).*sin (2*pi*Y); 
>> surf(x,y,abs(Z-Zexact)) 
>> xlabel('x-values'), ylabel('y-values'), 
>> zlabel('Error') 
>> %second error plot, below right 
\end{lstlisting}

\begin{center}
\includegraphics[scale=0.7]{fig24}
\end{center}

\textbf{\underline{EFR 11.6:}} \texttt{linspace(-2,3,11)} \\ 
\mycode{(a) The M-filc boxed below follows the strategies of the solution of Example 11.6:}

\begin{lstlisting}[frame=single, numbers=none]
function [Z, x, y] = triangledirichletsolver(n, leftdata, bottomdata, 
slantdata) 
% This program will solve the Dirichlet problem of Laplaces equation 
% on the special isoceles triangle with vertices (0,0), (1,0), (0,1). 
% The finite difference method will be used. 
% The inputs are as follows: n = the number of interior grid points 
% on both the x- and y-axis (so n+2= total # of x/y-grid values). 
% leftdata = vector of boundary values on left side (size n+2, read 
% top to bottom, bottomdata = vector of boundary values on bottom 
% side (size n+2)slantdata = vector of boundary values on slant side 
% (size n+2, read from top) 
% The output variables are as follows: 
% Z = the n+2 by n+2 matrix of the discrete solution's values 
% x = vector of x grid values 
% y = vector of y grid values (in reverse order to facilitate plots) 
N=n*(n-1)/2; %number interior nodes (with unknown function values) 
A=diag(4*ones(1,N)); border = [0]; count = 1;

for i=1:n-1 
	border(i+1)=border(i)+count; 
	count-count+1; 
end

for k=2:length(border) 
if k>2, pregap=right-left+1; end 
left=border(k-1)+1; right=border(k); 
if k<length(border) 
postgap=right-left+1; 
end 
for i=left:right 
if Kright %has right neighbor and top neighbor 
A(i, [i+1 i-pregap])=-1; 
end 
if i>left %has left neighbor 
A(i,i-1)=-1; 
end 
if k<length(border) %has bottom neighbor 
A(i,i+postgap)=-1; 
end 
end 
end 

%Next we need to build the vector C 
C=zeros(N,1); 
for k=2:length(border) 
left=border(k-1)+l; right=border(k); 
C(left)=C(left)+leftdata(k+1); 
C(right)=C(right)+slantdata(k+1)+slantdata(k); 
if k==length(border) 
	for i=left:right 
		C(i)=C(i)+bottomdata(i-left+2) ; 
	end
end
end

U=A\C;

%start building the matrix of the numerical solution 
Z=ones(n-1); count-1; 
for i=1:n-1 
gap=border(i+1)-count+1 ; Z(i,1:gap)=ü(count:(count+gap-1))'; 
count=count+gap ; 
end 
Z=[ones(1,n-1);[slantdata(2) ones(1,n-2));Z;bottomdata(2:n)]; 
Z=[leftdata', Z, [ones(1,n+1) bottomdata(n+1)]', slantdata']; 
for i=1:n+2 
	Z(i,i)=slantdata(i);
end
%We delete those values of the Z matrix which are not in the triangle 
%except for those nodes adjacent to two diagonal nodes where we use 
an
%average value 
for i=1:n+2 
	if i<n+2 
	Z(i,i+1)=(Z(i,i)+Z(i+1,i+1))/2; 
	end 
	for j=i+2:n+2 
		Z(i,j)=nan; 
	end 
end 

h=1/(n+1); 
x=0:h:1; y=x; 
for i-1:length(y), yrev(i)=y(length(y)+1-i); end 
y=yrev; 
\end{lstlisting}

\mycode{(b) The following commands will invoke the above M-file to solve the BVP of Example 11.6 with n = 
49 internal grid values.}
\begin{lstlisting}[frame=none, numbers=none]
>> leftdata = [50 zeros(1, 50)]; bottomdata = [zeros(1,50) 50]; 
>> slantdata = [50 100*ones(1,49) 50]; 
>> [Z, x, y]= triangledirichletsolver(49,leftdata,bottomdata, 
slantdata); 
>> surf(x,y,Z)
\end{lstlisting}
\mycode{A surface graph of the numerical solution will now appear. It can be rotated into looking exactly like 
the one in Figure 11.16b}
\begin{lstlisting}[frame=none, numbers=none]
>> c=contour(x,y,Z,12), clabel(c,'manual')
\end{lstlisting}
\mycode{The first of these two commands will create a contour (isotherm) plot with 12 contour lines. The 
second command has prompted users to click with their mouse at the locations (on the isotherms) 
where numerical values should be displayed. A plot as in Figure 11.17 can thus be constructed.}


\textbf{\underline{EFR 11.7:}} \texttt{linspace(-2,3,11)} \\
(a) The M-file boxed below follows the strategies of the solution of Example 11.7: 

\begin{lstlisting}[frame=sigle, numbers=none]
function [Z, x, y]=rectanglepoissonsolver(h, a, b, varf, leftdata, 
rightdata, topdata, bottomdata) 
% Program for solving the Dirichlet problem for the Poisson equation 
% Laplace(u)=f on the rectangular domain: 0 <= x <= a, 0<= y <= b. 
% Input variables: h = common step size (assumed to divide evenly 
% into both a and b) , varf = inhomogeneity function (of x and y)for 
% the Poisson equation, last four input variables give the Dirichlet 
% boundary data on the various sides of the rectangle. Horizontal 
% data are assumed to be row vectors (reading from left to right) and 
% vertical data are assumed to be column vectors (reading from top to 
% bottom). Output variables: Z = matrix of values of the numerical 
% solution at the grid values determined by the inputs, x, y = 
% correpsonding x-grid vectors and y-grid vectors. y-grid is assumed 
% to read the values from top to bottom to facilitate plots. 

%first check to see if h is a permissible step size: 
if (a/h>floor(a/h)+eps)|(b/h>floor(b/h)+eps) 
	warning('Inputted step size does not evenly divide into both side lengths; unexpected results may occur') 
end

N=floor(a/h)-1; %number of internal x-grid points 
M=floor(b/h)-1; %number of internal y-grid points 
xgrid=linspace(0,a,N+2); ygrid=linspace(0,b,M+2); 

% Check to see data input vectors are correct size , if not exit 
program 
if ... 
size (leftdata)~=size(ygrid')|size(rightdata)~=size(ygrid')|size(topdata)~=size(xgrid)|... 
size(bottomdata)~=size(ygrid) 
error('At least one of the boundary data vectors does not have correct size corresponding to step size h, program will terminate') 
end 
% Creation of coefficient matrix A of the linear system AU=C: 
% A=4*eye(N*M); 
% form sub/super diagonals 
a1=-ones(1,N-1); alrep = [0 a1]; 
for i=1:M-1, a1=[a1 alrep]; end 
aN=-1*ones(1,N*M-N); 
% put these diagonal entries on A 
A=A+diag(a1,-1)+ diag(a1,1)+diag(aN,-N)+diag(aN,N);

% Creation of column vector C of the linear system AU=C:We use the 
% decomposition (33), (34), (35) of Chapter 11 to guide us. 
% First we construct a row vector for F, arising from the source 
% term: 
% We do this by collecting the needed entries in the required reading 
% order (using an appropriately designed loop). 
row = 1; F=zeros(N*M,1); 
for j=M+1:-1:2 
	count=(row-1)*N+1; 
	F(count:count+N-1)=feval(varf,xgrid(2:N+1),ygrid(j)); row = row+1; 
end 
F=F'; 
% Since C = B-h^2*F, we also need to construct the vector B using the 
% boundary data; we use (35) of Chapter 11. We need to translate 
% (35) into the notation of the inputted boundary data vectors. For 
% example, the vector 'leftdata', in the notation of g_i_j, has the 
% following components for each MATLAB index (on left, so leftdata(i) 
% is abbreviated as i) :[1 2 3 ... M+l M+2] = [g_0_M+l g_0_M g_0_M-l 
% ... g_0_l g_0_0] Similarly, the MATLAB components of rightdata 
% are[:1 2 3 ... M+1 M+2] = [g_N+1_M+1 g_N+1_M g_N+1_M-1 ... 
% g_N+1_1 g_N+1_0] In the same fashion, here are the components of 
% topdata and bottomdata (1 2 3 ... N+1 N+2] = [g_0_M+1 g_1_M+1 
% g_2_M+1 ... g_N_M+1 g_N+1_M+1][1 2 3 ... N+1 N+2] = [g_0_0 g_1_0 
% g_2_0 ... g_N_0 g_N+1_0]
% Here now is the construction of the vector B from (35):
Bcount=1; 
for j=1:M 
	if j==1 
		for i=1:N 
			if i==1, B(Bcount)=topdata(2)+leftdata(2); Bcount=Bcount+1; 
			elseif i==N, B(Bcount)=topdata(N+1)+rightdata(2);
	Bcount=Bcount+1; 
			else, B(Bcount)=topdata(i+1); Bcount=Bcount+1; 
			end
		end
	elseif j==M 
		for i=1:N 
			if i==1, B(Bcount)=bottomdata(2)+leftdata(M+1);
Bcount=Bcount+1;
			elseif i==N, B(Bcount)=bottomdata(N+l)+rightdata(M+l); 
Bcount=Bcount+1; 
			else , B(Bcount)=bottomdata(i + 1); Bcount=Bcount+1; 
			end 
		end 
	else
		for i=1:N 
			if i==1, B(Bcount)=leftdata(1 + j) ; Bcount=Bcount+1; 
			elseif i==N, B(Bcount)=rightdata(1+j); Bcount=Bcount+1; 
			else, B(Bcount)=0; Bcount=Bcount+1; 
			end 
		end 
	end
	end
	
%With F and B constructed (as row vectors), using (33) of Chapter 
11, we 
%can form the vector C: 
C = B-h^2*F; C=C'; 

%Now we are ready to solve the system. 
U=A\C; 
Z=zeros(N,M); 
Z(:)=U; 
Z=Z'; 
% So far we have the numerical values in assembled in a matrix, we 
% just need to attach the given boundary values appropriately. For 
% the corner interfaces between two boundary values (e.g., where the 
% topdata vector meets the leftdata vector), we use the average 
% value.

Z=[topdata(2:N+1); Z; bottomdata(2:N+1)]; 
NWavg=(leftdata(1)+topdata(1))/2; 
NEavg=(rightdata(1)+topdata(N+2))/2; 
SWavg=(leftdata(M+2)+bottomdata(1))/2; 
SEavg=(rightdata(M+2)+bottomdata(N+2))/2; 
Zsol=[NWavg leftdata(2:M+1)' SWavg; Z'; SWavg rightdata(2:M+1)' 
SEavg]'; 
%rather than reverse the order of ygrid, we leave it in the usual 
order, 
%but change the ordering in Zsol to make it amenable to 3D plotting. 
%Znew = zeros(size(Zsol)); 
for i=1:M+2, Znew(i,:)=Zsol(M+3-i,:); end, Zsol = Znew; 
Z=Zsol; x=xgrid; y=ygrid;
\end{lstlisting}

\mycode{(b) The program requires the inputted inhomogeneity function to accept vector arguments. Since the 
squareheatsourc e M-file constructed in Example 11.7 does not take vector inputs, we first need 
to modify the M-file accordingly (as shown in Example 4.4):}

\begin{lstlisting}[frame=sigle, numbers=none]
function z = squareheatsourcevec(x,y) 
for i=1:length(x), for j=1:length(y) 
if x(i)>=.25 & x(i)<=.5 & y(j)>=.65 & y.(j)<=.9, z(i, j)=-800; 
else, z(i,j)=0; 
end, end, end
\end{lstlisting}
\mycode{It is now straightforward to use the program of part (a) to solve our problem. We must contemplate 
what size vectors to use for the input boundary data vectors once we decide on the step size h. Since 
we will use h = 0.02, the x- and y-grids will both have 1/h + 1 = 51 component}

\begin{lstlisting}[frame=sigle, numbers=none]
>> leftdata=zeros(51,1) ; rightdata=5*ones(51,1) ; ... 
xgrid = linspace(0,1,51) ; bottomdata=5*xgrid ; topdata=bottomdata; 
>>[Z, x,y]=rectanglepoissonsolver(.02,1,1, .. . 
@squareheatsourcevec,leftdata , rightdata , topdata,bottomdata); 
\end{lstlisting}
\mycode{Surface graphs (and contour plots) of the numerical solution can be obtained just as was done in the 
solution of Example 11.7, and the resulting graphics will agree with those of Figure 11.19, as the reader should verify}

\textbf{\underline{EFR 11.8:}} \texttt{linspace(-2,3,11)} \\
(a) The nodes, labeling scheme and ghost nodes are as illustrated below: 

\begin{center}
\includegraphics[scale=0.8]{fig25}
\end{center}

The nodes marked with $X$ 's have known values; as usual we took an average value for the corner point of a jump discontinuity. We will obtain a linear system for the 400 variables $U_{k}=u\left(P_{k}\right),(k=1,2, \ldots, 400)$. Since the inhomogeneity of the PDE $f=0$, (26) becomes: $4 u_{i, j}-u_{i+1, j}-u_{i-1, j}-u_{i, j+1}-u_{i, j-1}=0$. To incorporate the boundary conditions, it is helpful to separate into cases:

CASE 1: Top-row nodes: $\left(P_{1}, \cdots, P_{20}\right):$ (so $j=M$ ). In (26), $u_{i, M+1}$ corresponds to a ghost node. Using the Neumann boundary condition $u_{y}(x, 1)=20$ with the central difference formula gives:
$$
\frac{u_{i, M+1}-u_{i, M-1}}{2 h}=20 \underset{\text { Sinceh=0.05 }}{\Rightarrow} u_{i, M+1}=u_{i, M-1}+2 .
$$
Similarly, if $i=20$, (so we are at the right node), then we obtain (from the zero derivative conditions specified at the right side): $u_{21, M}=u_{19, M}$. If $i=1$, the Dirichlet boundary conditions at the left side would tell us that $u_{0, M}=100$. Summarizing and translating into $k$-indices gives the following:
$$
4 U_{k}-\underset{\left(=U_{k-1} \text { if } k=20\right)}{U_{k+1}}-\underset{(=100 i j k=1)}{U_{k-1}}-2 U_{k+20}=2 \quad(1 \leq k \leq 20) .
$$

CASE 2: Bottom-row nodes: $\left(P_{381}, \cdots, P_{400}\right):$ (so $j=1$ ). A similar argument (but this time we use the zero Dirichlet boundary condition for the values $u_{i, 0}$ ) leads to the following:\\
\begin{center}
\begin{math}
4 U_{380+i}-\underset{\left(=U_{399} \text { if } i=20\right)}{U_{380+i+1}}-\bigcup_{(=100 i f i=1)}^{U_{380+i-1}}-U_{360+i}=0 .
\end{math}
\end{center}

CASE 3: Interior rows: $\left(P_{21}, \cdots, P_{380}\right)$ : (so $1<j<M$ ). This case is easiest since the top and bottom edge boundary conditions never come into play; the equations are as follows:
$$
4 U_{20 n+i}-\underset{\left\{=U_{20 n+i-1}+i f i=20\right)}{U_{20 n+1}}-U_{\{=100 i j} U_{i=1)}-U_{20(n+1)+i}-U_{20(n-1)+i}=0 .
$$
The resulting linear system $A U=C$ is specified by the following $M \times M(M=20)$ block matrices:
\begin{center}
\includegraphics{fig26}
\end{center}

where $V_{N}$ is the same matrix as $W_{N}$ of $(42)$, except that the $(1,2)$ entry should be changed from $-2$ to $-1$, and $N=20$. Also, $w=\left[\begin{array}{lllll}100 & 0 & 0 & \cdots & 0\end{array}\right]^{\prime}$ and $v=\left[\begin{array}{lllll}2 & 2 & 2 & \cdots & 2\end{array}\right]^{\prime}$ into a MATLAB session, the system can be solved and one can obtain plots like those given in the text.

\begin{lstlisting}[frame=none, numbers=none]
>> N=20; 
>> A=diag(4*ones(1,N^2))-diag(ones(1,N^2-N), N)-... 
		diag(ones(1,N^2-N),-N); 
>> %next create vector for sub/super diagonals 
>> v1=-ones(1,N-1); v=[v1 0] ; 
>> for i=1:N-1 
	if i<N-1
		v=[v v1 0]; 
	else 
		v=[v v1]; vlow-v; vlow(N-1)=-2; 
	end 
end
>> A=A+diag(v,1)+diag(v,-1); 
>> cblock = zeros(N,1); cblock(1)=100; C=cblock; 
>> for i=1:N-1 
	C[C;cblock]; 
end 
>> C(1:N)=C(1:N)+2*ones(N,1);
 
>> cblock = zeros(N,1); cblock(1)=100; C=cblock; 
>> for i=l:N-1 
	C=[C;cblock]; 
end 
C(1:N)=C(1:N)+2*ones(N, 1); 
>> xgrid=0:.05:1; 
>> for i=1:21 
	ygrid(i)=xgrid(22-i);
end 
>> U=A\C; 
Z=zeros(N/N); 
>> Z(:)=U; Ζ=Ζ'; 
>> Z=[100*ones(N,1) Z]; 
>> Z=[Z;[50 zeros(1,N)]]; 
>> mesh(xgrid,ygrid,Z) %produces a mesh plot of the solution 
>> hidden off, xlabel('x-axis'), ylabel('y-axis') 
\end{lstlisting}
\mycode{A contour plot can now be produced in the usual fashion: }
\begin{lstlisting}[frame=none, numbers=none]
>> c=contour(xgrid,ygrid,Z,20) 
>> clabel(c, 'manual')
\end{lstlisting}
\mycode{We leave it to the reader to use their mouse to place the contour labels, and to repeat these 
computations with N = 50. }

\noindent\hrulefill\\
\textbf{CHAPTER 12: HYPERBOLIC AND PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS}\\
\textbf{\underline{EFR 12.1:}} \texttt{linspace(-2,3,11)} \\
The following commands will make the movie:

\begin{lstlisting}[frame=none, numbers=none]
>> x=-5:.01:5; counter =1; 
>> for t=0:.1:4; x1=x+t; x2=x-t; 
	for i=1:1001 
		u(i)=.5*(eg17_1(x1(i))+eg17_1(x2(i))); 
	end 
	plot(x,u), axis ([-5 5 -1 3]) %We fix a good axis range. 
	M(:, counter) = getframe; counter=counter+1; 
end
\end{lstlisting}
\mycode{Here is a possible playback mode:}
\begin{lstlisting}[frame=none, numbers=none]
>> movie(M, 10,25) 
\end{lstlisting}


\textbf{\underline{EFR 12.2:}} \texttt{linspace(-2,3,11)} \\
\mycode{(a) The M-file is boxed below:}
\begin{lstlisting}[frame=single, numbers=none]
function [] = dalembert(c,step, finaltime , phi, nu, range) 
% This function M-file will produce a serie s of snapshots of the 
% solution to the one-dimensional wave problem: u_tt = c^2u_xx 
% having initial displacement: u (x,0)=phi(x) and initial velocity 
% u_t (x,0)=nu(x) . 
% The snapshots run from t=0 to t = finaltime in increments of step. 
% Input variables: c = wave speed (from PDE), step s positive number 
% indicating time step for snapshot intervals, phi, nu = initial 
% displacement and velocity functions for wave, respectively, and 
% range =4 by 1 vector of uniform axes range to use in plots. The 
% code is based on D'Alembert's solution of Theorem 12.1. 
% Note: Since 'quad' is used within the program on the function nu, 
% it is necessary that nu be constructed to accept vector inputs. 
x=range(1):.01:range(2); 
sx = length(x); 
%Set dimensions of subplot window 
N = finaltime/step; %Number of shots 
if N<=11 
	N1=N+1; M=1; 
elseif N>11&N<=21 
	N1=ceil((N+1)/2); M=2; 
else 
	N1=ceil((N+1)/3); M=3; 
end 
counter =1; 
for t=0:step:finaltime 
x1=x+c*t; x2=x-c*t; 
for i=1:sx

u(i)=.5*(feval(phi , x1(i))+feval(phi, x2(i)));
u(i)=u(i) +quad (nu, x2(i), x1(i)); 
end 
subplot(N1,M,counter) 
plot(x,u) 
hold on 
axis([range]) %We fix a good axis range.
counter=counter+1; 
end
\end{lstlisting}
\mycode{(b): Since the function quad gets used inside the above program (with the inputted function nu), we must ensure that the nu is constructed in a way so that it can take vector inputs.}
\begin{lstlisting}[frame=none, numbers=none]
>> nu = inline('zeros(size(x))') 
\end{lstlisting}
\mycode{The following command will reproduce the results of Figure 12.5:}

\begin{lstlisting}[frame=none, numbers=none]
>> dalembertd(1, .5 , 5, @EX12_1, nu, [-5 5 0 2])
\end{lstlisting}

\mycode{(c) We first create an M-file for the function v(x)}

\begin{lstlisting}[frame=single, numbers=none]
function y = EFR12_3nu(x)
for i = 1:length(x)
	if abs(x(i))<1, y(i)=1;
	else y(i)=0;
	end
end
\end{lstlisting}

\mycode{The function phi, need not take vector inputs: }
\begin{lstlisting}[frame=none, numbers=none]
>> phi = inline('O' , 'x') 
\end{lstlisting}
\mycode{A bit of experimenting will show that ay-range of 0 to 2.5 serves well for this problem. }
\begin{lstlisting}[frame=none, numbers=none]
>> dalembertd(1, .5, 5, phi, @EFR12_3nu, [-5 5 0 2.5]) 
\end{lstlisting}

\mycode{(d) If we change the fina l time input in both parts (a) and (b) to 10, rerun the program, and examine the output, we will see that in both parts, the wavefront will reach x = 10 at (approximately) t - 9. This agrees with the theoretical fact that the wavefronts (here there are two moving in opposite directions) are traveling at speed c. The snapshots show that the starts of the disturbances are propagating to the left and to the right with speed c = 1 unit of space per one unit of time.}
\begin{center}
\includegraphics[scale=0.7]{fig27}
\end{center}


\textbf{\underline{EFR12.3:}}
\textbf{(a) In order to prevent the M-file from running into logical dilemmas, we define it for all values of $x$ (note that formula (13) excludes definitions at enpoint values: $x=0, L,-L$, etc.). We use formula (13) together with an if-branch for the structure of the M-file below (cf. Example 4.4).}

\begin{multicols}{2}
\begin{center}
\includegraphics[scale=0.5]{fig28}
\end{center}




\begin{lstlisting}[frame=single, numbers=none]
function y = phihat(x) 
for i = 1:length(x)
	if (x(i)<=2)&(x(i)>=0), y(i)=1-abs(1-x(i));
	elseif (x(i)<2)&(x(i)>=-2, y(i)=-phihat(-x(i));
	else n = floor((x(i)+2)/4;	
		r = x(i)-4*n; y(i) = phihat(r);
	end
\end{lstlisting}
\end{multicols}

\textbf{(b) The following commands were used to produce the plot shown above:}
\begin{lstlisting}[frame=none, numbers=none]
>> x=-6:.05:6; plot(x,phihat(x)) 
>> axis([- 6 6 -1.5 1.5]), grid on 
\end{lstlisting}

\noindent\textbf{\underline{EFR 12.4}}
Letting $\hat{\varphi}(x)$ and $\hat{v}(x)$ denote the periodic extensions (specified by (13)) of the functions $\varphi(x)$ and $v(x)$, respectively, the method of reflections and d'Alembert's theorem tell us that the function
$$
\hat{u}(x, t)=\frac{1}{2}[\hat{\varphi}(x+c t)+\hat{\varphi}(x-c t)]+\frac{1}{2 c} \int_{x-c t}^{x+c t} \hat{v}(s) d s,
$$

provides a solution to the finite string problem $(11)$ (if we restrict $x$ to the domain $[0, L]$ ). For such $x$ and for any positive integer $n$, if we substitute $t=t+n L / c$ into this equation, we see that the integral extends from $x-c t-c(n L / c)=x-c t-n L$ to $x+c t+c n L / c=x+c t+n L$. But since the integrand is a period $L$ extension of an odd function, it follows that the portions of the integral from $x-c t-n L$ to $x-c t$ and from $x+c t$ to $x+c t+n L$ must be zero. Similarly, since $\hat{\varphi}(x)$ is periodic of period $L$, we may conclude that
$$
\begin{aligned}
&\frac{1}{2}[\hat{\varphi}(x+c(t+n L / c)+\hat{\varphi}(x-c(t+n L / c))] \\
&=\frac{1}{2}[\hat{\varphi}(x+c t+n L)+\hat{\varphi}(x-c t-n L)]=\frac{1}{2}[\hat{\varphi}(x+c t)+\hat{\varphi}(x-c t)]
\end{aligned}
$$
It follows that $\hat{u}(x, t+n L / c)=\hat{u}(x, t)$ and this is the asserted periodicity statement.

\begin{multicols}{2}
\noindent\textbf{\underline{EFR 12.5:}} (a) To contruct the initial profile "pulse" function, we make use of the basic cubic spline function $\mathrm{BS}(x)$ given by formula (51) of Chapter 10. In EFR 10.16, we constructed an M-file BSSpline for this function. We will also need an M-file for its derivative-the following $M$-file gives such a construction based on the formula (53) of Chapter $10 .$ Note that because we will be using a variant of this function for the nu input of the dalembert $M$-file, we need to



\begin{center}
\includegraphics[scale=0.5]{fig29}
\end{center}
\end{multicols}
\noindent{construct it in a way that it will accept vector inputs (cf. Example 4.4):}

\begin{multicols}{2}
\begin{lstlisting}[frame=single, numbers=none]
function y = BSprime(x) 
%Derivative of basic cubic spline 
%function of Chapter 10, (52), 
%function is built to accept 
%vector arguments. 
for i=1:length(x) 
	if x(i)>=0 & x(i)<=1 
		y(i)=3/4*(4*(1-x(i))^2-(2-x(i)^2); 
	elseif x(i)>1 & x(i)<=2 
		y(i)=-3/4*(2-x(i))^2; 
	elseif x(i)>2 
		y(i)=0; 
	else, y(i) = -BSprime(-x(i)); 
	end 
end
\end{lstlisting}



\begin{center}
\includegraphics[scale=0.6]{fig30}
\end{center}

\end{multicols}




We represent the pulse in Figure $12.10$ with $(u(x, 0) \equiv) \varphi(x)=B S(x-3)$. Since we are given that the initial velocity of the pulse is 2 (units to the right per unit time), we can compute $\left(u_{t}(x, 0) \equiv\right) v(x)=\left.\frac{d}{d t} \varphi(x-2 t)\right|_{t=0}=-2 \varphi^{\prime}(x)=-2 B S^{\prime}(x-3)$ and thus $\left(u_{t}(x, 0) \equiv\right) v(x)=-2 B S^{\prime}(x-3)$.\\
Since we will be using the method of reflections we need to create M-files for the odd periodic extensions of these functions. The resulting M-files are as follows:
\newpage
\begin{multicols}{2}
\begin{lstlisting}[frame=single, numbers=none]
function y = EFR12_5phihat(x) 
if (x>=0)&(x<=10) 
	y=BSSpline(x-3);
elseif (x<0)&(x>=-10) 
	y = -EFR12_5phihat(-x); 
else q=floor((x+10)/20); 
	y=EFR12_5phihat(x-20*q); 
end 
\end{lstlisting}
Again, we need to construct the second one so it will 
accept vector inputs (as required by dalembert).
\begin{lstlisting}[frame=single, numbers=none]
function y = EFR12 5nuhat(x)
for i=1:length(x)
if (x(i)>=0)&(x(i)<=10)
	y(i)=-2*BSprime(x(i)-3); 
elseif (x(i)<0)&(x(i)>=-10)
	y(i) = -EFR12 5nuhat(-x(i));
else q=floor((x(i)+10)/20);
	y(i)=EFR12 5nuhat(x(i)-20*q);
	end
end
\end{lstlisting}




\begin{center}
\includegraphics[scale=0.9]{fig31}
\end{center}
\end{multicols}

The series of snapshots can now be accomplished with the following single command:
\begin{lstlisting}[frame=none, numbers=none]
>> [x,ua]=dalembert(2,.5,4,@EFR12_5phihat,@EFR12_5nuhat,[0 10 -1.5 1.5]);
\end{lstlisting}
The output is shown as the first figure in the series of three for this EFR (appearing on the last page). Digression: After completing all three parts of this exercise, it will be useful to make some comparisons. For such a purpose, it would be helpful to have additional output data for the snapshot profiles that our dalembert program computes. It is a simple matter to modify our program accordingly to produce output data (with or without the snapshots).\\
(b) Here, the only change will be in the constant appearing in the formula for $v(x)$, arguing as in Part\\
\text { (a), we find that } $v(x)=-B S^{\prime}(x-3)$ \text {. If we modify the M-file 'EFR12 } 5 \text { nuhat' accordingly (let's } call the modified M-file as 'EFR12 5nuhatb'), we can then get our snapshots with the correspondingly modifed 'dalembert' call:\\
\begin{lstlisting}[frame=none, numbers=none]
>> [x,ub]=dalembert(2,.5,4,@EFR12_5phihat,@EFR12_5nuhatb,[0 10 -1.5 1.5]);
\end{lstlisting}
The resulting graphic is the middle one appearing in the series.
(c) Similarly, to get the final series of snapshots, we just need to change the $M$-file for $v(x)$ to correspond to the formula $v(x)=-4 B S^{\prime}(x-3)$. This being done (and the M-file stored as
'EFR12 5nuhatc' ), we obtain the third series of snapshots with the corresponding call on 'dalembert'.\\
\text { We point out some observations from the snapshots. In Part (a), we simply get an undistorted pulse }
\begin{multicols}{2}
\noindent moving at s peed two (and after it reflects on the right end, it switches direction and moves upside down to the left at speed two). In part (b) wave's initial velocity is slower than the speed of the PDE (natural speed for the string), the pulse is slightly weaker but still moves to the right at speed two, but we also get a secondary smaller pulse moving to the left at the same speed (so after it reflects and moves to the right but will be upside down). In part (c) when the initial velocity is faster than the speed of the PDE, we get a stronger main pulse moving to the right at speed two as well as a secondary pulse that moves in the opposite direction but with upside



\begin{center}
\includegraphics[scale=0.6]{fig32}
\end{center}
\end{multicols}
\noindent down orientation. The relative strengths of these pulses are difficult to detect from the subplots shown above. To get a clearer picture, we plot in a single axis window the three solution snapshots when $t=$ $2.5$ (assuming the solution matrix for Part (c) was stored as a matrix 'uc'). The plot shown at the right was created with the following commands:
\begin{lstlisting}[frame=none, numbers=none]
>> size(ua) -> ans= 9 101 
>> plot(x,ua(6,101) ) 
>> hold on, plot(x,ub(6,:),'r-x' ) 
>> plot(x,uc(6,:) , 'bo-') 
\end{lstlisting}

\noindent\textbf{\underline{EFR 12.6}} (a) Taylor's theorem tells us that we may write:\\
$f(x+h)=f(x)+f^{\prime}(x) h+f^{\prime \prime}(x) h^{2} / 2+O\left(h^{3}\right)$ and $f(x-h)=f(x)-f^{\prime}(x) h+f^{\prime \prime}(x) h^{2} / 2+O\left(h^{3}\right)$.
Since $O\left(h^{3}\right) / h=O\left(h^{2}\right)$, subtracting the second of these equations from the first and then dividing by $2 h$, results in (30).
(b) Under the assumptions on $u(x, t)$, we may apply the centered difference approximation (30) in the time variable to obtain the $O\left(k^{2}\right)$ estimate: $u_{i, 1}-u_{i,-1} \approx 2 k v\left(x_{i}\right)$ or $u_{i,-1} \approx u_{i, 1}-2 k v\left(x_{i}\right)$. If we substitute this latter approximation into $(23)$ with $\mathrm{j}=0$ :
$u_{i, 1}=2\left(1-\mu^{2}\right) u_{i, 0}+\mu^{2}\left[u_{i+1,0}+u_{i-1,0}\right]-u_{i,-1}=2\left(1-\mu^{2}\right) \varphi\left(x_{i}\right)+\mu^{2}\left[\varphi\left(x_{i+1}\right)+\varphi\left(x_{i-1}\right)\right]-u_{i,-1}$ and then solve for $u_{i, 1}$, we arrive at (31) with local truncation error: $O\left(h^{2}+k^{2}\right)+O\left(k^{2}\right)=O\left(h^{2}+k^{2}\right)$.

\noindent\textbf{\underline{EFR 12.7}} (a) The program will be identical to onedimwave, except that the single line defining 'U $(2, i)$ ' should be changed to: $U(2, i)=U(1, i)+k \star$ feval $(n u, x(i))$; so as to correspond to (29).\\
(b) The following loop will create a window with the 10 asked for plots using onedimwavebasic:

\begin{lstlisting}[frame=none, numbers=none]
>>for n=0:9 
d=2^n; %doubling factor 
[xbas, tbas, Ubas] = onedimwavebasic(phi, nu, pi, A, B, 8, 10, d*30, c);
subplot(2,5,n+1) 
plot(xbas,abs(Ubas(d*30,:)-uExact(xbas,8)))
end
>> title('Error plots for ''onedimwavebasic'', Ν = 10, M = 30, 60, 120, ...')
\end{lstlisting}
The resulting graphic is shown in the upper left portion below. To get the corresponding graphic when $N=40$, simply use the same code but change the seventh input of 'onedimwavebas ic' from 10 to 40. Also, the same two codes will produce the corresponding plots for 'onedimwave', simply replace this as the M-file name, and keep all else the same.
By examining the plots below, we see that the results of both methods are quite similar, with the accuracy of 'onedimwave' being slightly better than that of 'onedimwavebasic'. The instability is only evident in the first two plots (for each method) when $N=40$. This corroborates well with the CFL stability condition, which states (since the wave speed is one) that we should have $k \leq h$; indeed, this happens exactly on the third plots. Notice also that in all cases (after instability), the maximum errors seem to decrease by about $50 \%$ each time that we double the time step until the gains begin to taper off (e.g., the last three frames when $N=10$ ). No matter how large we take $M$, it seems reasonable that there will be a certain threshold of accuracy that we will be limited to if we keep the $x$ grid fixed.
\begin{center}
\includegraphics[scale=0.8]{fig33}
\end{center}

\noindent\textbf{\underline{EFR 12.8}} We leave it to the reader to rerun the code of Example 12.6 by replacing onedimwave with onedimwavebasic and to compare the graphical results. 

\noindent\textbf{\underline{EFR 12.9}} (a) The M-file is boxed below:
\begin{lstlisting}[frame=single, numbers=none]
function (x, t, U] = onedimwaveimpl_4(phi, nu, L, A, B, T, N, M, c) 
% solves the one-dimensional wave problem u_tt = c^2*u_xx 
% using implicit method with parameter omega=1/4. The Thomas method 
% is used. 
% Input variables: phi=phi(x) = initial wave profile function 
% nu=nu(x) = initial wave velocity function, L = length of string, A 
% =A(t) height function of left end of string u(0,t)=A(t), B=B(t) = 
% height function for right end of string u(L,t)=B(t), T= final time 
% for which solution will be computed, N = number of internal x-grid 
% values, M = number of internal t-grid values, c = c(x,t,u,u_x) 
% speed of wave. Functions of the indicated variables must be stored 
% as(either inline or M-file) functions with the same variables, in 
% the same order. 
% Output variables: t = time grid row vector (starts at t=0, ends at 
% t=T, has M+2 equally spaced values), x = space grid row vector, U 
% =(N+2) by (M+2) matrix of solution approximations at corresponding 
% grid points x grid will correspond to second (col) indices of U, y 
% grid values to first (row) indices of U. Row 1 of U corresponds to 
% t = 0. 
% CAUTION: For stability of the method, the Courant-Friedrichs-Levy 
% condition should hold: c(x,t,u,u_x)(T/L)(N+1)/(M+1) <1. 

h = L/(N+1); k = T/(M+1); 
U=zeros(M+2,N+2); x=0:h:L; t=0:k:T; 
% Recall matrix indices must start at 1. Thus the indices of the 
% matrix will always be one more than the corresponding indices that 
% were used in theoretical development. 

%Assign left and right Dirichlet boundary values. 
U(:,1)=feval(A,t)'; U (:,N+2)=feval(B,t)';

%Assign initial time t=0 values and next step t=k values. 
for i=2: (N+1) 
	U(1,i)=feval(phi,x(i)); 
	mu(i)=k*feval(c,0,x(i),U(1,i),(feval(phi,x(i+1))... 
-feval(phi,x(i-1)))/2/h)/h;U(2,i) = (1-mu(i)^N2)*feval(phi,x(i)) ... 
+mu(i)^2/2*(feval(phi,x(i-1))+feval(phi,x(i+1))) + k*feval(nu,x(i)); 
end 

%Assign values at interior grid points 
for j=2:(M+1) 
for i=2:(N+1) 
mu(i)=k*feval(c, t(j), x(i), U(j,i), (U (j,i+1)-U(j,i-1))/2/h)/h; 
end 
%Set up vectors for Thomas method 
a=-mu(2:N).^2; a(N)=0; 
d=4+2*mu(2:N+1).^2; 
b(1)=0; b(2:N)=-mu(3:N+1).^2; 
cT=4*(2-mu(2:N+1).^2).*U(j,2:N+1)+2*mu(2:N+1).^2.* ... 
	(U(j,1:N)+U(j,3:N+2))-2*(2+mu(2:N+1).^2).*U(j-... 
	1,2:N+1)+mu(2:N+1).^2.*(U(j-1,1:N)+Ü(j-1,3:N+2)); 
cT(1)=cT(1)+mu(2)^2*feval(A, t(j + 1)) ; 
cT(N)=cT(N)+mu(N+l)^2*feval(B,t(j+1));
U(j+1,2:(N+1))=thomas(a,d,b,cT); 
end 
\end{lstlisting}
(b) We leave such experiments to the reader. In particular, we suggest trying to choose the paramters N 
and M in such a way as to reduce the artificial "noise" (cf, Figure 12.16). Does going outside the 
stability ranges for the explicit method seem to help much?

\textbf{\texttt{EFR 12.10:}} In an analogous fashion to how (28) was derived, Taylor's theorem gives us that:
$$
u\left(x_{i}, y_{j}, k\right)=u\left(x_{i}, y_{j}, 0\right)+k u_{t}\left(x_{i}, y_{j}, 0\right)+\left(k^{2} / 2\right) u_{u}\left(x_{i}, y_{j}, 0\right)+O\left(k^{3}\right) .
$$
Now, if we assume that the PDE (wave equation) continues to hold for $u(x, y, t)$ on the initial plane $t=0$, we can write: $u_{u}(x, y, 0)=c^{2} \Delta u(x, y, 0)=c^{2}\left[\varphi_{x x}(x, y)+\varphi_{y y}(x, y)\right]$ Using the central difference approximations (Lemma 10.3) on these second derivatives of $\varphi$ and substituting into the first estimate produces the following:
$$
\begin{gathered}
u\left(x_{i}, y_{j}, k\right)=u\left(x_{i}, y_{j}, 0\right)+k u_{i}\left(x_{i}, y_{j}, 0\right)+\left(c^{2} k^{2} / 2 h^{2}\right)\left\{\varphi\left(x_{i+1}, y_{j}\right)+\varphi\left(x_{i-1}, y_{j}\right)+\varphi\left(x_{i}, y_{j+1}\right)+\varphi\left(x_{i}, y_{j-1}\right)\right. \\
\left.-4 \varphi\left(x_{i}, y_{j}\right)\right\}+O\left(k^{3}\right)+O\left(h^{2}+k^{2}\right)
\end{gathered}
$$
Since $O\left(k^{3}\right)+O\left(h^{2}+k^{2}\right)=O\left(h^{2}+k^{2}\right), \varphi(x, y)=u(x, y, 0), \mu^{2}=c^{2} k^{2} / h^{2}$, and $v(x, y)=u t(x, y, 0)$, if we use multi-index notation, this approximation tranlates to the following $O\left(h^{2}+k^{2}\right)$ estimate:
$$
u_{i, j}^{\prime} \approx\left(1-2 \mu^{2}\right) \varphi\left(x_{i}, y_{j}\right)+k v\left(x_{i}, y_{j}\right)+\mu^{2} / 2\left\{\varphi\left(x_{i+1}, y_{j}\right)+\varphi\left(x_{i-1}, y_{j}\right)+\varphi\left(x_{i}, y_{j+1}\right)+\varphi\left(x_{i}, y_{j-1}\right)\right\},
$$
as desired.

\textbf{\texttt{EFR 12.11:}} We will show that the local truncation error of the Crank-Nicolson method is $O\left(h^{2}+k^{2}\right)$ when viewed as a discretization of the PDE at $\left(x_{i}, t_{j}\right)$. A similar argument will show the same estimate is valid if we were to discretize at $\left(x_{i}, y_{j+1}\right)$. To clean up the notation a bit we will write $(x, t)$ in place of $\left(x_{i}, t_{j}\right)$ for the remainder of this proof. This proof will be more delicate than others since we really need to carefully use both Taylor's theorem and the PDE to estimate the error. We need to estimate the left side of (49) minus the right side, by expanding all terms using Taylor's theorem based at $\left(x_{i}, y_{j}\right)$ :
$$
\frac{u_{i, j+1}-u_{i, j}}{k}-\frac{\alpha}{2}\left[\frac{u_{i+1, j}-2 u_{i, j}+u_{i-1, j}}{h^{2}}+\frac{u_{i+1, j+1}-2 u_{i, j+1}+u_{i-1, j+1}}{h^{2}}\right]-\frac{1}{2}\left[q\left(x_{i}, t_{j}\right)+q\left(x_{i}, t_{j+1}\right)\right]
$$
We invoke Taylor's theorem to first separately estimate each term:
$$
\begin{aligned}
\frac{u_{i, j+1}-u_{i, j}}{k}=\frac{u(x, t+k)-u(x, t)}{k} &=\frac{\left[u(x, t)+k u_{t}(x, t)+k^{2} / 2 u_{n}(x, t)+O\left(k^{3}\right)\right]-u(x, t)}{k} \\
&=u_{t}(x, t)+(k / 2) u_{1 t}(x, t)+O\left(k^{2}\right) \\
\frac{1}{2}\left[q\left(x, t_{j}\right)+q\left(x_{i}, t_{j+1}\right)\right] &=\frac{1}{2}[q(x, t)+q(x, t+k)]=\frac{1}{2}\left[q(x, t)+\left[q(x, t)+k q_{t}(x, t)\right]+O\left(k^{2}\right)\right] \\
&=q(x, t)+(k / 2) q_{t}(x, t)+O\left(k^{2}\right)
\end{aligned}
$$
$$
\begin{aligned}
&\frac{u_{i+1, j}-2 u_{i, j}+u_{i-1, j}}{h^{2}}=\frac{u(x+h, t)-2 u(x, t)+u(x-h, t)}{h^{2}} \\
&=\frac{\left[u(x, t)+h u_{x}(x, t)+\left(h^{2} / 2\right) u_{x x}(x, t)+\left(h^{3} / 6\right) u_{x x}(x, t)+O\left(h^{4}\right)\right]-2 u(x, t)+}{h^{2}} \\
&+\frac{\left[u(x, t)-h u_{x}(x, t)+\left(h^{2} / 2\right) u_{x x}(x, t)-\left(h^{3} / 6\right) u_{x x}(x, t)+O\left(h^{4}\right)\right]}{h^{2}}=u_{x x}(x, t)+O\left(h^{2}\right) .
\end{aligned}
$$

Similarly, $\frac{u_{i+1, j+1}-2 u_{i, j+1}+u_{i-1, j+1}}{h^{2}}=u_{x x}(x, t+k)+O\left(h^{2}\right) .$ We use Taylor's theorem once again to obtain: $u_{x x}(x, t+k)=u_{x x}(x, t)+k u_{x x t}(x, t)+O\left(k^{2}\right)$. If we invoke all of these estimates into (*), the expression can be rewritten in the following form (for further notational convenience, we omit functional arguments since they are all $(x, t))$ :
$$
\begin{gathered}
u_{i}+(k / 2) u_{a}+O\left(k^{2}\right)-(\alpha / 2)\left[u_{x x}+O\left(h^{2}\right)+u_{x x}+k u_{x x t}+O\left(h^{2}+k^{2}\right)\right]-q-(k / 2) q_{t}+O\left(k^{2}\right)= \\
\left(u_{t}-\alpha u_{x x}-q\right)+(k / 2)\left\{u_{u t}-\alpha u_{x x t}-q_{t}\right\}+O\left(h^{2}+k^{2}\right)
\end{gathered}
$$
Now, the expression in parentheses is zero by the PDE. The expression in braces is the time derivative of the first expression. Thus, if the solution and $q$ are sufficiently differentiable, this expression will also be zero and we are left with the desired $O\left(h^{2}+k^{2}\right)$ estimate.

\textbf{\texttt{EFR 12.12:}} (a) The M-file is boxed below:
\begin{lstlisting}[frame=single, numbers=none]
functio n [x, t , U] = fwdtimecentspace(phi , L, A, B, T, N, M, alpha,q) 
% solve s the one-dimensional heat problem 
% u_t = alpha(t,x,u)*u_xx+q(x,t) 
% using the explicit forward time centered-space method. 
% Input variables: phi=phi(x) = initial wave profile function 
% L = length of rod, A =A(t)= temperature of left end of rod 
% u(0,t)=A(t), B=B(t) = temperature of right end of rod u(L,t)=B(t), 
% T= final time for which solution will be 
% computed, N = number of internal x-grid values, M = number 
% of internal t-grid values, alpha =alpha(t,x,u,u_x)= diffusivity of 
rod. 
% q = q(x,t) = internal heat source function 
% Output variables: t = time grid row vector (starts at t=0, ends at 
% t=T, has M+2 equally spaced values), x = space grid row vector, 
% U = (M+2) by (N+2) matrix of solution approximations at 
corresponding 
% grid points, x grid values will correspond to second 
(column)entries of U, y 
% grid values to first (row) entries of U. Row 1 of U corresponds to 
% t = 0. 

h = L/(N+1) ; k = T/(M+1) ; 
U=zeros(M+2,N+2); x=0:h:L; t=0:k:T; 
% Recall matrix indices must start at 1. Thus the indices of the 
% matrix will always be one more than the corresponding indices that 
% were used in theoretical development.

%Assign left and right Dirichlet boundary values. 
U(:,1)=feval(A,t)'; U(:,N+2)=feval(B,t)'; 

%Assign initial time t=0 values and next step t=k values. 
for i=2:(N+1) 
	U(1,i)=feval(phi,x(i)); 
end 

%Assign values at interior grid points 
for j=2:(M+2) 
for i=2:(N+1) 
mu(i)=k*feval(alpha,t(j-1),x(i),U(j-1,i))/h^2; 
qvec(i)=feval(q,x(i),t(j-1)); 
end 
% First form needed vectors and matrices, because we will be using 
the 
% thomas M-file, we do not need to construct the coefficient matrix T. 
V = zeros(N,l); V(1)=mu(2)*U(j-1,1); V(N)=mu(N + 1)*U(j-1,N+2); 
Q = k*qvec(2:N+1)';
 
%We now form the next time level approximation. Notice we have 
avoided 
%matrix multiplication. 
U(j,2:N+1)=(1-2*mu(2:N+1)).*U(j-1,2:N+1)+mu(2:N+1).*(U(j-1,1:N)+U(j-1,3:N+2)); 
end
\end{lstlisting}

(b) The M-file is boxed below:
\begin{lstlisting}[frame=single, numbers=none]
function [x, t, U] = backwdtimecentspace(phi, L, A, B, T, N, M, alpha,q) 
% solves the one-dimensional heat problem 
% u_t = alpha(t,x,u)*u_xx+q(x,t) 
% using the backward-time central-space method. 
% Input variables: phi=phi(x) = initial wave profile function 
% L = length of rod, A =A(t) = temperature of left end of rod 
% u(0,t)=A(t), B=B(t) = temperature of right end of rod u(L,t)=B(t), 
% T= final time for which solution will be 
% computed, N = number of internal x-grid values, M = number 
% of internal t-grid values, alpha =alpha(t,x,u)= diffusivity of rod. 
% q = q(x,t) = internal heat source function 
% Output variables: t = time grid row vector (starts at t=0, ends at 
% t=T, has M+2 equally spaced values), x = space grid row vector, 
% U = (M+2) by (N+2) matrix of solution approximations at 
corresponding 
% grid points, x grid values will correspond to second 
(column)entries of U, y 
% grid values to first (row) entries of U. Row 1 of U corresponds to 
% t = 0.

h = L/(N+1); k = T/(M+1); 
U=zeros(M+2,N+2); x=0:h:L; t=0:k:T; 
% Recall matrix indices must start at 1. Thus the indices of the 
% matrix will always be one more than the corresponding indices that 
% were used in theoretical development.
 
%Assign left and right Dirichlet boundary values.
U(:,1)=feval(A,t) '; U (:,N+2)=feval(B,t)'; 

%Assign initial time t=0 values and next step t=k values. 
for i=2:(N+1) 
	U(1,i)=feval(phi,x(i));
end 

%Assign values at interior grid points 
for j-2:(M+2) 
for i=2:(N+1) 
mu(i)=k*feval(alpha,t(j),x(i),U(j-1,i))/h^2; 
qvec(i)=feval(q,x(i) ,t(j)) ; 
end 
% First form needed vectors and matrices, because we will be using the 
% thomas M-file, we do not need to construct the coefficient matrix T. 
Q = k*qvec(2:N+1)'; 
V = zeros(N,1); V(1)=mu(2)*U(j,1); V(N)=mu(N+1)*U(j,N+2);

%Now perform the matrix multiplications to iteratively obtain solution
%values for increasing time levels.
c=U(j-1,2: (N+1)+V+Q;
a=-mu(2:N+1); b=a; a(N)=0; b(1)=0;
U(j,2:N+1)=thomas(a,1+2*mu(2:N+1),b,c);
end
\end{lstlisting}

\textbf{\texttt{EFR 12.13:}}  (a) We first need to construct an M-file for the inhomogeneity function, since it involves cases:

\begin{lstlisting}[frame=single, numbers=none]
function y = phiEFR12_13(x)
for i = 1:length(x)
	if x(i)<=3 & x(i)>=1, y(i) = 100;
	else, y(i)=0;
	end
end
\end{lstlisting}
The remaining input functions can be stored as inline functions: 

\begin{lstlisting}[frame=none, numbers=none]
alpha=inline('3', 'x', 't', 'u'); q = inline('0', 'x', 'y'); 
A=inline('0') ; B=inline('100*(l-exp(-t))' , 't') ;
\end{lstlisting}
It is now a simple matter to run the two programs and obtain the desired numerical graphs. We will use $N=80$ intemal $x$-grid values and $M=20$ internal time-grid values. This gives equal spacing of the time and space grids.

\begin{lstlisting}[frame=none, numbers=none]
>>[x, t, UCN] = cranknicolson(@phiEFR12_13, 4, A, B, 1, 80, 20, alpha,q); 
>> plot(x,UCN(22,:)) %plot of the CR solution profile at time t = 1. 
>> %compare w/ Figure 12.27b 
>> [x, t, UBT] « backwdtimecentspace(@phiEFR12_13, 4, A, B, 1, 80, 20, alpha,q); 
>> plot(x,UBT(22,:)) %plot of the BT solution profile at time t = 1. 
>> %compare w/ Figure 12.27a 
\end{lstlisting}

\noindent(b) With the data from part (a), the desired surface plots are readily obtained by the following commands. The results are shown below. 

\begin{lstlisting}[frame=none, numbers=none]
>> surf (x,t, UCN) , xlabel('x-values'), ylabel('t-values'), 
title ('Crank-Nicolson') 
>> surf(x,t,UBT), xlabel('x-values'), ylabel('t-values'), 
title ('BTCS') 
\end{lstlisting}
\begin{center}
\includegraphics[scale=0.9]{fig34}
\end{center}

\textbf{\texttt{EFR 12.14:}}(a) The code of the Example $12.9$ just needs a minor modification (in the line defining $U(j, 1)$ ). Since it is a short code, we give it here and provide details on how to obtain Figure $12.28 \mathrm{~b}:$

\begin{lstlisting}[frame=none, numbers=none]
h=1/20; k=1/1850 ; mu=k/h^2; 
N=21; M=1851; 
U=zeros(M+1,N); x=0:h:1 ; t=0:k:1 ;

%Assign initial time t=0 values and next step t=k values. 
for i=1:N, U(1,i)=100; end 
%Assign values at interior grid points 
for j=2:M+1
U(j,2:N-1)=(1-2*mu)*U(j-1,2:N-1)+mu*(U(j-1,3:N)+U(j-1,1:N-2)); 
U(j,1)= (1-2*mu)*U(j-1,1)+2*mu*(U(j-1,2)-h* U(j-1, 1)^1.5); 
U(j,N)= (1-2*mu) *U(j-1,N)+2*mu*(-h*U(j-1,N) +U(j-1, N-1)); 
end 

>> plot(x,U(1,:)) %initial temperature 
>> hold on, plot(x,U(11,:)), plot(x,U(21,:)), plot(x,U (81, :)), 
plot(x,U(121,:)) 
>> plot(x,U(241,:)), plot(x,U(441,:)), plot(x,U(661,:)), 
plot(x,U(801,:))
>>plot(x,U(1201,:)), plot(x,U(1600,:))
>>axis([0 1 0 111]), xlabel('space'), ylabel('temperature')
>> gtext('Initial temperature (t=0)') %Use the mouse to put in the first label.
>> [10 20 80 120 240 440 660 800 1200 1600]/1850 %time data for other labels
->ans = 0.0054 0.0108 0.0432 0.0649 0.1297 0.2378 0.3568 0.4324 0.6486 0.8649 
>> gtext('t = 0.005') %Use the mouse to place this label, repeat for rest of labels
\end{lstlisting}
(b) Physically, the heat in the rod will continue to be lost forever as the temperature distribution decays (but never reaches zero). The fact that it will never be totally lost follows from the fact there is an exponential decay of heat from the right $\mathrm{BC}$ and (eventually) less than exponential decay from the left BC. Since $T^{1.5}>T$ only when $T>1$, in fact as $T$ approaches zero the ratio $T / T^{1.5}=1 / \sqrt{T} \rightarrow \infty$, it follows that eventually the heat will be lost much, much faster on the right end than on the left. Thus, the temperature at the right end should eventually fall below that of the left. To see this with MATLAB, we will have to let the solver code of part (a) run for more time. It is not immediately clear how long we should run it (until the temperatures at the ends fall to be less than one), but after some experimentation, we see that letting it run until $t=2$ will be sufficient. The code of part (a) is easily modified to obtain the two plots we give below. The first one is for $t=2$ and the second is for $t=4$.
\begin{center}
\includegraphics[scale=0.9]{fig35}
\end{center}

\noindent(c) Physically, the BC conditions mean that heat is being absorbed at the left end at a rate proportional to the temperature there and is being lost at the right end at a rate proportional to the temperature there. It follows that the left end will always be hotter than the right, and there will be a net exponential gain of heat absorption of the rod, the rate being equal to the difference of the left temperature less the right temperature. Since the diffusion takes time for the heat from the left side to make it to the right, the difference in temperatures (between left and right end) will continue to increase. The temperture in the heat in the rod will thus increase without bound. To confirm this phenomenon on MATLAB, the solver code in Part (a) needs only to have changed the line defining $\cup(j, 1)$ to read as follows.
$$
U(j, 1)=(1-2 * m u) * U(j-1,1)+2 * m u *(U(j-1,2)+h \star U(j-1,1)) ;
$$
Below we include two plots.
\begin{center}
\includegraphics[scale=0.9]{fig36}
\end{center}

\textbf{\texttt{EFR 12.15:}} (a) The $x$-grid will have two ghost nodes, just as in Example 12.9:
$$
-h=x_{0}<0=x_{1}<\cdots<x_{N}=L<x_{N+1}=L \text {. }
$$
The central difference approximation for the left BC gives $\left[u_{2, j}-u_{0, j}\right] / 2 h \approx a u_{1, j}+b$. Solving this for the ghost node value produceds $u_{0, j} \approx u_{2, j}-2 h\left(a u_{1, j}+b\right)$. Assuming the PDE is valid on the left boundary, we substitute this approximation into the discretization (50):\\
$\quad-\mu u_{i-1, j+1}+2(1+\mu) u_{i, j+1}-\mu u_{i+1, j+1}=\mu u_{i-1, j}+2(1-\mu) u_{i, j}+\mu u_{i+1, j}+k\left[q_{i, j}+q_{i, j+1}\right]$\\ (when $i=1)$, to obtain\\ $2(1+\mu+\mu h a) u_{1, j+1}-2 \mu u_{2, j+1}+2 h b \mu=2(1-\mu-\mu h a) u_{1, j}+2 \mu u_{2, j}+k\left[q_{i, j}+q_{i, j+1}\right]-2 h b \mu$ (*).
Similarly, the central difference approximation on the right BC gives $u_{N+1, j} \approx u_{N-1, j}+2 h\left(c u_{N, j}+d\right)$, and when this is incorporated into (50), we obtain:\\
$$
-2 \mu u_{N-1, j+1}+2(1+\mu-\mu h c) u_{N, j+1}-2 h d \mu=2 \mu u_{N-1, j}+2(1-\mu-\mu h c) u_{N, j}+k\left[q_{N, j}+q_{N, j+1}\right]+2 h d \mu
$$
(**).
The required M-file can now be obtained with some small modifications of the cranknicolson Mfile of Program 12.3. What needs to be done is that the first and last rows of the linear system need to be changed according to (*) and (**). We refer the complete code to the ftp site for this book (see note at the beginning of this appendix).\\
(b) The following code will use the M-file of part (a) to re-solve the BVP of Example $12.9$ using the same grid.
\begin{lstlisting}[frame=none, numbers=none]
>> phi = inline ('0'); q = inline ('0', 'x', 't'), alpha = inline ('1', 't', 'x', 'u') 
>> [x, t, U]=cranknicolsonRobinLR(phi, 1, [1 0], [-1 0], 1, 21, 1851, alpha, q)
\end{lstlisting}
Plots can be accomplished with this data just as in the solution of EFR 12.14, and the results are graphically indistinguishable from those obtained in the example. 

\noindent\hrulefill \\
\textbf{\texttt{CHAPTER 13: THE FINITE ELEMENT METHOD}}
\textbf{\texttt{EFR 13.1:}}For $\Phi_{3}$, the code given in Example 13.1 just needs a small modification to accommodate the change of node. Indeed, in the for loop, the three modified lines are:
\begin{lstlisting}[frame=none, numbers=none]
if ismember(3,T(L,:))==1,index=find(T(L,:)=*3);nv=[T(L,1:2)3] ; nv(index)=T(L,3) The new output of the modified loop is then the following matrix A:
\end{lstlisting}
\begin{math}
\rightarrow A=\begin{array}{llll} 
1 & -1 & 0 & 1 \\
5 & -1 & 0 & 1
\end{array}
\end{math}

From this we can write: $\Phi_{3}(x, y)=\left\{\begin{array}{cc}-x+1, & \text { if }(x, y) \in T_{1}, \\ -x+1, & \text { if }(x, y) \in T_{5}, \\ 0, & \text { otherwise. }\end{array}\right.$\\
In a similar fashion, we find that:\\
$\Phi_{4}(x, y)=\left\{\begin{array}{cccc}
\frac{2}{3}x-y-\frac{2}{3}, & \text { if }(x, y) \in T_{3}, & -x-y+\frac{7}{2}, &\text { if }(x, y) \in T_{4} \\ 

\frac{2}{3}x-\frac{2}{3}, & \text { if }(x, y) \in T_{6}, & y+1, &\text { if }(x, y) \in T_{7} \\ 

-x+y+\frac{7}{2}, & \text { if }(x, y) \in T_{8}, & 0, &\text {otherwise.}\end{array}\right.$\\





\textbf{\texttt{EFR 13.2:}} (a) As a quadrilateral has four vertices and a linear function in $x$ and $y$ has only three parameters (see equation (2)), linear functions are not versatile enough to accommodate arbitrarily specifying four numerical values at the vertices of a quadrilateral.
(b) A generic function of $x$ and $y$ having four parameters is a so-called bilinear function: $a x y+b x+c y+d$, these are often used for quadrilateral elements. In the special case where the elements are rectangles parallel to the axis, the matter is further discussed in some of the exercises at the end of Section 13.2.

\textbf{\texttt{EFR 13.3:}} (a) The M-file is boxed below:
\begin{lstlisting}[frame=single, numbers=none]
function voronoiall(x,y) 
% M-file for EFR 13.3 
% inputs: two vectors x and y of the same size giving, respectively, 
% the x- and y-coordinates of a set of distinct points in the plane; 
% outputs: none, but a graphic will be produced of the Voronoi 
% regions corresponding to the point set in the plane, 
% including the unbounded regions 
n=length(x); 
xbar = sum(x)/n; ybar = sum(y)/n; %centroid of points 
md = max(sqrt(x-xbar).^2 + sqrt(y-ybar).^2); 
%maximum distance of points to centroid 
mdx = max(abs(x-xbar)); mdy - max(abs(y-ybar)); 
%max x- and y- distances to averages 
% We create additional points that lie in a circle of radius 3md 
% about (xbar, ybar). We deploy them with angular gaps of 1 degree, 
% this will be suitable for all practical purposes. 
xnew=x; ynew=y; 
for k = 1:360 
	xnew(n+k)=xbar+3*md*cos(k*pi/180) ; 
	ynew(n+k)=ybar+3*md*sin(k*pi/180); 
end 
voronoi(xnew,ynew) 
axis([min(x)-mdx/2 max(x)+mdx/2 min(y)-mdy/2 max(y)+mdy/2] ) 
\end{lstlisting}
\noindent b) With this program, we can easily re-create Figure 13.9(b):
\begin{lstlisting}[frame=none, numbers=none]
>> N=[1 1;5/ 2 1;0 0;1 0;5/ 2 0;7/ 2 0;1 -1;2. 5 -1];x=N(:,1); y=N(:,2); 
>> voronoiall(x,y) 
\end{lstlisting}

\textbf{\texttt{EFR 13.14:}}(a) Although the scheme we used in the solution of part (c) of Example $13.2$ can be adapted for this triangulation, we will introduce a slightly different approach. Specifically, we will take advantage of the fact that intersections of circles (centered at $(0,0)$ ) all have the same boundary angles. At each iteration, we will deploy nodes on circles of equally spaced radii in the annular sector domains: $\Omega_{n}=\left\{(x, y) \in \Omega: 1 / 2^{n}<\operatorname{dist}((x, y),(0,0))<2 \cdot\left(1 / 2^{n}\right)\right\}$ for $n=1,2, \ldots$ By the special shape of $\Omega$, we\\ get the following exact formula for the area of $\Omega_{n}: \operatorname{Area}\left(\Omega_{n}\right)=\frac{1}{2} \cdot \frac{5 \pi}{3}\left[\left(2 \cdot 2^{-n}\right)^{2}-\left(2^{-n}\right)^{2}\right]=\frac{5 \pi}{2} 2^{-2 n}$.\\ Thus, if we were to deploy (approximately) 100 nodes in $\Omega_{n}$ with a uniform grid, the gap size $s$ should\\ (approximately) satisfy: $100 s^{2}=\frac{5 \pi}{2} 2^{-2 n}$ or $s=\sqrt{\pi / 40} \cdot 2^{-n}$. We use this for the gaps between radii, and, on average, arrange for a similar gap size between adjacent nodes on a given circle of deployment. Since the domain is not convex, we will use additional ghost nodes (as in Example 13.3) to help us detect and remove unwanted elements.

\begin{lstlisting}[frame=single, numbers=none]
%Script for EFR 13.4a 
count=1; 
for n=1:7 
s=sqrt(pi/40)/2^n; 
len = 5*ρi/2/2^n; %avg. arclength of node circular arc in Omega_n 
nnodes= ceil(len/s); %number of nodes to put on each circular arc 
ncirc= ceil(1/2^n/s); 
%number of circlular arcs w/ to put nodes on Omega_n 
rads = linspace(2/2^n, 1/2^n+s/2, ncirc); 
%radii of circular arcs with nodes 
angles = linspace(pi/6, 11*pi/6, nnodes); %angles for node deployment

%deploy nodes: 
for r=rads 
	for theta = angles 
		x(count)=r*cos(theta); y(count)=r*sin(theta); count=count+1; 
	end 
end 
end
%the final portion takes a slightly different approach since we want 
%to deploy nodes throughout the whole sector (not just the annulus). 
%We will thus want the circles of deployment to have radii all the 
%way down to s(gap size), but on the smaller circles we should deploy 
%less nodes
n=8; s=sqrt(pi/40)/2^n; 
len = 5*pi/2/2^n; 
%avg. arclength of node circular arc in Omega_n-outer circles 
nnodes= ceil(len/s); 
%number of nodes to put on each outer circular arc 
rads = linspace(2/2^n, 0, ceil(2/2^n/s)); 
%radii of circular arcs with nodes 
angles = linspace(pi/6, 11*pi/6, nnodes); %angles for node deployment

%delploy nodes 
for r=rads 
	for theta = linspace(pi/6, 11*pi/6, ceil(len/s*r/(2/2^n))) 
		x(count)=r*cos(theta); y(count)=r*sin(theta); count=count+1; 
	end 
end 

% Put in extra ghost nodes to detect bad elements 
% There are several ways to do this, we will deploy them in a 
% sufficient pattern on the positive x-axis. 
nnodes=count-1; %number of nodes (=932) 
for k=0:7 
	x(count)=1/2^k; y(count)=0; count=count+1; 
	x(count)=.75/2^k; y(count)=0; count=count+1; 
end 
for k=rads 
	if k>0 
		x (count)=k; y(count)=0; count=count+1;
	end 
end 
tri = delaunay(x,y); 
%The following two commands will plot the triangulation containing 
%the ghost nodes, the latter indicated by pentacles. This plot and a 
%magnification are shown in the %figure below.
\end{lstlisting}
\begin{center}
\includegraphics[scale=0.9]{fig37}
\end{center}
By the way that the ghost nodes were deployed, the unwanted elements are precisely those that have a ghost node as one of their vertices. The remaining code will search and destroy these elements, it is modeled after that of Example 13.3. The final triangularon and a zoomed view are shown in the two figures below.

\begin{lstlisting}[frame=single, numbers=none]
plot(x(nnodes+1:count-1), y(nnodes+1:count-1), 'rp')
hold on, trimesh (tri,x, y) , axis('equal')
%>> size(tri) 
%ans = 
% 	1876     3
badelcount=1; 
for e11=1:1876 
	if max(ismember(nnodes+1:count-1, tri(e11,:))) 
		badel(badelcount)=e11; 
		badelcount=badelcount+1;
	end
end
clf 
tri=tri(setdiff(1:1876,badel),:); 
x=x(1:nnodes); y=y(1:nnodes); 
trimesh(tri,x(1:nnodes),y(1:nnodes)), axis('equa1')
\end{lstlisting}
\begin{center}
\includegraphics[scale=0.9]{fig38}
\end{center}


\noindent (b) We take the vertices of the domain to be: $(0,0),(2,0),(2,1),(-1,1),(-1,-2)$, and $(0,-2)$. The code below presents yet another variation of node deployment schemes. The crucial part (Stage 2 in the code below) is the deployment of nodes inside the circle with center $(0,0)$ and radius $0.8$. We put an equal number of nodes (13) on each such circle. Because of the exponential decay of the radii, the gaps between radii remain close to the arclength gaps on the corresponding circles. The code below uses ghost nodes and they can be viewed by executing the code up to the line with the first trimesh command (as in part (a)). We show only a figure of the final triangulation along with a zoomed view (without axes). 

\begin{lstlisting}[frame=single, numbers=none]
%Script for EFR 13.4b 
%We deploy the nodes in three stages 
%Stage 1: Outside the circle of radius 1, center (0,0), squarelike 
%grid with gap size s = 0.2 
%We can do boundary and interior nodes together:
count=1;
for xt=-1:.2:2 
	for yt=-2:.2:1 
		pt=[xt yt]; %test point 
		if norm(pt,2)>.8+.1 & ~(xt>0 & yt<0) 
	%these conditions ensure the test point is in the domain and a 
	%safe distance from the boundary of the outer circle of Stage 2 
		x(count)=xt; y(count)=yt; count=count+1; 
		end 
	end 
end 
%Stage 2: Put nodes on concentric circles with exponential decay of 
%radii 
angles=0:pi/16:3*pi/2; 
%this vector of angles will not change in the loop 
for k=1:40 
	r=.8^k; 
	for theta = angles 
		x (count)=r*cos(theta); y(count)=r*sin(theta); count=count+1; 
		if k==0 & (x(count-1)<-.95|y(count-1)>.95) 
count=count-1; end %discard points too close to domain boundary 
	end 
end 
%Stage 3: Put nodes on the inside of the last circle of Stage 2 
gap=3*pi/4*r/13; 
%approx. gap size gotton by dividing arclength of last circle 
%by number of nodes that were put on it 
xvec=linspace(-r,r,2*ceil(r/gap)+1); yvec=xvec; 
for xt=xvec 
	for yt=yvec 
		pt=[xt yt]; %test point 
			if norm(pt,2)<=r-gap/2 & ~(xt>0 & yt<0) 
				%these conditions ensure the test point is in the domain 
				%and a safe distance from the boundary of the circle 
					x(count)=xt; y(count)=yt; count=count+1; 
		end 
	end 
end 
%plot(x,y, 'rp') 
tri = delaunay(x,y); 
hold on, trimesh(tri,x,y), axis('equal')

% Now we put in extra ghost nodes to detect bad elements 
% There are several ways to do this, we will deploy them in a 
% sufficient pattern on the ray theta = - pi/4 
nnodes=count-1; %number of nodes 
x(count)=1; y(count)=-1; count-count+1;
for k=0:40
x(count)=.8^k*cos(-pi/4); y(count)=.8^k*sin(-pi/4); count=count+1; 
end
for k=r:-gap:gap 
x(count)=k*cos(-pi/4); y(count)=k*sin(-pi/4); count=count+1;
end 
x(count)=gap/2*cos(-pi/4); y(count)=gap/2*sin(-pi/4); count=count+1; 
tri = delaunay(x,y); 
clf, plot(x(nnodes+1:count-1), y(nnodes+1:count-1), 'rp') 
hold on, trimesh(tri,x,y), axis('equal')
size(tri) 
%ans = 
%		2406	3
badelcount=1; 
for e11=1:2406 
	if max(ismember(nnodes+1:count-1, tri(e11,:))) 
		badel(badelcount)=e11; 
		badelcount=badelcount+1; 
	end 
end 
clf
tri=tri(setdiff(1:2406,badel),:); 
x=x(1:nnodes); y=y(1:nnodes); 
trimesh(tri,x,y), axis('equal'), axis off
\end{lstlisting}
\begin{center}
\includegraphics[scale=0.9]{fig39}
\end{center}


\textbf{\texttt{EFR 13.5:}} (a) In multivariable calculus, it is proved that the gradient vector of a function of two variables points in the direction in which the partial derivative is maximum and has magnitude equal to this maximum partial derivative. Also, the gradient is perpendicular to the direction in which the partial derivatives are zero. Since $\phi$ is a linear function, its gradient is a constant vector. Since the function $\phi$ is zero on the line joining $v_{1}$ and $v_{2}$, it follows that the gradient must be perpendicular to this side of $T$ and therefore it must be parallel to $\vec{a}$ (the opposite direction would have negative partial derivative). The magnitude of the partial derivative, since the function is linear, can be gotten by taking the difference quotient of the values of $\phi$ at the tip and tail of $\vec{a}$ over the length of the vector $\vec{a}$ and this completes the proof of (a).
(b) The integral will be unchanged if we perform a rotation change of variables (which has Jacobian $=$ 1), so we may assume that the line joining $v_{1}$ and $v_{2}$ is the $x$-axis. Write $v_{1}=(a, 0), v_{2}=(b, 0)$ and let $c$ denote the $x$-coordinate of $v_{3}$. Thus $a \leq c \leq b$ and $\phi(x, y)=y /\|\vec{a}\|$. Assume first that $a<c<b$. The height of the triangle at any value of $x \in[a, b]$ is given by:
$$
h(x)= \begin{cases}\frac{\|\vec{a}\|}{c} \cdot\left(\frac{x-a}{c-a}\right), & \text { if } x \leq c, \\ \|\vec{a}\| \cdot\left(1-\frac{x-c}{b-c}\right), & \text { if } x>c .\end{cases}
$$
Thus we may compute:
$$
\iint_{T} \phi(x, y) d x d y=\int_{a}^{b h(x)} \int_{0}^{h} \frac{y}{\|\vec{a}\|} d y d x=\int_{a}^{b} \frac{h(x)^{2}}{2} d x=\frac{\|\vec{a}\|}{2} \int_{a}^{c}\left(\frac{x-a}{c-a}\right)^{2} d x+\frac{\|\vec{a}\|}{2} \int_{c}^{b}\left(1-\frac{x-c}{b-c}\right)^{2} d x .
$$
These two integrals are easily done by $u$-substitution. In the first one, we let $u=\frac{x-a}{c-a}$, so $d u=\frac{d x}{c-a}$ and the integral becomes: $\int_{a}^{c}\left(\frac{x-a}{c-a}\right)^{2} d x=(c-a) \int_{0}^{1} u^{2} d u=\frac{1}{3}(c-a)$. Similarly, the second integral is $\frac{1}{3}(b-c)$; combining these gives $\iint_{T} \phi(x, y) d x d y=\frac{1}{3} \frac{\|\vec{a}\|}{2}(b-a)=\frac{1}{3} \operatorname{Area}(T)$, as asserted. In the remaining case that $c=a$ or $c=b$ (so the triangle is a right triangle), the function $h(x)$ can be written as a single formula and the above proof simplifies.


\textbf{\texttt{EFR 13.6:}}
 If $u_{\text {old }}$ denotes the exact solution of the BVP of Example 13.5, we let $u_{\text {new }} = u_{\text {old }}+1$. Certainly $u_{\text {new }}$ satisfies the PDE $-\Delta u=f(x, y)$ since $u_{\text {old }}$ does. Also, since $u_{\text {old }} \equiv 1$ on the boundary, we get that $u_{\text {new }} \equiv 2$ on the boundary. Thus $u_{\text {new }}$ will solve the modified BVP. Since the coefficients of the stiffness matrix (see $\left.\left(15^{l}\right)\right)$ do not depend on the boundary values, this matrix $A$ will be the same for both problems. The only change will be in the load vector coefficients; now $\left(16^{\prime}\right)$ takes on the following form:
$$
b_{\alpha}^{\ell}=\iint_{T_{l}} f \Phi_{i_{\alpha}} d x d y-2 \sum_{s=4,5} \iint_{T_{l}} \nabla \Phi_{s} \cdot \nabla \Phi_{i_{\alpha}} d x d y(1 \leq \alpha \leq 3) .
$$
The only difference from the example is the presence of the factor of 2 . Since the computations leading to the load vector $b$ parallel very closely those of Example 13.5, we simply summarize the element-byelement updates of the vector $b$ :
$$
\begin{aligned}
&\ell=1: b=\left[\begin{array}{l}
2 \\
0
\end{array}\right], \ell=2: b=\left[\begin{array}{c}
2+3 / 2 \\
0
\end{array}\right]=\left[\begin{array}{c}
7 / 2 \\
0
\end{array}\right], \ell=3: b=\left[\begin{array}{c}
7 / 2 \\
0+3 / 2
\end{array}\right]=\left[\begin{array}{l}
7 / 2 \\
3 / 2
\end{array}\right] \\
&\ell=4: b=\left[\begin{array}{c}
7 / 2 \\
3 / 2+11 / 6
\end{array}\right]=\left[\begin{array}{c}
7 / 2 \\
10 / 3
\end{array}\right], \ell=5: b=\left[\begin{array}{c}
7 / 2+2 \\
10 / 3
\end{array}\right]=\left[\begin{array}{l}
11 / 2 \\
10 / 3
\end{array}\right], \ell=6: b=\left[\begin{array}{c}
11 / 2+3 / 2 \\
10 / 3
\end{array}\right]=\left[\begin{array}{c}
7 \\
10 / 3
\end{array}\right], \\
&\ell=7: b=\left[\begin{array}{c}
7 \\
10 / 3+3 / 2
\end{array}\right]=\left[\begin{array}{c}
7 \\
29 / 6
\end{array}\right], \ell=8: b=\left[\begin{array}{c}
7 \\
29 / 6+11 / 6
\end{array}\right]=\left[\begin{array}{c}
7 \\
20 / 3
\end{array}\right] .
\end{aligned}
$$
If we solve the resulting matrix equation $A x=b$; we get (to 4 decimals) $x(1)=1.9869$, and $x(2)=$ 1.9179. Comparing with the solutions of the original system: $x(1)=0.9278$ and $x(2)=1.0484$, we see that the numerical solutions are somewhat close, but definitely do not differ by one. With finer triangulations, the exact relationship would be made more apparent.


\textbf{\texttt{EFR 13.7:}} (a) We first draw a picture of the region $S$ on which the integration is to take place, and realize it lying between two functions of $x$; see the left figure below. It is convenient to break the integral up into two pieces since the top function experiences a formula change at $x=\cos (\pi / 4)$.
\begin{lstlisting}[frame=none, numbers=none]
>> syms x y 
>> Int_A = quad2d(x*y^2,0 , cos(pi/4) , 0, x)+quad2d(x*y^2,cos(pi/4 ), 1, 0, sqrt(1-x^2))
-> Int_A = 0.0236 (This is the numerical approximation to the first integral in "format short.") 
(b) The picture, shown on the right below, shows that the curves intersect when x is negative. We first find this intersection point:
find this intersection point: 
>> xmin = f zero (inline ('x^2-1-exp(x)'),-1) -> xmin =-1.1478 
>> Int_B = quad2d(exp(1-x^2-2*y^2 ),xmin, 0, x^2-1, exp(x)) ->Int_B = 2.0661
\end{lstlisting}
\begin{center}
\includegraphics[scale=0.9]{fig40}
\end{center}
Note: Both plots were created in MATLAB using the built-in function patch . The syntax is as 
follows:\\
\begin{center}
\begin{tabular}{|c|c|c|} 
 \hline
\begin{lstlisting}[frame=none, numbers=none]
patch([x xrev], 
[flow f toprev] , [r g b] )
				->
\end{lstlisting}
 
&

\begin{lstlisting}[frame=none, numbers=none]
This command will produce a graphic of a shaded 
region between two functions. Here x is a vector 
of x-coordinates for an interval on which the 
corresponding vectors flow and ftop_rev 
represent two functions. The function represented 
by flow has its graph lying below the one 
represented by ftop_rev . The syntax requires 
also as input the vector xrev that is the vector x 
taken in reverse order. The vector f top_re v 
(representing the top function) correspondingly 
needs to be inputted in reverse order. The final 
input is a 3x1 rgb vector of numbers between 0 
and 1 that will determine the color of the patch.
\end{lstlisting}


\end{tabular}
\end{center}
As an example, we give the code used to create the second plot:
\begin{lstlisting}[frame=none, numbers=none]
>> x=xmin:.01:0 ; 
>> for i-1:length(x), xrev(i)=x(length(x)+l-i); end 
>> patch([ x xrev], [x.^2-1 exp(xrev)], [.5 .5 .5]), hold on 
>> t = -1.5:.01:.5; plot(t,t.^2-1, 'b'), plot(t,exp (t), 'b'), 
>> axis([-1.5 .5 -2 2]) 
>> gtext('y = exp(x)') %use mouse to place text on graphic window 
>> gtext('y = x^2-1') %use mouse to place text on graphic window 
\end{lstlisting}
Some embellishments were done to the graph using menu options on the graphics window. 

\textbf{\texttt{EFR 13.8:}} (a) The M-file is boxed below:
\begin{lstlisting}[frame=single, numbers=none]
function integ-triangquad2d(fun,vl,v2,v3) 
% M-file for EFR 13.8. This function will integrate a function 
% of two variables x and y over a triangle T in the plane. 
% It uses the M-file 'quad2d' of Program 13.1 
% Input variables: fun = a symbolic expression (using one or both of 
% the symbolic variables x and y, v1, v2, and v3: three length 2 
% vectors giving the vertices of the triangle T in the plane. 
% NOTE: Before this program is used, x and y should be declared as 
% symbolic variables.syms x y u
vys = [v1(2) v2(2) v3(2)]; 
vxs = [v1(1) v2(1) v3(1)]; 
minx=min(vxs); maxx=max(vxs); 
miny=min(vys) ; 
minyind =find(vys==miny); 
minxind =find(vxs==minx); 
maxxind =find(vxs==maxx); 
if length(minxind)==2|length(maxxind)==2 %triangle has a vertical side
	if length(minxind)==2 
		vertx=minx; 
		vertymax=max(vys(minxind)); 
		vertymin=min(vys(minxind)) ; 
	else 
		vertx=maxx; 
		vertymax=max(vys(maxxind)) ; 
		vertymin=min(vys(maxxind)); 
	end 
	thirdind = find(vxs~= vertx); 
	topslope=sym((vys(thirdind)-vertymax)/(vxs(thirdind)-vertx)); 
	botslope=sym((vys(thirdind)-vertymin)/(vxs(thirdind)-vertx)); 
	ytop=topslope*(x-vxs(thirdind))+vys(thirdind); 
	ylow=botslope*(x-vxs(thirdind))+vys(thirdind); 
	integ = quad2d(fun,minx,maxx,ylow,ytop); 
else %no vertical sides so vertices have 3 different x coordinates
	midind = find(vxs>minx& vxs<maxx); %index of middle vertex 
	longslope=sym((vys(maxxind)-vys(minxind))/(maxx-minx)); 
	ylong = longslope*(x-vxs(minxind))+vys(minxind); 
	if vys(midind)>subs(ylong,x,vxs(midind)); 
	%long edge lies below mid vertex 
	topleftslope = sym{(vys(midind)-vys(minxind))/(vxs(midind)-... 
vxs(minxind)));
	toprgtslope = sym((vys(midind)-vys(maxxind))/(vxs(midind)- ... 
vxs(maxxind))); 
	ytopleft = topleftslope*(x-vxs(midind))+vys(midind); 
	ytoprgt = toprgtslope* (x-vxs (midind))+vys (midind) ; 
	integ = quad2d(fun,minx, vxs(midind),ylong, ytopleft)+ ... 
		quad2d(fun,vxs(midind),maxx,ylong,ytoprgt);
	else %long edge lies above mid vertex 
botleftslope = sym((vys(midind)-vys(minxind))/(vxs(midind)- ...
				vxs(minxind))); 
	botrgtslope = sym((vys(midind)-vys(maxxind))/(vxs(midind)- ... 
		vxs(maxxind))); 
	ybotleft = botleftslope*(x-vxs(midind))+vys(midind); 
	ybotrgt = botrgtslope*(x-vxs(midind))+vys(midind); 
	integ = quad2d(fun,minx,vxs(midind), ybotleft, ylong)+ ... 
		quad2d(fun,vxs(midind),maxx,ybotrgt,ylong);
	end
end
\end{lstlisting}
\noindent(b) To recalculate the integrals of Example 13.5, the following commands will suffice and result in the 
same outputs that were obtained in the example:

\begin{lstlisting}[frame=none, numbers=none]
>> syms x y 
>> v1 = [1 3]; v2 = [5 1]; v3 = [4 6]; %Triangle of Example 13. 5 
>> triangquad2d(2*x*y^2,v1,v2,v3 ) ->ans = 724.8000 
>> triangquad2d(sin(x*y*sqrt(y)) ,v1, v2, v3) ->ans = 0.1397 
The remaining integrals can be done in the same swift fashion. We store separately the vertices of the two triangles T1 and T2: 
>> v1 = [0 0]; v2 = [6 0]; v3 = [12 2]; %Triangle T1 of EFR 13.8 
>> V1 = [1 3]; V2 = [3 2]; V3 = [2 5]; %Triangle T2 of EFR 13.8
>> int_1 = triangquad2d(1,vl,v2,v3) ->int_1=6 
>> int_2 = triangquad2d(1,V1,V2,V3 ) -> int_2 = 2.5000 
>> int_3 = triangquad2d(2*x^2,v1,v2,v3) -> int_3 = 504 
>> int_4 = triangquad2d(sin(x^2),V1,V2,V3) -> int_4 = -0.2998 
\end{lstlisting}
These numerical calculations are all in agreement with the exact answers that were provided.\\

\textbf{\texttt{EFR 13.9:}} We will use modification of the method used in part (c) of Example 13.2. In that example, a similar node deployment was required on the same domain, except that there we wanted more nodes to be focused near the boundary point $(1,0)$ and here we want the focus area to be the boundary point $(\cos (3), \sin (3))$. What we will do is very slightly modify the node deployment code of the example (since here we want less nodes) and then simply rotate the node set by an angle of $\theta=3$ (using the rotation transformation of Section 7.2). The rotation idea is quite a natural one; it could be circumvented, but then we would need a more serious modification of the code of the example. Since the codes are long, we indicate only the changes needed for the present problem.

Referring to the notations of the solution of part (c) of Example 13.2, in the determination of the gap size $s$ to use in the region $\Omega_{n}$, we will use roughly 10 nodes (rather than 100) per such region, so $s$ \\should satisfy $10 \cdot s^{2} \leq \operatorname{Area}\left(\Omega_{n}\right) \leq \frac{3 \pi}{2} 2^{-2 n}$ or $s \leq \sqrt{3 \pi / 20} \cdot 2^{-n}$. If we then run through 8 iterations (n nuns from 0 to 7) of deploying nodes just as in the example, we see that the nodes are a bit sparse in the first two regions. To mitigate this, we make $s$ a bit smaller in the first two iterations. If we replace the first three lines of the node deployment code of the example with the following four lines (and run the rest of the code), we will arrive at a triangulation that looks quite appropriate.

\begin{lstlisting}[frame=none, numbers=none]
>> n=0; nodecount=1; 
>> while n<8 
s=sqrt(3*pi/20)/2^n; 
if n==0, s = s/3; elseif n ==1, s=s/2; end 
\end{lstlisting}
\noindent This node set should now be rotated by an angle of $\theta=3$, and this is done using the rotation matrix of Section 7.2:

\begin{lstlisting}[frame=none, numbers=none]
>> Rot=[cos(3 ) -sin(3); sin(3) cos(3)]*[x; y] ; 
>> xn = Rot(1,:); yn = Rot(2,:); %newly rotated nodes for desired 
triangulation.
\end{lstlisting}
\noindent Now, in order to be able to more easily use the assembly code of Example 13.7, we should reorder the nodes so that the boundary nodes appear last. This is accomplished with the following commands: 

\begin{lstlisting}[frame=none, numbers=none]
bdyind = find(xn.^2 + yn.^2 > 1 - 10*eps); 
size(xn), size(bdyind) -> 1	123,	1	38 
intind = setdiff(1:123, bdyind); %these are the indices of interior nodes 
xn = [xn(intind) xn(bdyind)]; %reordered x-coordinates of nodes 
yn = [yn(intind) yn(bdyind)]; %reordered x-coordinates of nodes 
tri=delaunay(xn,yn); 
trimesh(tri,xn,yn), axis('equal') %triangulation is shown below left

We  now store the boundary values: 
for i=86:123 
th=cart2pol(x(i),y(i)); 
if th<0, th=th+2*pi; end 
%need to ensure th is in domain of boundary data function 
c(i)=ex_13_7_bdydata(th) ; 
end 

The assembly code of the example will now work very well in this situation; we need only change the first three lines as follows:
N=[xn' yn']; 
E=tri; 
n=85; m=123; syms x y
\end{lstlisting}
\noindent When this and the rest of the code is run, we will have created the numerical solution's values stored as a vector c. The exact solution's values can be created just as in the example (the code is verbatim) and stored as a vector cp. This being done, the following command will plot the error of the numerical solution; the plot is shown on the right. 
\begin{lstlisting}[frame=none, numbers=none]
>> trimesh(E,xn,yn,abs(c-cp)) 
\end{lstlisting}
\noindent Notice that the maximum error is seen to be smaller than that obtained in part (b) of the example (cf. Figure 13.38b), using a lot less nodes but a more appropriate node deployment strategy. 
\begin{center}
\includegraphics[scale=0.9]{fig41}
\end{center}

\textbf{\texttt{EFR 13.10:}} (a) The M-file is boxed below:
\begin{lstlisting}[frame=single, numbers=none]
function int = gaussianintapprox(f,V1,V2,V3) 
% M-file for numerically approximating integral of a function f(x,y) 
% over a triangle in the plane with vertices V1, V2, V3 
% Approximation is done using the Gaussian quadrature formula (24) 
% of Chapter 13. 
% Input Variables: f = an inline function or an M-file of the 
% integrand specified as a function of two variables: x and y 
% V1, V2, V3 length 2 row vectors containing coordinates of the 
% vertices of the triangle. Output variable: int = approximation 
A=feval(f,(V1(1)+V2(1))/2, (V1(2)+V2(2))/2) ; 
B=feval(f,(V1(1)+V3(1))/2,(V1(2)+V3(2))/2); 
C=feval(f,(V2(1)+V3(1))/2,(V2(2)+V3(2))/2); 
M=[V1 1;V2 1; V3 1]; 
area=abs(det(M))/2; %See formula (5) of Chapter 13 
int=area*(A+B+C)/3;
\end{lstlisting}

\noindent(b) After creating and storing the triangulation for part (c) of Example 13.7, and then the boundary values (just as was done in the example), the first three lines of the assembly code should read as follows:
\begin{lstlisting}[frame=none, numbers=none]
>> N=[x' y'] ; 
>> E=tri ; 
>> A=zeros(n); b=zeros(n,1) ; 
\end{lstlisting}

\noindent(Same as before, except now we do not need symbolic variables.) The rest of the assembly code only needs changing in the two places where the numerical integrator triangquad2 d was used. To save space, we include the relevant modified passages here; the ftp site for this book includes a file for the complete code. 

\begin{lstlisting}[frame=none, numbers=none]
%update stiffness matrix 
for i1=1:length(intnodes) 
for i2=1:length(intnodes) 
fun1 = num2str(intgrad(i1,:)*intgrad(i2,:)',10); %integrand for 
(15e11) 
fun=inline(fun1, 'x', 'y'); 
integ=gaussianintapprox(fun,xyt,xyr,xys); 
A(intnodes(i1),intnodes(i2))=A(intnodes(i1), intnodes(i2))+integ; 
end 
end
%update load vector 
for i=1:length(intnodes) 
for j=1:length(bdynodes) 
fun1 = num2str(intgrad(i,:)*bdygrad(j,:)',10); %integrand for (16e11) 
fun=inline(fun1,'x', 'y'); 
integ=gaussianintapprox(fun,xyt,xyr,xys); 
b(intnodes(i))=b(intnodes(i))-c(bdynodes(j))*integ; 
end 
end
\end{lstlisting}

\noindent Whereas the original code took about an hour to run (on the author's computer), the modified assembly code took only a few seconds. Moreover, an examination of the error plot (against the exact Poisson solution) shows the errors of the two methods to be about the same.

\textbf{\texttt{EFR 13.11:}}For completeness, we include a full code for the FEM. Assume that the node set (vectors x andy) have been constructed as in Example 13.3. Although from the construction it is clear that the nodes on the inner circle came first and those on the outer circle came last, before we triangulate, we give a code that will automatically reindex so that the interior nodes precede the boundary nodes: 

\begin{lstlisting}[frame=none, numbers=none]
m = length(x); %m = total number of nodes. 
cnt1=1; cnt2=1; 
for i=1:m 
if norm([x(i) y(i)],2)<1+4*eps %tests if node is on inner circle 
bdy1(cnt1)=i; cnt1=cnt1+1; 
elseif norm([x(i) y(i)],2)>2-4*eps %tests if node is on outer circle 
bdy2(cnt2)=i; cnt2=cnt2+1; 
end 
end 
n=m-length(bdy1)-length(bdy2); % n = total number of interior nodes 
xnew=[x(setdiff(1:m, union(bdy1, bdy2))) x(bdy1) x(bdy2)]; x=xnew; 
ynew=(y(setdiff(1:m, union(bdy1, bdy2))) y(bdy1) y(bdy2)]; y=ynew; 
\end{lstlisting}
\noindent Next, we form the Delaunay triangularon using the code of Example 13.3. This being done, we assign the boundary values: 
\begin{lstlisting}[frame=none, numbers=none]
c(n+1:n+length(bdy1))=2 ; 
for i=n+length(bdy1)+1:m 
th=cart2pol(x(i),y(i)); 
c(i)=cos(2*th);
end
\end{lstlisting}
\noindent The remaining code below will perform the FEM and create the plot of the numerical solution (Figure 13.39). We use Method 2 (Gaussian quadrature for the integrals). We include the code for completeness only, but because of the way we have prepared things, the remaining code is identical to that of the preceding EFR (if we had written it out there): 

\begin{lstlisting}[frame=single, numbers=none]
N=[x' y']; 
E=tri; 
A=zeros(n); b=zeros(n,1); 
[L cL]=size(E) ; 
for e11=1:L 
nodes=E(e11,:); 
bdynodes=nodes(find(nodes>n)); 
intnodes=setdiff(nodes,bdynodes); 

%find gradients [a b] of local basis functions
% ax + by +c; distinguish between int node 
%local basis functions and bdy node local basis
%functions
 
for i=1:length(intnodes) 
xyt=N(intnodes(i),:); %main node for local basis function 
onodes=setdiff(nodes,intnodes(i)); 
%two other nodes (w/ zero values) for local basis function 
xyr=N(onodes(1),:) ; 
xys=N(onodes(2),:) ; 
M=[xyr 1;xys 1;xyt 1]; %matrix M of (4) 
abccoeff=[xyr(2)-xys(2); xys(1)-xyr(1); xyr(1)*xys(2)-... 
xys(1)*xyr(2)]/det(M); %coefficients of basis function on triangle#L, 
see formula (6a) 
intgrad(i,:)=abccoeff(1:2); 
end 

for j=1:length(bdynodes) 
xyt=N(bdynodes(j),:); %main node for local basis function 
onodes-setdiff(nodes,bdynodes(j));%two other nodes (w/ zero values) 
for local basis function 
xyr=N(onodes(1), :) ; 
xys=N(onodes(2), :) ; 
M=[xyr 1;xys 1;xyt 1]; %matrix M of (4) 
abccoeff=[xyr(2)-xys(2); xys(1)-xyr(1); xyr(1)*xys(2)-... 
xys(1)*xyr(2)]/det(M); %coefficents of basis function on triangle#L, 
see formula (6a) 
bdygrad(j,:)=abccoeff(1:2)'; 
end 
%update stiffness matrix 
for i1=1:length(intnodes) 
for i2=1:length(intnodes) 
fun1 = num2str(intgrad(i1,:)*intgrad(i2,:)', 10); %integrand for 
(15e11) 
fun=inline(fun1,'x', 'y'); 
integ=gaussianintapprox(fun,xyt,xyr,xys); 
A(intnodes(i1),intnodes(i2))=A(intnodes(i1),intnodes(i2))+integ; 
end
end

%update load vector 
for i=1:length(intnodes) 
for j=1:length(bdynodes) 
fun1 = num2str(intgrad(i,:)*bdygrad(j, :)' , 10) ; %integrand for (16e11) 
fun=inline(fun1,'x', 'y'); 
integ=gaussianintapprox(fun,xyt,xyr,xys); 
b(intnodes(i))=b(intnodes(i))-c(bdynodes(j))*integ; 
end 
end 

end 
sol=A\b; 
c(1:n)=sol'; 
>> trimesh(tri,x,y,c) 
>> xlabel('x-axis'), ylabel('y-axis')
\end{lstlisting}


\textbf{\texttt{EFR 13.12:}}(a) Rerun the triangulation code of the solution of Example 13.2(a). The construction was done in a way that the boundary nodes came last. So we will be able to adapt the assembly code of EFR 13.11 quite simply. (The only change will be in dealing with the load vector, because of the presence of the inhomogeneity function.) 

\begin{lstlisting}[frame=none, numbers=none]
>> m=length(x); %number of nodes 
>> n = min(find(x.^2 + y.^2>1-10*eps))-1; %number of interior nodes
\end{lstlisting}
\noindent Now we easily modify the (boxed) code of the preceding EFR to work for the present situation. There are some changes here due to the fact that the boundary data is now all zero, but we do have a nonzero inhomogeneity fucntion $f(x, y)$, and thus $\left(16^{\prime}\right)$ takes on the following more simple form: $b_{\alpha}^{l}=\iint_{T_{l}} f \Phi_{i_{\alpha}} d x d y(1 \leq \alpha \leq 3)$. Thus, the "updating the load vector" portion should be replaced by:

\begin{lstlisting}[frame=none, numbers=none]
%update load vector 
for i1=1:length(intnodes) 
xyt=N(intnodes(i),:); %main node for local basis function 
onodes=setdiff(nodes,intnodes(i)) ; 
%two other nodes (w/ zero values) for local basis function 
xyr=N(onodes(1),:) ; 
xys=N(onodes(2),:) ; 
M=[xyr 1;xys 1;xyt 1] ; %matrix M of (4) 
abccoeff=[xyr(2)-xys(2); xys(1)-xyr(1) ; xyr(1)*xys(2)-... 
xys(1)*xyr(2)]/det(M);	%coefficients of basis function on triangle#L, 
						%see formula (6a)
%since we cannot mix M-fil e and inline functions to input into 
%another M-file , we recode the gaussianintappro x M-file 
atemp=num2str(abccoeff(1),10); btemp=num2str(abccoeff(2),10); 
ctemp=num2str(abccoeff(3),10); 
phixy=inline([atemp , '*x+' , btemp, '*y+',ctemp],'x','y'); 
Atemp=feval(@EFR13_12f, (xyt(1)+xyr(1))/2, (xyt(2)+xyr(2))/2)*... 
feva(phixy , (xyt(1)+xyr(1))/2, (xyt(2)+xyr(2))/2); 
Btemp=feval(@EFR13_12f, (xyt(1)+xys(1))/2 , (xyt(2)+xys(2))/2)*... 
feva(phixy , (xyt(1)+xys(1))/2 , (xyt(2)+xys(2))/2) ; 
Ctemp=feval(@EFR13_12f, (xyr(1)+xys(1))/2 , (xyr(2)+xys(2))/2)* . . . 
feva(phixy, (xyr(1)+xys(1))/2, (xyr(2)+xys(2))/2); 
M=[xyr(1) xyr(2) 1;xys(1) xys(2) 1; xyt(1) xyt(2) 1] ;
area=abs(det(M))/2 ; 
integ=area*(Atemp-fBtemp+Ctemp)/3; 
b(intnodes(i1))=b(intnodes(i1))+integ ; 
end 
\end{lstlisting}
\noindent Also, the loop portion of the assembly code commencing with "for $j=1:$ length (bdynodes)" can be deleted since the boundary node gradients that it creates will not be needed in ( $16^{l}$ ). With these modifications, the code will produce the numerical solution of Figure $13.39(\mathrm{~b})$, once an M-file for the inhomogeneity function is created (due to the cases in its definition, an inline construction is not feasible):
\begin{lstlisting}[frame=single, numbers=none]
function z = EFR13_12f(x,y)
if norm([x y]-[0 5],2)<.25
z=20;
else
z=0;
end
\end{lstlisting}

\noindent(b) The assembly instructions are exactly as in part (a), after we have created the node set and 
triangulation according to the specifications. The following code will create such a triangularon:

\begin{lstlisting}[frame=none, numbers=none]
% node deployment, use concentric circles centered at (0, 1/2) 
% except for on the boundary 
% Step 1 inside Omegal (small circle) has 50% of nodes 
% d1=common gap size 
% avg radius = 1/8, avg. circumf= pi/4, 
% avg no. of nodes on circ = pi/4/d1 
% number of circles = 1/4/d1 
% setting 50% of 800 = [pi/4/d1][1/4/d1] gives 
d1=sqrt(pi/16/400); 
x(1)=0; y(1)=.5; 
nodecount=1; ncirc=floor(1/4/d1); minrad=1/4/ncirc; 
for i=1:ncirc, rad=i*minrad; nnodes=floor(2*pi*rad/d1); 
anglegap=2*pi/nnodes;
for k=1:nnodes 
	x(nodecount+1)=rad*cos(k*anglegap); 
	y(nodecount+1)=rad*sin(k*anglegap)+.5; 
	nodecount = nodecount+1; 
end 
end  

% step 2: inside annulus Omega2 has 25% of nodes 
% d2=common gap size 
% avg radius = 3/8, avg circumf = 3pi/4, 
% avg no of nodes on circ = 3pi/4/d2 
% number of circles = 1/4/d2
d2<<sqrt(3*pi/16/200); ncirc=floor(1/4/d2);minrad=1/4+(d1+d2)/2; 
%blend interface 
for i=1:ncirc 
	rad=minrad + (i-1)*d2; nnodes=floor(2*pi*rad/d2); 
	anglegap=2*pi/nnodes; 
	for k=1:nnodes 
		x(nodecount+1)=rad*cos(k*anglegap); 
		y(nodecount+1)=rad*sin(k*anglegap)+.5; 
		nodecount = nodecount+1; 
end 
end 

% step 3: inside region Omega3 has 15% of nodes 
% d3 = common gap size 
% avg radius = 3/4, avg arclength (approx)= (2pi +pi)/2*3/4=9pi/8 
% number of circles = 1/2/d3
d3=sqrt(9*pi/16/120); ncirc=floor(1/2/d3); minrad=1/2+(d2+d3)/2; 
%blend interface 
for i=1:ncirc 
	rad=minrad + (i-1)*d3; nnodes=floor(2*pi*rad/d3) ; 
	anglegap=2*pi/nnodes; 
	for k=1:nnodes 
		xtest=rad*cos(k*anglegap); ytest=rad*sin(k*anglegap)+.5; 
		if norm([xtest ytest],2)<1-d3/2 %don't put nodes too close to bdy x(nodecount+1)=xtest; y(nodecount+1)=ytest; nodecount = nodecount+1; 
		end 
	end 
end

% step 4: inside region Omega4 has 10% of nodes 
% d4 = common gap size 
% avg radius = 5/4, avg (approx) arclength = 5pi/4 
% number of circles = 1/2/d4 
d4=sqrt(5*pi/8/80); ncirc=floor(1/2/d4); minrad=1+(d3+d4)/2; %blend interface 
for i=1:ncirc 
	rad=minrad + (i-1)*d4; nnodes=floor(2*pi*rad/d4); 
	anglegap=2 *pi/nnodes ; 
	for k=1:nnodes 
		xtest=rad*cos(k*anglegap); ytest=rad*sin(k*anglegap)+.5; 
		if norm([xtest ytest],2)<1-d4/2 %don't put nodes too close to bdy x(nodecount+1)=xtest; y(nodecount+1)=ytest; nodecount = nodecount+1; 
		end 
	end 
end 

% step 5: put nodes on boundary 
% if bdy point is touches Omega3 use d3 spacing
% otherwise use d4 spacing 
theta=0; 
while theta<2*pi-d4 
	x(nodecount+1)=cos(theta); y(nodecount+1)=sin(theta); 
	nodecount = nodecount+1; 
	if norm([cos(theta) sin(theta)]-[0 .5], 2)<.5 
		theta=theta+d3; 
	else 
		theta=theta+d4; 
	end 
end 
\end{lstlisting}

\textbf{\texttt{EFR 12.13:}} (a) The M-file is boxed below: 
\begin{lstlisting}[frame=single, numbers=none]
function lineint = bdyintapprox(fun, tri, redges) 
% function M-file for EFR 13.13 
% inputs will be 'fun', an inline function (or M-file) of vars x, y; 
% a matrix 'tri' of nodes of a triangle in the plane, and a 2-column 
% matrix 'redges', possibly empty ([ ]), containing, as rows, the 
% corresponding node indices (from 1 to 3 indicating nodes 
% by their row in 'tri') of nodes which are endpoints of segments of 
% the triangle which are part of the 'Robin' boundary (for an 
% underlying FEM problem). Thus the rows of 'redges' can include 
% only the following three vectors: [1 2], [1 3], and [2 3]. (Or 
% permutations of these.) The output, 'lineint' will be the the 
% Newton-Coates approx. ((31) of Chapter 13) line integral of 'fun' 
% over the Robin segments of the triangle. 
lineint=0; 
[rn cn] = size(redges); %rn = number of Robin edges 
if rn == 0 
	return 
end 
for i=1:rn 
	nodes = redges(i,:); 
	N1=tri(nodes(1),:); N2=tri(nodes(2),:); 
	N1x=N1(1); N1y=N1(2); N2x=N2(1); N2y=N2(2); 
	vec = N2-N1; 
	
approx=norm(vec,2)/6*(feval(fun,N1x,N1y)+4*feval(fun,(N1x+N2x)/2, (N1y+N2y)/2+feval(fun,N2x,N2y)); 
	lineint=lineint+approx; 
end
\end{lstlisting}

\noindent(b)

\begin{lstlisting}[frame=none, numbers=none]
>> tril = [0 0;2 0;0 3]; tri2=tri1/10;
>> f1 = inline('4','x','y'); f2=inline('cos(pi*x/4+pi*y/2)','x','y')
>> redgesl = [1 2;2 3); redges2 = [1 2; 1 3];
>> Int1=bdyintapprox(f1, tri1, redges1) ->Int1 =22.4222
>> abs(Int1-8-4*sqrt(13)) ->ans = 1.7764e-015 (Error for first approximation)
>> bdyintapprox(f1, tri2 , redges1) ->ans = 2.2422
>> Int2=bdyintapprox(f2,tril,redges2) -> Int2 = 0.3619 (Error for first approximation)
>> abs(Int2-2/pi) ->ans = 0.4882 
\end{lstlisting}
\noindent It is not surprising that the error for the first integration was as small as machine precision, since the method is exact for polynomials of degree up to three and we are integrating a constant function. A similar accuracy would hold for the integral over the smaller triangle. The second integration had a very large error and this was due to the fact that the integrand experiences a lot of variation on the edges. A similarly large error (although a bit smaller relatively) would occur if we looked at the integral of the second function over the smaller triangle (the error would be $0.1263$ ). When we utilize this integrator in our FEM codes, we can use a fine enough partition (in the portions of the boundary where the data has more variation) to prevent such problems.

\textbf{\texttt{EFR 13.14:}} The PDE and the Dirichlet portion of the BCs are plainly satisfied, so we have only to check the Neumann $\mathrm{BC}$ on the parabolic portion of the boundary. A tangent vector to a point on the parabola $y=\varphi(x) \equiv x(10-x)$ is given by $\vec{\tau}(x)=(d / d x)(x, \varphi(x))=(1,10-2 x)$. Since this tangent vector has positive $x$-component, an outward-pointing normal vector can be obtained from it by rotating $\vec{\tau}(x)$ by an angle of $\pi / 2$ (see Section 7.2). Dividing this vector by its Euclidean norm (see Section 7.6) gives the outward pointing unit normal vector: $\vec{n}=\vec{n}(x)=(2 x-10,1) /\|(2 x-10,1)\|_{2}=$ $\frac{(2 x-10,1)}{\sqrt{4 x^{2}-40 x+101}}$. Taking the dot product with the gradient of $u \quad \nabla u(x, y)=(0, y / 25)$ of the exact solution given produces the stated Neumann $B C$.

\textbf{\texttt{EFR 13.15:}} The triangulations for this problem have been already done and can simply be imported. The main task is to set up the assembly process. In the notation of (10), we have: $p \equiv 1, q \equiv 0, g \equiv 0, r=2$ (on $\left.\Gamma_{2}\right), h=40$ (on $\Gamma_{2}$ ), $f(x)$ is as specified. Thus, $c_{s}=0(s>n)$ and the element matrix analogues of $(28)$ and $(29)\left(c f .,\left(15^{l}\right)\right.$ and $\left(16^{l}\right)$ become:
$$
\begin{gathered}
a_{\alpha \beta}^{l}=\iint_{T_{l}}\left[\nabla \Phi_{i_{\alpha}} \cdot \nabla \Phi_{i_{\beta}}\right] d x d y+2 \int_{\Gamma_{2} \cap T_{\ell}} \Phi_{i_{\alpha}} \Phi_{i_{\beta}} d s \quad(1 \leq \alpha, \beta \leq 3), \text { and } \\
b_{\alpha}^{l}=\iint_{T_{l}} f(x, y) \Phi_{i_{\alpha}} d x d y+40 \int_{r_{2} \cap T_{l}} \Phi_{i_{\alpha}} d s \quad(1 \leq \alpha \leq 3) .
\end{gathered}
$$
This is just a bit more involved than the assembly equations for Example 13.8, since in the former there were no line integrals in the first (stiffness matrix coefficient) equations. Nonetheless, the assembly code of the example can be easily adapted to fill our present needs. We first need to store an $M$-file for the inhomogeneity function $f(x, y)$ :

\begin{lstlisting}[frame=single, numbers=none]
function z = EFR13_15f(x,y) 
if x>=4 & x<=6 & y>=10 & y<=15 
z=200; 
else 
z=0; 
end
\end{lstlisting}

Before running the assembly code below, we assume that the triangulation code of Example 13.8(a) has been run. In particular, the following variables have been created: nint $=$ the number of interior nodes, $n=$ the number of interior/Robin nodes, $m=$ the number of nodes, dir $1=m=$ node index for $(0,0)$, and dir2 = nint $+1=$ the node index for $(10,0)$. As in the example, in the first part of the code, we need not compute gradients of basis functions corresponding to Dirichlet nodes. since the Dirichlet boundary values are all zero. The only new technical issue here is that in the computation of the load coefficients (in the first integral), since it is awkward to mix inline functions and M-files into a single function, we choose to simply recode the gaussianintapprox M-file (which is a rather short code).

\begin{lstlisting}[frame=none, numbers=none]
N=[x' y']; E=tri; A=zeros(n); b=zeros(n,1); [L cL]=size(E); 
for e11=1:L 
nodes=E(e11,:); %global node indices of element 
percent=100*e11/L %optional percent meter will show progression. 
intnodes=nodes(find(nodes<=n)); %global interior/Robin node indices 
%find coefficients [a b c] of local basis functions 
% ax + by +c; for int/robin nodes 
for i=1:length(intnodes) 
xyt=N(intnodes(i),:); %main node for local basis function 
onodes=setdiff(nodes,intnodes(i)); 
%global indices for two other nodes (w/ zero values) for local basis 
function 
xyr=N(onodes(1),:); xys=N(onodes(2),:);
M=[xyr 1;xys 1;xyt 1]; %matrix M of (4) 
%local basis function coefficients using (6B) 
abccoeff=[xyr(2)-xys(2); xys(1)-xyr(1); xyr(1)*xys(2)-... 
	xys(1)*xyr(2)]/det(M); 
intgrad(i,:)=abccoeff(1:2)'; abc(i,:)=abccoeff'; 
end 

% determine if there are any Robin edges 
marker=0; %will change to 1 if there are Robin edges. 
roblocind=find(nodes==dir1|nodes==dir2|(nodes<=n & .. . 
	nodes >=(nint+1))); 
%local indices of nodes for possible robin edges 
if length(roblocind>1 
elemnodes = N(nodes,:);

%now find robin edges and make a 2 column matrix out of their local 
%indices. 
rnodes=nodes(roblocind); %global indices of robin nodes 
count=1; 
for k=(nint+1):(n-1) 
if ismember (k, modes) & ismember (k+1, rnodes) 
robedges(count,:)=[find(nodes==k) find(nodes==k+1)]; count=count+1; 
marker =1; 
end 
end 
end 

%update stiffness matrix 
for i1=1:length(intnodes) 
for i2=1:length(intnodes) 
if intnodes(i1)>=intnodes(i2) 
%to save some computation, we use symmetry of the stiffness matrix. 
fun1 = num2str(intgrad(i1,:)*intgrad(i2,:)',10); 
%integrand for (15e11) 
fun=inline(fun1,'x', 'y'); integ=gaussianintapprox(fun,xyt,xyr,xys); 
A(intnodes(i1),intnodes(i2))=A(intnodes(i1),intnodes(i2))+integ; 

%now add Robin portion, if applicable 
%robin edges were computed above 
if marker==1 
ai1 = num2str(abc(i1,1),10); ai2 = num2str(abe(i2,1),10); 
bi1 = num2str(abc(i1,2),10); bi2 = num2str(abc(i2,2),10); 
ci1 = num2str(abc(i1,3),10); ci2 = num2str(abe(i2,3),10); 
prod=inline(['2* (\ai1,'*x+', bi1, '*y+', ci1,')* ... 
(',ai2, '*x+', bi2, '*y+', ci2,'),'x','y'); 
A (intnodes(i1),intnodes(i2))=A(intnodes(i1),intnodes(i2))... 
	+bdyintapprox(prod,elemnodes, robedges); 
end
end
end
end

%update load vector 
for i1=1:length(intnodes) 
ai1 = num2str(abc(i1,1),10); bi1 = num2str(abc(i1,2),10); 
ci1 = num2str(abc(i1,3),10); 
phi=inline([ai1,'*x+', bi1, '*y+', ci1],'x','y');
%since we cannot mix M-file and inlin e functions to input into 
%another M-file, we basically must recode the gaussianintapprox M-
%file 
Atemp=feval(@EFR13_15f, (xyt(1)+xyr(1))/2, (xyt(2)+xyr(2))/2)*... 
feval(phi, (xyt(1) +xyr(1))/2, (xyt(2)+xyr(2))/2);
Btemp=feval(@EFR13_15f, (xyt(1)+xys(1))/2, (xyt(2)+xys(2))/2)*...
feval(phi,(xyt(1)+xys(1))/2,(xyt(2)+xys(2))/2); 
Ctemp=feval(@EFR13_15f,(xyr(1)+xys(1))/2, (xyr(2)+xys(2))/2)*... 
feval(phi,(xyr(1)+xys(1))/2,(xyr(2)+xys(2))/2);
M=[xyr(1) xyr(2) 1;xys(1) xys(2) 1; xyt(1) xyt(2) 1]; 
area=abs(det(M))/2; 
integ=area*(Atemp+Btemp+Ctemp)/3; 
b(intnodes(i1))=b(intnodes(i1))+integ;

%now add Robin portion, if applicable 
%robin edges were computed above 
if marker==1 
prod=inline(['40*(',ai1,'*x+', bi1, '*y+', ci1,')'],'x','y'); 
b(intnodes(i1))=b(intnodes(i1))+ ... 
	bdyintapprox(prod, elemnodes, robedges);
end
end
clear roblocind modes robedges
end
end 
A=A+A'-A.*eye(n); %Use symmetry to fill in remaining entries of A.

so1=A\b; 
c(1:n)=so1'; 
c(n+1:m)=0;

%The result is now easily plotted using the 'trimesh' function of the 
%last section: 

x=N(:,1); y=N(:,2); 
trimesh(E,x,y,c) 
hidden off 
xlabel ('x-axis'), ylabel('y-axis') 
The above code will produce a plot of the FEM solution.
\end{lstlisting}


\textbf{\texttt{EFR 13.16:}} In the notation of (10), we have: $p \equiv 1, q \equiv 0, f \equiv 0, g \equiv 100\left(\right.$ on $\left.\Gamma_{1}\right), r=0,1$, or 2 (on $\Gamma_{2}$ ), and $h=0,20$, or 30 (on $\Gamma_{2}$ ). The element matrix analogues of (28) and (29) (cf., $\left(15^{\ell}\right)$ and $\left.\left(16^{\prime}\right)\right)$ thus become:
$$
\begin{gathered}
a_{\alpha \beta}^{l}=\iint_{T_{l}}\left[\nabla \Phi_{i_{a}} \cdot \nabla \Phi_{i_{\beta}}\right] d x d y+r \int_{r_{2} \cap T_{1}} \Phi_{i_{\alpha}} \Phi_{i_{\beta}} d s \quad(1 \leq \alpha, \beta \leq 3), \text { and } \\
b_{\alpha}^{\prime}=\iint_{T_{l}} f(x, y) \Phi_{i_{\alpha}} d x d y+40 \int_{r_{2} \cap T_{l}} \Phi_{i_{a}} d s- \\
\sum_{s=n+1}^{m} 100\left[\iint_{T_{l}}\left[\nabla \Phi_{s} \cdot \nabla \Phi_{i_{a}}\right] d x d y+r \int_{r_{2} \cap T_{l}} \Phi_{s} \Phi_{i_{a}} d s\right](1 \leq \alpha \leq 3) .
\end{gathered}
$$
The triangulation is new but can be accomplished with the various techniques that we have developed so far. Here is the complete annotated code for our construction. The code also introduces some special variables used to store important node numbers corresponding to the eight corner nodes on the boundary.

\begin{lstlisting}[frame=none, numbers=none]
%Mesh Generation 
A =36-pi*(4+1); %area of region
delta = sqrt(A/2500); count = 1;
 
%place interior nodes first 
for i=1:cei1(6/delta), for j=1:cei1(6/delta) 
xt=i*delta; yt=j*delta; xy=[xt yt]; 
if norm(xy,2)>2+delta/2 & norm(xy-[6 0],2)>2+delta/2 & ... 
	norm(xy-[6 6],2)>2+delta/2 &norm(xy-[0 6],2)>2+delta/2 ... 
	& norm(xy-[3 3],2)>1+delta/2 & xt<6-delta/2 & yt<6-delta/2 
x(count)=xt; y(count)=yt; count=count+1; 
end, end, end 
nint=count-1; %number of interior nodes 

%now deploy boundary nodes; we will group them according to their 
%boundary conditions; as usual, the Robin nodes precede the Dirichlet 
%nodes. At the corners there is some ambiguity since the normal 
%vector is undefined. We make some conventions that Robin 
%conditions take precedence over Neumann conditions, and for Neumann 
%conditions at an interface, we simply average the values of the 
%normal derivative values.

%Helpful Auxilliary Vectors: 
v1=linspace(2,4,2/delta); lenv1=length(v1); 
thetaout=linspace(0,pi/2,pi/delta); %node angular gaps for big 
quarter circles 
lenthout=length(thetaout); 
thetain=linspace(0,2*pi,2*pi/delta); %node angular gaps for smaller 
interior cirlce 
lenthin=length(thetain);

%Neumann conditions with zero boundary values: 
for i=2:lenv1 %east 
x(count)=6; y(count)=v1(i); count=count+1; 
end 
for i=2:lenthout %northeast 
x(count)=6+2*cos(-pi/2-thetaout(i)); y(count)=6+2*sin(-pi/2-... 
	thetaout(i)); count=count+1; 
end 
toprightindex=count-1

for i=2:lenv1 %north 
x(count)=6-v1(i); y(count)=6; count=count+1; 
end 
topleftindex=count-1

for i=2:lenthout %northwest 
x(count)=2*cos(-thetaout(i)); y(count)=6+2*sin(-thetaout(i)); 
count=count+1; 
end

for i=2:lenv1-1 %west 
x(count)=0; y(count)=6-v1(i); count=count+1; 
end 
lastwestind=count-1
firstsouthind=count 

for i=2:lenv1-1 %south 
x (count)=v1(i); y(count)=0; count=count + 1; 
end
lastsouthind=count-1

%Now we move on to the two Robin portions 
firstswind=count 
for i=1:lenthout %southwest 
x(count)=2*cos(thetaout(i)); y(count)=2*sin(thetaout(i)); 
count=count+1; 
end 
lastswind=count-1 
firstseind=count

for i=1:lenthout %southeast 
x(count)=6+2*cos(pi/2+thetaout(i)); y (count)=2*sin(pi/2+thetaout(i)); 
count=count+1; 
end 
n=count-1 %number of interior and Robin nodes 
lastseind=n; 

% finally put in the Dirichlet nodes 
for i=1:lenthin 
x(count)=3+cos(thetain(i)); y(count)=3+sin(thetain(i)); 
count=count+1; 
end 
m=count-1 %number of nodes

%ASIDE: Enter these commands to plot the nodes 
%plot(x(1:nint), y(1:nint),'b.'), axis('equal') 
%hold on 
%plot(x(nint:m),y(nint:m),'rp'), axis('equal')

%Since the domain is not convex (in 5 spots) we will use the 
%technique of Example 13.3 of introducing 5 ghost nodes that will 
%yield a triangulation from which it will be easier to delete the 
%unwanted triangles 

x(m+1)=3; y(m+1)=3; 
x(m+2)=5; y(m+2)=1; 
x(m+3)=5; y(m+3)=5; 
x(m+4)=1; y(m+4)=5; 
x(m+5)=1; y(m+5)=1; 
tri=delaunay(x, y);
trimesh(tri,x,y,'LineWidth', 1.2), axis('equal') 
%Plots the triangulation 
axis('equal') 
%Now we need to delete all elements which have a node with index in 
%the range m+1 to m+5. 
size(tri) %ans =5224 3, so there are 5224 elements 
badelcount=1; 
for e11=1:5224 
if sum(ismember(m+1:m+5, tri(e11,:)))>0 
badel(badelcount)=e11; 
badelcount=badelcount+1; 
end 
end

tri=tri(setdiff(1:5224,badel),:); 
x=x(1:m); y=y(1:m); 
trimesh(tri,x,y), axis('equal')
\end{lstlisting}

\begin{center}
\begin{tabular}{ |c|c| }
\hline
\begin{lstlisting}[frame=none, numbers=none]
function z=h_EFR13_16(x, y) 
%Inhomogeneity function for 
Neumann/Robin BC of %EFR13.16. 
if y>2+eps & y<6-eps z=0; 
elseif y>=6-eps, z=20; 
elseif y<eps, z=-20 ; 
elseif (y>=eps & y<=2+eps)|[x y]==[2
0]|[x y]==[4 0] 
	z=30; 
end 
if y==0 & (x==2|x==4), z=5; end 
if y==2, z=15; end 
if y==6 % (x==2|x==4), z=5; end
\end{lstlisting}

  &
\begin{lstlisting}[frame=none, numbers=none]

function r=r_EFR13_16(x,y) 
%u-coefficient functio n 
for %Neumann/Robin BC of 
%EFR13.16. 
if (y>=0&y<=2) & x<=2 
	r=1; 
elseif (y>=0&y<=2) & x>=4 
	r=2; 
else 
	r=0; 
end
\end{lstlisting}
\\\hline
\end{tabular}
\end{center}
\noindent The assembly code is long, but it can be done by combining elements of the others we have developed so far. For space considerations we will refer the complete assembly code to the FTP site for the book (see beginning of this appendix for the URL.)




\newpage\noindent\textbf{\textbf{References}}

\noindent[Abb-66] Abbott, Michael B., An Introduction to the Method of Characteristics, American Elsevier, New York (1966)
\newline\bigskip

\noindent[Aga-00] Agarwal, Ravi $P_{7}$, Difference equations and inequalities. Theory, methods, and applications, Second edition, Marcel Dekker, Inc., New York, (2000)
\newline\bigskip

\noindent[Ahl-79] Ahlfors, Lars Valerian, Complex Analysis, Third Edition, MeGraw-Hill, New York (1979)
\newline\bigskip

\noindent[Ame-77] Ames, William F., Numerical Methods for Partial Differential Equations, Barnes and Noble, New York (1977)
\newline\bigskip

\noindent[Ant-00] Anton, Howard, Elementary Linear Algebra, Eighth Edition, John Wiley \& Sons, New York (2000)
\newline\bigskip

\noindent[Apo-74] Apostol, Thomas. M., Mathematical Analysis: A Modern Approach to Advanced Calculus (2nd Edition). Addison-Wesley, Reading. MA (1974)
\newline\bigskip

\noindent[Am-78], Amold, Vladimir. I., Ordinary Differential Eguations, MIT Press, Cambridge, MA (1978)
\newline\bigskip

\noindent[Asm-00], Asmar, Nakhlé, Partial Differential Equations and Boundary Value Problems, Prentice. Hall, Upper Saddle River, NJ (2000)
\newline\bigskip

\noindent[Atk-89] Atkinson, Kendall E., An Introduction to Numerical Analysis, Second Edition, John Wiley \& Sons, New York (1989).
\newline\bigskip

\noindent[AxBa-84] Axelsson, Owe, and Vincent A. Barker, Finite Element Solution of Boundary Value Problems, Academic Press, Orlando, FL (1984)
\newline\bigskip

\noindent[Bar-93] Barnsley, Michael F., Fractals Everywhere. Second Edition, Academic Press, Boston, MA (1993)
\newline\bigskip

\noindent[BaZiBy-02] Barnett, Raymond A., Michael R. Ziegler, and Karl E. Byleen, Finite Mathematics, For Business, Economics, Life Sciences and Social Sciences, Ninth Edition, Prentice-Hall, Upper Saddle River, NJ (2002)
\newline\bigskip

\noindent[Bec-71] Beckmann, Petr, A History of $\pi$, Second Edition, The Golem Press, Boulder, CO (1971)
\newline\bigskip

\noindent[BeEp-92] Bern, Marshall and David Eppstein, Mesh Generation and Optimal Triangulation, In F.K. Hwang and D.-Z. Du, editors, Computing in Euclidean Geometry. World Scientific Publishing, River Edge, NJ (1992)
\newline\bigskip

\noindent[Br-93]. Braun, Martin, Differential Equations and Their Applications. Springer-Verlag. New York (1993)
\newline\bigskip

\noindent[BrCh-93] Brown, James $\mathbf{W}_{,}$, and Ruel V. Churchill, Fourier Series and Boundary Value Problems, Fifth Edition, McGraw-Hill Inc., New York (1993)
\newline\bigskip

\noindent[BrChSi-03] Brown, James W. Ruel V. Churchill, and H. Jay Siskin, Complex Variables and Applications. Seventh Edition, McGraw-Hill Ine., New York (2003)
\newline\bigskip

\noindent[BuFa-01] Burden, Richard, L., and J. Douglas Faires, Numerical Analysis, Seventh Edition, Brooks/Cole, Pacific Grove, CA (2001)
\newline\bigskip

\noindent[But-87] Butcher, John C., The Numerical Analysis of Ordinary Differential Equations: Runge-Kutta and General Linear Methods, John Wiley \& Sons, New York, 1987.
\newline\bigskip

\noindent[Cia-02] Ciarlet, Phillipe G., The Finite Element Method for Elliptic Problems, Soc. of Industrial and Applied Math.(S1AM), Philadelphia, PA (2002)
\newline\bigskip

\noindent[CiLi-89] Ciarlet, Phillipe G. and Jacques Louis Lions, Handbook of Numerical Analysis, Volume II: Finite Element Methods (Part I), North Holland, Amsterdam (1989)
\newline\bigskip

\noindent[Col-42] Collatz, Lothar, Fehlerabschätzung fũr das lherationsverfahren zur Auflōsung linearer Gleichungrsysteme (German), Zeitschrift für Angewandte Mathematik und Mechanik. Ingenieurwissenschaftliche Forschungsarbeiten, vol. 22, Pp. 357-361 (1942)
\newline\bigskip

\noindent[Con-72] Conway, John H., Unpredictable iterations, Proceedings of the 1972 Number Theory Conference, University of Colorado, Boulder, Colorado, pp. 49-52, (1972)
\newline\bigskip

\noindent[Cou-43] Courant, Richard, Variational methods for the solution of problems of equilibrium and vibrations, Bull. Amer. Math. Soc., vol 49, pp. 1-23 (1943)
\newline\bigskip

\noindent[Cow-73] Cowper, E. R., Gaussian quadrature formulae for triangles, International Journal of Numerical Methods in Engineering, vol 3, 405-408 (1973)
\newline\bigskip

\noindent[CrNi-47] Crank, John, and Phyllis Nicolson, A practical method for the numerical evaluation of solutions of partial differential equations of the heat conduction type, Proceedings of the Cambridge Philosophical Society, vol. 43, pp. 50-67 (1947)
\newline\bigskip

\noindent[Del-34] Delaunay, Boris, Sur la sphere vide, Inv. Akad. Nauk SSSR, Otdelenie Matematicheskii i Estestvennyka Nauk, vol. 7, pp. 793-800 (1934)
\newline\bigskip

\noindent[DuCZa-89] DuChateau, Paul, and David Zachmann, Applied Partial Differential Equations, Harper \& Row, New York (1989)
\newline\bigskip

\noindent[Dur-99] Duran, Dale, R., Numerical Methods for Wave Equations in Geophysical Fluid Dynamics, Springer-Verlag, New York (1999)
\newline\bigskip

\noindent[Ede-01] Edelsbrunner, Herbert, Geometry and Topology for Mesh Generation, Cambridge University Press, Cambridge, UK (2001)
\newline\bigskip

\noindent[EdK-87] Edelstein-Keshet, Leah. Mathematical Models in Biology, McGraw-Hill. New York $(1987)$
\newline\bigskip

\noindent[Ela-99] Elaydi, Saber N., An Introduction to Difference Equations, Second edition. Springer-Verlag. New York (1999)
\newline\bigskip

\noindent[Eng-69] England, Roland, Error Estimates for Runge-Kutta type solutions to systems of ordinary differential equations, Computer Journal, vol. 12, pp. 166-170 (1969)
\newline\bigskip

\noindent[Epp-02] Epperson, James F., An Introduction to Numerical Methods and Analysis, John Wiley \& Sons, New York (2002)
\newline\bigskip

\noindent[Fal-86] Falconner, Kenneth J., The Geometry of Fractal Sets, Cambridge University Press, Cambridge, UK (1986)
\newline\bigskip

\noindent[Feh-70] Fehlberg, Erwin, Klassische Runge-Kutta Formeln vierter und niedrigerer Ordnung mitt Schrittweiten-Kontrolle und ihre Anwendung auf Wärmeleitungsprobleme, Computing, vol. 6, pp. 61$71,(1970)$
\newline\bigskip


\noindent[Gea-71] Gear, C. William, Numerical Initial Value Problems in Ordinary Differential Equations, Prentice-Hall, Englewood Cliffs, NJ, 1971
\newline\bigskip

\noindent[GiTr-83] Gilbarg, David, and Neil S. Trudinger, Elliptic Partial Differential Equations of Second Order, Springer-Verlag, Berlin (1983)
\newline\bigskip

\noindent[GoVL-83] Golub, Gene, H., and Charles F. Van Loan, Matrix Computations, The Johns Hopkins University Press, Baltimore (1983)
\newline\bigskip

\noindent[GoWeWo-92] Gordon, Carolyn, David L. Webb, and Scott Wolpert, One cannot hear the shape of a drum, Bulletin of the American Mathematical Society $(N . S .) 27$ (1992), no. 1, pp. 134-138
\newline\bigskip
.
\noindent[Gre-97], Greenbaum, Anne, Iterative Methods for Solving Linear Systems, SIAM, Philadelphia, PA $(1997)$
\newline\bigskip

\noindent[HaLi-00] Hanselman, Duane, and Bruce Littlefield, Mastering MATLAB 6: A Comprehensive Tutorial and Reference, Prentice Hall, Upper Saddle River, NJ (2001)
\newline\bigskip

\noindent[Hea-00] Heathcote, Herbert, The mathematics of infectious diseases, S1AM Review 42 (2000), Pp. $599-653$
\newline\bigskip

\noindent[HiHi-00] Higham, Desmond J., and Nieholas J. Higham, MATLAB Guide, SIAM, Philadelphia, PA $(2000)$
\newline\bigskip

\noindent[HiSm-97]. Hirsch, Morris and Stephen Smale, Differential Equations, Dynamical Systems and Linear Algebra, Academic Press, New York (1997)
\newline\bigskip

\noindent[HoKu-71] Hoffman, Kenneth, and Ray Kunze, Linear Algebra, Prentice-Hall, Englewood Cliffs, NJ (1971)
\newline\bigskip

\noindent[HuLiRo-01] Hunt, Brian R., Ronald L. Lipsman, and Jonathan M. Rosenberg, A Guide to MATLAB: for Beginners and Experienced Users, Cambridge University Press, Cambridge, UK (2001)
\newline\bigskip

\noindent[Hur-90] Hurewicz, Witold, Ordinary Differential Equations, Dover Publications, New York (1990)
\newline\bigskip

\noindent[IsKe-66] Lsaacson, Eugene, and Keller, Herbert B., Analysis of Numerical Methods, John Wiley and Sons, New York (1966)
\newline\bigskip

\noindent[John-82] John, Fritz, Partial Differential Equations, Fourth Edition, Springer-Verlag, New York (1982)
\newline\bigskip

\noindent[Joh-87] Johnson, Claes, Numerical Solutions of Partial Differential Equations by the Finite Element Method, Cambridge University Press, Cambridge, UK (1987)
\newline\bigskip

\noindent[Kac 66] Kac, Mare, Can one hear the shape of a drwm?, Ameriean Mathematioai Mionthily, voi. $\mathbf{7 j}$. pp. $1-23(1966)$
\newline\bigskip

\noindent[Kah-66] Kahan, William M., Numerical linear algebra, Canadian Mathematical Bulletin, vol, 9, pp. $757-801(1966)$ $757-801(1966)$
\newline\bigskip

\noindent[Kel-68] Keller, Herbert B., Numerical Methods for Two-Point Boundary Value Problems, Blaisdell Publishing. Waltham, MA (1968)
\newline\bigskip

\noindent[KeMeK-27] Kermack, W. O., and A. G. MeKendrick, A contribution to the mathematical theory of epidemics, Proceedings of the Royal Society of London, Series A, vol. 115(772), pp. 700-721 (1927)
\newline\bigskip

\noindent[KaKr-58] Kantorovich, Leonid V,, and Vladimir 1. Krylov, Approximate Methods of Higher Analysis, P. Noordhoff Ltd., Amsterdam (1958).
\newline\bigskip

\noindent[Kev-00] Kevorkian, Jerry, Partial Differential Equations, Analytical Solution Techniques, SpringerVerlag. New York (2000)
\newline\bigskip

\noindent[Kol-99] Kolman, Bernard, and David R. Hill, Elementary Linear Algebra, Seventh Edition, PrenticeHall, Upper Saddle River, NJ (1999)
\newline\bigskip

\noindent[Kry-62] Krylov, Vladimir I., Approximate Calculation of Integrals, MacMillan, New York (1962)
\newline\bigskip

\noindent[Lag-85] Lagarias, Jeffrey C. The 3x+ I Problem and Its Generalizations. American Mathematical Monthly vol. 92, pp. 3-23, (1985)
\newline\bigskip

\noindent[Lam-91] Lambert, John D., Mumerical Methods for Ordinary Differential Systems, The Initial Value Problem, John Wiley \& Sons, New York, 1991
\newline\bigskip

\noindent[Lan-84] Langford, William $\mathrm{F}_{-}$, Numerical studles of torus bifurcations. Internationale Schriftenreihe zur Numerischen Mathematik, vol. 70. pp. 285-295 (1984)
\newline\bigskip

\noindent[Lan-99] Langtangen, Hans P., Computational Partial Differential Equations, Springer Verlag. Berlin (1999)
\newline\bigskip

\noindent[Lan-91] Lautwerier, Hans A., Fractals: Endlessly Repeated Geometrical Figures, Princeton University Press, Princeton, NJ (1991)
\newline\bigskip

\noindent[Log-94] Logan, J. David, An Introduction to Nonlinear Partial Differential Equations, John Wiley \& Sons, New York (1994)
\newline\bigskip

\noindent[Mat-99] Matilla, Pertti, Geometry of Sets and Measures in Euclidean Spaces. Fractals and Rectifiability, Cambridge University Press, Cambridge, UK (1999)
\newline\bigskip

\noindent[Maw-82] Mawhin, Jean, Periodic oscillations of forced pendulum-like equations, Lecture Notes in Mathematics No. 964, pp. 458-476, Springer-Verlag. New York (1982)
\newline\bigskip

\noindent[Maw-97] Mawhin, Jean, Seventy five years of global analysis around the forced pendulum equation, Proceedings of the Equadiff Conference at Bmo in 1997, pp. 115-145 (1997)
\newline\bigskip

\noindent[Mor-85] Morley, Tom, A simple proof that the world is three-dimensional, SIAM review, vol. 27, no. 1, pp. 69.71 (1985)
\newline\bigskip

\noindent[Mor-85b] Morley, Tom, Errata: A simple proof that the world is three-dimensional, SIAM review, vol. 28 , no, 2 , p. $229(1986)$
\newline\bigskip

\noindent[Mur-03] Murray, James D. Mathematical Biology, Volume I: An Introduction, Springer-Verlag. New York (2003)
\newline\bigskip

\noindent[Neu-98] Neumnier, Amold, Solving ill-condintoned and singular linear systems: a tutorial on regularization, SLAM Review, vol. 40(no. 3), pp. 626-666 (1998)
\newline\bigskip

\noindent[OkBoSu-92] Okabe, Atsuyuki, Barry Boots, Kokichi Sugihara, and Sung-Nok Chiu, Spatial Tessellation: Concepts and Applications of Varonoi Diagrams, John Wiley ak Sons, Chichester UK (1992)
\newline\bigskip

\noindent[OeS-99] Oliveira e Silva, Tomás, Maximum excursion and stopping time record-holders for the 3x+l problem. computational reswlts, Math. Comput. vol. 68, pp. 371-384, (1999),
\newline\bigskip

\noindent[PSM1-98] Part-Enander, Eva, Anders Sjoberg. Bo Melin, and Pernilla Isaksson, The MATLAB Handbook, Addison-Wesley, Harlow UK (1998)
\newline\bigskip

\noindent[PSJY-92] Peitgen, Heinz-Out, Dietmar Saupe, H. Jurgens, and L. Yunker, Chaos and Fracials: New Frontiers of Science, Springer-Verlag. New York (1992)
\newline\bigskip







\noindent[ReSh-97], Reichelt, Mark W. and Lawrence F. Shampine, The MATLAB ODE suite, SIAM Journal of Scientific Computing, vol. 18 no. 1, pp. 1-22 (1997)
\newline\bigskip

\noindent[ReRo-92] Renardy, Michael, and Robert C. Rogers, An Introduction to Partial Differential Equations, Springer-Verlag. New York (1992)
\newline\bigskip

\noindent[RiMo-67] Richtmyer, Robert D., Morton, K. W. Difjerence Methods for Initial Value Problems, Second Edition, John Wiley \& Sons, New York (1967)
\newline\bigskip

\noindent[Ros-00] Rosen, Kenneth H., Handbook of Discrete and Combinatorial Mathematics, CRC Press, Boca Raton, FL (2000)
\newline\bigskip

\noindent[Ros-96] Ross, Keneth A., Elementary Analysis. The Theory of Calculus, Eighth Edition, SpringerVerlag. New York ( 1996$)$
\newline\bigskip

\noindent[Rud-64] Rudin, Walter. Principles of Mathematical Analysis, Second Edition, MeGraw-Hill, New York $(1964)$
\newline\bigskip

\noindent[Sch-95] Sehreiber, Peter, The Cawchy-Bunyakoushy-Schwarz inequalify, in Hermann Grassmann, (Lieschow, 1994) pp. 64-70, Emst-Moritz-Amdt Univ., Greifswald, Germany (1995)
\newline\bigskip

\noindent[Sch-73] Schultz, Martin. H., Spline Analysis, Prentice-Hall, Englewood Cliffs, N] (1973)
\newline\bigskip

\noindent[ShAIPr-97] Shampine, Lawrence F., Richard Allen and Steve Pruess, Fundamentals of Numerical Computing, John Wiley \& Sons, New York, (1997)
\newline\bigskip

\noindent[Smi-85] Smith, Gordon D., Numerical Solution of Partial Differemtial Equations, Oxford University Press, New York (1985)
\newline\bigskip

\noindent[Smo-83] Smoller, Joel, Shock Waver and Reaction-Diffusion Equations, Springer-Vering, New York $(1983)$
\newline\bigskip

\noindent[Sni-99] Snider, Arthur David, Parfial Differential Equations, Sources and Solutions, Prentice-Hall, Upper Saddle River, NJ (1999)
\newline\bigskip

\noindent[StBu-92] Stoer, Josef, and Roland Bulirsch, Introchetion to Numerical Analysis, Springer-Verlag: TAM Series \#12. New York (1992)
\newline\bigskip

\noindent[Sta-79] Stakgold, Ivar, Green's Funetion and Boundary Value Problems, John Wiley \& Sons, New York (1979)
\newline\bigskip

\noindent[Str-88] Strang, Gilbert, Linear Algebra and Its Applications, Third Edition, Prentice-Hall, Englewood ClafT, NJ $(1988)$ Eaglewood Cliffs, N) $(1988)$
\newline\bigskip

\noindent[StFj-73] Strang, Gilbert, and George J. Fix, An Analysis of the Finite Element Method, PrenticeHall, Englewood Cliffs, NJ (1973)
\newline\bigskip

\noindent[Str-92] Strauss, Walter A., Partial Differential Equations, An Introduction, John Wiley \& Sons, New York (1992)
\newline\bigskip

\noindent[StVa-78] Strauss, Walter. A. and Luis Yanquez Numerical solufion of a monfineor Klein-Gordon equarion, Joumal of Computational Physics, vol. 28, pp. 271-278 (1978)
\newline\bigskip

\noindent[SuDr-95] Su, Peter and Robert L. Drysdale, A comparison of sequential Delaunay iriangulation algorithms, in Proceeding of the ACM IIth Annual Symposium on Computational Geometry. Pp. 61$70, \mathrm{ACM}$, Vancouver, CANADA (1995)
\newline\bigskip



\noindent[Tho-95a] Thomas, James W., Numerical Partial Differential Equations, Finite Difference Methods, Springer-Verlag, New York (1995)
\newline\bigskip

\noindent[Tho-95b] Thomas, James W., Numerical Partial Differential Equations, Conservation Laws and Elliptic Equations, Springer-Verlag, New York (1995)
\newline\bigskip

\noindent[TrBa-97] Trefethen, Lloyd N. and David Bau, III, Numerical Linear Algebra, SIAM, Philadelphia, PA (1997)
\newline\bigskip

\noindent[Vor-08] Voronoi, Georges, Nouvelles applications des paramèmetres continues à la théorie des formes quadratiques, J. Reine Angew. Math., vol. 133, pp. 97-178 (1907) and vol. 134, pp. 198-287 (1908)
\newline\bigskip

\noindent[Wei-65] Weinberger, Hans F., A First Course in Partial Differential Equations, John Wiley \& Sons, New York (1965)
\newline\bigskip

\noindent[Wil-88] Wilkinson, James H., The Algebraic Eigenvalue Problem, Clarendon Press, Oxford, UK (1988)
\newline\bigskip

\noindent[You-71], Young, David M., Iterative Solution of Large Linear Systems, Academic Press, New York, (1997)
\newline\bigskip

\noindent[Zau-89] Zauderer, Erich, Partial Differential Equations of Applied Mathematics, Second Edition, John Wiley \& Sons, New York (1989)
\newline\bigskip

\noindent[ZiMo-83] Zienkiewicz, Olgierd C., and Kenneth Morgan, Finite Elements and Approximation, John Wiley \& Sons, New York (1983)


\newpage
\textbf{\textbf{MATLAB Command Index}}


\begin{math}
\begin{aligned}
&\text { FAMILIAR MATHEMATICAL FUNCTIONS OF ONE VARIABLE }\\
&\begin{array}{|l|l|}
\hline \text { Algebraic } & \operatorname{sqrt}(x)(=\sqrt{x}), \operatorname{abs}(x)(=|x|) \\
\hline \begin{array}{l}
\text { Exponential/ } \\
\text { Logarithmic }
\end{array} & \exp (x)\left(=e^{x}\right), \log (x) \quad(=\ln (x)), \log 10 \\
\hline \text { Trigonometric } & \sin , \cos , \text { tan, sec, etc, asin, etc, asin, etc, sinh, cosh, etc., asinh, etc., } \\
\hline
\end{array}
\end{aligned}
\end{math}

\noindent\textbf{MATLAB COMMANDS AND M-FILES: NOTE: Textbook-constructed M-files are indicated with an asterisk after page reference. Optional input variables are underlined. Most of the auxiliary M-files representing specific functional data needed to solve examples in Part III have been omitted.}



\begin{multicols}{2}
\begin{lstlisting}[frame=none, numbers=none]
A(i,j),		77,147 
A([i1 i2 ... imax], :), 77 
adamsbash5 (f,a,b,yO,h),	339* 
adamspc(f,a,b,yO,h),	339* 
ans,	6 
axis('equal') , 12 
axis([xmin xmax ymin ymax]), 30 
			 - zmin zmax]), 466 
			 
backeuler(f,a,b,yO,h), 334* 
backsubst(U,b), 206* 
backwdtimecentspace(phi,L,A,B, 
		Τ,Ν,Μ, alpha,q), 578* 
bdyintapprox(f,tri,redges), 669* 
bisect(f,a,b,tol), 113* 
break, 62,63 
BSSpline(x), 750 
bumpy(x), 50*
 
cart2pol(x,y), 657 
ceil(x), 66 
circdrw, 46* 
circdrwf(xO,yO,r), 46* 
clear,	6 
clf, 175 
collatz,	68* 
collctr,	69* 
colormap([r g b]), 463 
comet3(x, y, z), 465 
cond(A,p), 228 
contour(x,y,2,n), 464 
cranknicolson(phi,L,A,Β,Τ,Ν, 
	M, alpha, q), 577* 
eranknicoIsonRobinLR(phi,L,A,B, 
	T,N,M,alpha,q), 585* 
dalembert (c,h,T,phi,nu,ran), 529* 
delaunay(x,y), 610 
det(A), 77,149 
diag(v,k), 147,149,152
\end{lstlisting}



\begin{lstlisting}[frame=none, numbers=none]
diary, 2
dblquad(f,xmin,xmax,ymin,ymax, 
	tol,gd,pi, ...), 651
	
	
eig(A), 244 
eps, 115 
error('message') , 115 
euler2d(f,g,a,b,x0,y0,h) , 360* 
eulermeth(f,a,b,y0,hstep) , 297* 
ex4_5(x), ex4_5v2(x), 66* 
exist('name') , 47 
eye(n), 148
 
fact(n) , 47 
factor, 211 
factorial(n), 28 
feval(exp,vars), 112 
fill(x,y,'c'), 159 
floor(x), 66 
flops, 75 
fminbnd(f,a,bj,opt), 52 
for...end, 60 
format bank/long/,etc., 4 
fprintf ('mssg', vars), 64,65,125 
full(S), 276 

function, 46 
fwdsubst(L,b), 207* 
fwdtimecentspace(phi,L,A,B,T, 
	N, M, alpha, q), 578* 
fzero(f,a), 54
 
gamma(n), 28 
gaussseidel (A,b, xO, tol, k), 256* 
gausselim(A,b), 215* 
gaussianintapprox(f,V1,V2,V3), 
					663* 
getframe, 167 
global, 436 
\end{lstlisting}
\end{multicols}

\newpage
\noindent
\begin{multicols}{2}
\begin{lstlisting}[frame=none, numbers=none]
gmres(A,b,r,tol,k,Ml,M2,xO), 274 
grid, 462-463 
gtext ('label'), 14
 
help, 6,7 
hilb(n), 192 
hold on / hold off, 10
 
if...elseif/else...end, 61-64 
impeuler(f,a,b,yO,hstep), 308* 
Inf (or inf ), 88, 149 
inline('exp', 'vars') , 111,112 
inpolygon(x,y,xpoly,ypoly), 628 
input('phrase': ') , 67 
inv(A), 149
 
jacobi(A,b,xO,tol,kmax), 256*
 
1cm (a, b), 194 
linearshooting(p,q,r,a, 
	alpha,b,beta,h), 407* 
linspace(F,L,N), 8 
listp2 , 47* 
load, 6 
lu(A), 214 

max(v), 53,155,214 
mesh(X,Y,Z), 461-462 
meshc(x,y,Z), 463 
meshgrid(x,y), 460 
min(v), 53,155 
mkhom(A), 169* 
movie(M, rep, fps), 167 
mydet2, mydet3, mydet, 77*
 
nan (output), 492 
nargin, 113 
newton(f,fp,xO,tol,n), 120* 
newtonsh(f,fp,xO,tol,n), 124* 
newtonmr(f,fp,xO,or,tol,n), 124* 
nonlinshoot(a, alpha, b, beta, 
	f, fy, fyp, tol, h), 415* 

norm(A,p), 227 
norm(x, p), 225,226 
num2str (a,n), 333
 
ode45(f, [a b],yO,opts), 321 
onedimwave(phi,nu,L,A,B,
	T,N,M,c), 550* 
onedimwavebasic(phi,nu,L,A,B, 
	T,N,M,c), 554* 
onedimwaveimpl_4(phi,nu,L,A,B, 
	T,N,M,c), 559* 
ones(n,m), 150 
optimset, 52
\end{lstlisting}




\begin{lstlisting}[frame=none, numbers=none]
patch([x xrev],[top toprev] , 
[r g b]) , 783 
path, 45 
pcq(A,b,tol,kmax,Ml,M2,xO), 273 
plot (x,y , style) , 8,10 
plot3(x,y,z ) , 465 
poissonsolver(q,a,b,c,d,h) , 488* 
pol2cart(r,th) , 657 
poly (A), 257 

quad(f ,a,b , tol ) /quadl, 51,52 
quad2d(f,a,b,ylow , ytop), 654* 
quit, 3 

\r, 62 
raffledraw, 80 
rand, 79 
rand(n,m), 77 
randint(n,m,k), 152* 
rayritz(p, q, f, n), 448* 
rectanglepoissonsolver(h,a,b, 
	varf,lft,rt,top,bott), 506* 
return, 62 
rkf45(f,a,b,yO,tol,hO,hmx), 329* 
rksys(vecf,a,b,vecx,hstep) , 386* 
roots (vector), 139,246 
rot(Ah,x0,y0,th), 169* 
round(x), 66 
rowcomb(A,i,j,c), 209* 
rowmult(A,i,c), 209* 
rowswitch(A,i,j), 208* 
rref(Ab), 195,196 
runkut (f, a, b, yO, h), 307 
runkut2d(f,g,a,b,x0,y0,h) , 360* 

save, 6 
secant (f, xO, xl, tol, n), 130, 131* 
semilogy (x, y), semilogx, 255 
setdiff (a,b), 620,658 
sgasketl (V1, V2, V3, n), 173-175* 
sgasket2(V1,V2,V3,n), 175-177* 
sgasket3(V1,V2,V3,n), 177-179* 
sign(x), 113 
snow(n), 179,180* 
sorit(A,b,omega,xO,tol,k), 258* 

sorsparsediag(diags,inds,b,om, 
	x0,tol,k), 271* 
spdiags(Diags,d,n,n), 276 
spy (A), 491* 
strrepCstrg', 'old', 'new'), 742 
sum2sq(n), 67* 
subplot(m,n,i), 30 
surf (x,y, Z), 463 

\end{lstlisting}
\end{multicols}


\newpage
\noindent
\begin{multicols}{2}
\begin{lstlisting}[frame=none, numbers=none]
text(x,y, 'label') , 14 
thomas(a,d,b,c) , 421* 
t i c ... toc , 74,75 
title ('toplabel') , 11 
triangledirichletsolver(n,left 
	,bott,slant) , 493* 
trianglequad2d(f,v1,v2,v3) , 655* 
trimesh(T,x,y,z,C) , 606 
twodimwavedirbc(phi,nu,a,b,T , 
		h,c),561 * 
type filename (displays file), 246 
	(filename = name of M-file)
 
vectorize('string') , 334 
vertscale(Ah,b,yO) , 714 
view(azim, elev) , 464 
voronoi(x,y) , 610 
voronoiall(x , y), 611
 
waterfall(x,y,Z) , 463 
while...end , 16 
who, 5
\end{lstlisting}




\begin{lstlisting}[frame=none, numbers=none]
whos, 6
 
xlabel('bottom label'), 11 
xor(p,q), 58 

ylabel('left label'), 11 

zeros(n,m), 150 
zlabel('vertical label'), 463 

; (2 uses), 4/5 
' (transpose), 8 
: (vector construct), 8 
>, <, >= ,<= ,==, ~=, 37 
@ (calls M-file), 51 
&, | (or), ~ (not), 58 
\ (matrix left-divide), 187 
% (comment), 7 
... (continue input), 78
^ (matrix power), 146 
\end{lstlisting}
\end{multicols}


\noindent\textbf{SYMBOLIC TOOLBOX COMMANDS:}

\begin{multicols}{2}
\begin{lstlisting}[frame=none, numbers=none]
char(SymExp), 334 
diff(f,x,n), 692 
digits(d), 694 
double(sn), 695 
dsolve('DE1','DE2', ...,'c1', 
	'c2', ... , 'var'), 696-698 
expand(exp), 690 
ezplot(f, [a b] ), 697 
factor(exp), 690
\end{lstlisting}



\begin{lstlisting}[frame=none, numbers=none]
int(f,x,a,b), 692 
pretty , 690 
simplify(exp) , 690 
solve(exp,var) , 691 
subs(S,old,new) , 694 
sym(fpn), 695 
syms, 690 
vpa(a,d) , 694 
taylor (f,n,a) , 695
\end{lstlisting}
\end{multicols}

\newpage
\noindent
\textbf{General Index}

\begin{multicols}{2}
\noindent
Adams family methods, 338\\
Adams-Bashforth method, 338\\
Adams-Moullon method, 339\\
Abel, Niels Henrik, 108, 109\\
Actual error, 24\\
Adaptive method, 327\\
Admissible function, 427\\
Affine transfoemation. 163\\
Agebraic multiplicity, 243\\
Approximation, 24\\
Associated matrix norm, 226\\
Asymptotic errof constant, 133\\
Augmented matrix, 195\\
Autonomoes, 357\\
Auxiliary condition, 286\\
\bigskip
Back substitution, 206\\
Backward difference approximation, 509\\
Backward Euler method, 332\\
Base, 85, 94\\
Basin of attraction, 382\\
Basis theorem, 193\\
Bendixson, Ivar, 382\\
Big-0 notation, 320\\
Binary arithmetic, 85\\
Birth rate, 290\\
Birthday problem, 70\\
Bistetion method, 110\\
Boundary eondition, 475\\
- Cauchy, 527\\
- Dirichlet, 476\\
- Neunann, 476\\
- Robin, 637\\
Boundary value problem, $\mathbf{3 5 5}, \mathbf{3 9 9}$\\
Bracket, 116\\
Buryakowsky, Viktor Yakovlevich, 455\\
\bigskip
Cantor, Georg F.L. P, 169\\
Cantor square, 184\\
Cardano, Girolamo, 108\\
Carrying capacity, 292\\
Cauchy, Augustin Louis, 455\\
Cauchy-Bunyakowski-Schware inequality, 455\\
Cauchy problem, 527\\
Center, $36 ?$\\
Central difference formuls, $43,418419,544$\\
Characieristic polynomial, 241,342\\
Chopped arithmetic, 89\\
Clay Foundation, 68\\
Cofactor expsnsion, 76\\
Collate, Lothar, 77\\
Collatz conjecture, 67,68\\




\noindent
Column, 143\\
Combinatorics: alternating power sums, 202\\
Combinatorics: power sums, 202\\
Coempatibility candition, 508\\
Compenent-wise operation, 9\\
Computed solution, 231\\
Computer graphies, 157\\
Condition number, 228-230\\
Conservation of energy, 537\\
Convergence order, 132\\
Convergence theorem, 262, 264, 265, 266\\
Convex hull, 609\\
Coestact rate, 366\\
Counter, 60\\
Courant, Richard, 597-598\\
Courant-Friedrichs-Levy eondition, 548\\
Cramer, Gabriel, 203\\
Crtmer's rule, 203\\
Crank, John, 575\\
Crank-Nicolson method, 575-577\\
Cycling 122\\
\bigskip
D'Alembert, Jean Le Rond, 525\\
Death rate, 290\\
Degree, 25\\
Delaunay triengulation, 608\\
Determinast, 75, 222\\
Diagonal matrix 147\\
Dianseter, 71\\
Differential Equation (DE), $2 B 5$\\
Diffusivity, 469\\
Dilation, 172\\
Dimension, 171\\
Dircet rethod, 252\\
Dirichlet's principle, 520\\
Discriminant, 379, 474\\
Divergence theorem, 519\\
Divided differenee. 131\\
Doenain of dependenee, 531\\
Dot product, 22, 144\\
Double root, 130\\
\bigskip
Eigendats, 240\\
Eigenfanction. 441. 496\\
Eigenspace. 243\\
Eigenvalue, $240,496,497$\\
Eigenvector, 240\\
Element, 598\\
- Standard. 633\\
- Standard rectan zular. 629\\
Elementary row operation $(\mathrm{EOO}), 20 \%$\\
Epicycloids. 13
\end{multicols}

\newpage
\noindent
\begin{multicols}{2}
\noindent Epidenic, 366\\
Equilibrium solution, 299, 362, 373\\
- Isolated, 377\\
Equivalent linear system, 195\\
Error bound via residual, 233\\
Error function, 42\\
Error term, 231\\
Essentially disjoint, 172\\
Exclidean length, 224\\
Euler, Leonhard, 292-293\\
Euler's method, 292-294\\
Exact answer, 24, 231\\
Expected value, 83\\
Existence theorem, 314, 376, 402, 494, 496,\\
$507,515,585$\\
Explicit method, 332\\
\bigskip
False, 57\\
Fem leaf fractal, 185\\
Finite difference schemes\\
- Crank-Nicolson, 575-577\\
- Elliptic, Sec. 11.3,11.4\\
- Explicit, 542-543\\
- Forward-time central-space, 573\\
- Backward-ime central-space, 574\\
- Implicit, 558\\
- ODEs, $418.425$\\
- Richardsen, 575\\
Finite element interpolant, 607\\
Finite element method, 597\\
First generation, 170\\
Fixed point iteration, 140\\
Flosting point number, $8.5$\\
Flop, 74\\
Flop counis (for Omussian elimination), 226\\
Flow, 323\\
Fontana, Niccolo 108\\
Forward substitution, 207\\
Forward difference formula, 43,508\\
Fractals (fractal sets). 169\\
Futare value annuities, 72. 73\\
\bigskip
Galerkin, Boris Grigorievich, 440\\
Gaierkin method, 440\\
Galois, Evariste, 109\\
Gauss, Carl Friedrich, 204\\
Gauss quadrature, 662\\
Gauss-Seidel iteration, 256\\
Gaussian elimination, 203-213\\
General solution, 286\\
Generalized minimum residual method, 273.274\\
Geometric multiplicity, 243\\
Ghost node, 509\\
Global solution, 315\\
Global variables, 46\\
Gomperz law, 300\\
Gosper island fractal, 185, 186\\
Green's identities, 519\\
- First, 519\\





\noindent - Second, 520\\
Gromth rale, 290\\
\bigskip
Hamming, Richard Wesley, 348\\
Hamming method, 348\\
Harmonic function, 476\\
Hat function, 432\\
Heat eonductivity, 469\\
Heat (diffusion) equation, 469,470\\
- Fundarnental solution, 478\\
- With source term, 470\\
Heun's method, 303\\
Higher-arder Taylor methods, 318\\
Hilbert, David, 193\\
Honsogeneous, 401, 472\\
Hormogeneous coordinses, 163,164\\
\bigskip
Hyper convergenee of order $a, 133$\\
IEEE dosble precision standard, 86\\
IIl-eanditioned, 102\\
Ill-posed, 187\\
Iemplicit method, 332\\
Improved Euler method, 303-304\\
Infectivity, 364\\
Initial condition (|C], 286\\
Initisl value problem (TVP), 286\\
Inline function, 51\\
Infinite loop, 16\\
Infinity matrix norm, 227\\
Infinity (vector) norm, 225\\
Initial pepulation, 290\\
Inner product, 427\\
Input-output analysis, 200,201\\
Intemal demand matrix, 201\\
Internal elastie energy, 428\\
Inverse of a matrix, 148\\
Invertible (nonsingular), 148\\
llerative, 109\\
lierakive method, 252\\
Iterative refinemext, 249\\
\bigskip
Jacobj-Cass coevergence theorem, 262\\
Jacobi iteration, 253\\
Jacobian matrix, 378\\
Julia, Gaston, 169\\
\bigskip

\noindent Kinetic energy, 535\\
Kronteker delta, 608\\
Kurta, Martin W , 305\\
\bigskip

\noindent Lagrange, Joseph Louis, 471\\
Laplace, Pierre Simon, 471\\
Laplace equation, 471\\
Laplace eperater (Laplacian), 470\\
- in polar coordinates, 686\\
Leading one, 195\\
Leontief, Wassily, 200\\
Linear eonvergenee, 133\\
\end{multicols}


\newpage
\noindent
\begin{multicols}{2}
\noindent Linear operator, 473\\
Linear ODE, 401\\
Linear PDE, 472\\
Linear transformation, 160\\
Lincarization, 378\\
Lipschitz condition, 313,376\\
Load potential, 428\\
Load vector, 434,443\\
Local basis, 607\\
Local solution, 315\\
Local truncation error, 317\\
Local variables, 46\\
Logic, 57\\
Logical operators, 58\\
Logistical growth model, 291\\
Lorenz, Edward N., 387\\
Lorenz strange attractor, 387\\
Lotka, Alfred, 359\\
Lower triangular, 205\\
LU decomposition (or factorization), 213\\
\bigskip

\noindent M-file, 45\\
- Function M-files, 45\\
- Script M-files, 45\\
Machin, John, 43\\
Machine epsilon, 86\\
Maclaurin, Colin, 39\\
Maclaurin series, 38\\
Malthus, growth model, 290\\
Mandelbrot, Benoit, 170\\
Mantissa, 87\\
Matrix, 143\\
- Banded, 152, 420\\
- Block, 502\\
- Diagonally-dominant, 221, 264, 422\\
- Elementary, 208\\
- Hilbert, 192\\
- Identity, 148\\
- Nonsingular (invertible), 148\\
- Positive definite, 265\\
- Sparse, 151, 269-278, 420\\
- Stiffness, 434, 443\\
- Technology. 201\\
- Tridiagonal, 420\\
Matrix arithmetic, 144\\
Max norm, 225\\
Maximum principle, $477,586,595$\\
Midpoint method, 343\\
Monte-Carlo method, 173\\
Mother loop, 62\\
Multiple root, 125\\
Multiplicity 1, 55\\
Multistep method, 337\\
\bigskip

\noindent Natural growth rate, 292\\
Nearly singular (poorly conditioned), 228\\
Necrotic, 300\\






Nested loop, 61\\
Newton's method, 118,119 Newton-Coates formula, 669 Nicolson, Phyllis, 575 Node, 602\\ Nonautonomous, 357 Nullclines, 373 Numerical differentiation, 43 Numerically stable, 334\\ Numerically unstable, 335\\
\bigskip

\noindent One-step method, 303\\
Orbit, 362\\
- Closed, 382\\
Ordinary Differential Equation (ODE), 285\\
Output matrix, 201\\
Overflow, 88\\
\bigskip

\noindent Parallel, 239\\
Parametric equations, 11\\
Partial Differential Equation (PDE), 285,459\\
- Divergence form, 637\\
- Elliptic, 474\\
- Hyperbolic, 474\\
- Parabolic, 474\\
Partial pivoting, 211\\
Path (MATLAB's), 45\\
Peano, Guiseppe, 169\\
Pendulum model, 389\\
Perfect number, 81 Phase-plane, 362\\
Piecewise smooth, 496\\
Pivot, 211\\
Poincare, Henri, 378\\
Poincaré-Bendixson theorem, 382\\
Poisson, Siméon-Denis, 649-649\\
Poisson's integral formula, 649\\
Poisson equation, 479\\
Polynomial, 25\\
Polynomial interpolation, 189, 197-199\\
Poorly conditioned matrix, 150, 228\\
Potential energy, 536\\
Potential theory, 476\\
Preconditioned conjugate gradient method, 273\\
Preconditioning, 273\\
Predator-prey model, 358-360\\
Predictor-corrector scheme, 339\\
Prime number, 81\\
Principle of minimum potential energy, 428\\
Principle of virtual work, 428\\
Prompt, 2\\
Pyramid function, 603\\
\bigskip

\noindent Quadratic convergence, 139\\
Quadrature, 51\\
Quartic, 108\\
Quintic, 108
\end{multicols}


\newpage
\noindent
\begin{multicols}{2}
\noindent Random integer matrix generator, 152\\
Random walk, 82\\
Rayleigh-Ritz method, 426-458\\
Recursion formulas, 15\\
Reduced row echelon form, 195\\
Reflection, 162\\
- Method of, 531\\
Region of numerical stability, 335\\
Relative error bound (via residual), 233\\
Relaxation parameter, 258\\
Remainder (Taylor's), 35\\
Repelling, 382\\
Reproduction rate, 367\\
Residual, 116\\
Residual matrix, 250\\
Residual vector, 232\\
Rhind Mathematical Papyrus, 107\\
Richardson's method, 575\\
Ritz, Walter, 426\\
Root, 110\\
Rossler, Otto, 395\\
Rotation, 161\\
Rounded arithmetic, 89\\
Row, 143\\
Runge, Carle D. T., 205\\
Kunge-Kutta method,\\
- Classical, 304-305\\
- Higher order, 350\\
\bigskip

\noindent
Scalar, 240\\
Scalar multiplication, 144\\
Scaling, 161\\
Schwarz, Hermann Amandus, 455\\
Secant method, 128,129\\
Self-similarity property, 169\\
Separation of variables. 302\\
Shearing , 181\\
Shift transformation, 162\\
Shooting method, 399\\
- Linear, 403-411\\
- Nonlinear, 411-418\\
Sierpinski, Waclaw, 170\\
Sierpinski carpet fractal, 184, 185\\
Sierpinski gasket fractal, 170\\
Significant digits, 85\\
Similarity transformation, 172\\
Simple root, 125\\
Simpson's Rule, 325\\
Simulation, 79\\
Single-step method, 337\\
Singularity, 527\\
SIR model, 363\\
SIRS mode, 367\\
Solution, 285\\
SOR (successive over relaxation), 258\\
SOR convergence theorem, 264\\
Special function, 693\\
Specific heat, 468\\





\noindent Spectrum, 251, 497\\
Spline, 449\\
Stability, 323, 381\\
Stability condition, 574\\
Stable, 299, 323, 376\\
- Conditionally, 586\\
- Neutrally, 323\\
- Unconditionally, 586\\
- Weakly, 342\\
Standard local basis, 608\\
Statement, 57\\
Steady-state solution, 336\\
Stencil, 481,542,576\\
Step size, 293\\
Stiff, 335\\
Strutt, John William, 426\\
Submatrix, 76\\
Superposition principle, 473\\
Symbolic computation, 689\\
Symmetric matrix, 243\\
\bigskip

\noindent Tartaglia, 108\\
Taylor, Brook, 34\\
Taylor polynomial, 25\\
Taylor series, 38\\
Taylor's theorem,\\
- One variable, 35\\
- Two variables, 350\\
Tessellation, 186\\
Thomas, Llewellyn H., 220\\
Thomas method, 220\\
Three-body problem, 391\\
Tolerance, 24\\
Torricelli, Evangelista, 312\\
Torricelli's law, 312\\
Traffic logistics, 199,200\\
Transient part, 335\\
Transpose, 7\\
Trapezoid method, 337\\
Triangulation, 598\\
Tridiagonal matrix, 150\\
Triple root, 126\\
True, 57\\
Truth value, 57\\
Two-body problem, 391\\
\bigskip

\noindent Unconditional numerical stability, 336\\
Underflow, 88\\
Uniqueness theorem, $314,376,402,421,494$,\\
$496,507,515,585$\\
Unit roundoff, 86\\
Unstable, $299,323,376,548$\\
Upper triangular matrix, 204\\
\bigskip

\noindent van der Pol, Balthasar, 396\\
van der Pol equation, 396\\
Vandermonde matrix, 197\\
Variable precision arithmetic, 689\\
Vector, 7\\
\end{multicols}

\newpage
\noindent
\begin{multicols}{2}
\noindent Vector norm, 225\\
Verhulst, Peirre François, 292\\
Volterra, Vito, 358-359\\
von Koch, Niels F.H., 179\\
von Koch snowflake, 179\\
Voronoi diagram, 610\\
Voronoi region, 609\\
Vortex, 362\\




\noindent Wave equation, $474,523,524$\\
Weierstrass, Karl, 179\\
Weights, 662\\
Well-conditioned, 102\\
Well-posed, 187\\
\bigskip

\noindent Zero divisors, 105\\
Zeroth generation, 170\\
\end{multicols}



\newpage
\noindent
\textbf{PURE AND APPLIED MATHEMATICS}\\
A Wiley-Interscience Series of Texts, Monographs, and Tracts 
\bigskip

\noindent Founded by RICHARD COURANT
Editors Emeriti: MYRON B. ALLEN III, DAVID A. COX, PETER HILTON, HARRY HOCHSTADT, PETER LAX, JOHN TOLAND
\bigskip

\noindent ADAMEK, HERRLICH, and STRECKER-Abstract and Concrete Catetories \\
ADAMOWICZ and ZBIERSKI-Logic of Mathematics\\
AINSWORTH and ODEN-A Posteriori Error Estimation in Finite Element Analysis\\
AKIVIS and GOLDBERG - Conformal Differential Geometry and lts Generalizations\\
ALLEN and ISAACSON-Numerical Analysis for Applied Science\\
ARTTN-Geometric Algebra\\
AUBIN-Applied Functional Analysis, Second Edition\\
AZIZOV and IOKHVIDOV-Linear Operators in Spaces with an Indefinite Metric\\
BERG-The Fourier-Analytic Proof of Quadratic Reciprocity\\
BERMAN, NEUMANN, and STERN-Nonnegative Matrices in Dynamic Systems\\
BERKOVITZ-Convexity and Optimization in $\mathbf{R}^{n}$\\
BOYARINTSEV-Methods of Solving Singular Systems of Ordinary Differential Equations\\
BURK-Lebesgue Measure and Integration: An Introduction\\
*CARTER-Finite Groups of Lie Type\\
CASTILLO, COBO, JUBETE, and PRUNEDA-Orthogonal Sets and Polar Methods in Linear Algebra: Applications \centerline{to Matrix Calculations, Systems of Equations, Inequalities, and Linear Programming}\\
CASTILLO, CONEJO, PEDREGAL, GARCI $A$, and ALGUACIL-Building and Solving Mathematical Programming \centerline{Models in Engineering and Science}\\
CHATELIN-Eigenvalues of Matrices\\
CLARK-Mathematical Bioeconomics: The Optimal Management of Renewable Resources, Second Edition\\
COX-Galois Theory\\
+COX-Primes of the Form $x^{2}+m y^{2}$ : Fermat, Class Field Theory, and Complex Multiplication\\
*CURTIS and REINER-Representation Theory of Finite Groups and Associative Algebras \\
*CURTIS and REINER-Methods of Representation Theory: With Applications to Finite\\
\centerline{Groups and Orders, Volume I}\\
CURTIS and REINER—Methods of Representation Theory: With Applications to Finite\\ 
\centerline{Groups and Orders, Volume II}\\
DINCULEANU-Vector Integration and Stochastic Integration in Banach Spaces\\
*DUNFORD and SCHWARTZ-Linear Operators\\
\centerline{Part 1-General Theory}\\
\centerline{Part 2-Spectral Theory, Self Adjoint Operators in
Hilbert Space}\\
\centerline{Part 3-Spectral Operators}\\
FARINA and RINALDI-Positive Linear Systems: Theory and Applications\\
FOLLAND-Real Analysis: Modern Techniques and Their Applications\\
FROLICHER and KRIEGL-Linear Spaces and Differentiation Theory\\
GARDINER-Teichmuller Theory and Quadratic Differentials
GILBERT and NICHOLSON-Modern Algebra with Applications, Second Edition\\
*GRIFFITHS and HARRIS-Principles of Algebraic Geometry\\
GRILLET-Algebra\\
GROVE - Groups and Characters\\
GUSTAFSSON, KREISS and OLIGER-Time Dependent Problems and Difference Methods\\
HANNA and ROWLAND-Fourier Series, Transforms, and Boundary Value Problems,\\
\centerline{Second Edition}
*HENRICl-Applied and Computational Complex Analysis\\
\centerline{Volume 1, Power Series-Integration-Conformal Mapping-Location}\
\centerline{of Zeros}\\
\centerline{Volume 2, Special Functions-Integral Transforms-Asymptotics-}\\
\centerline{Continued Fractions}\\
\centerline{Volume 3, Discrete Fourier Analysis, Cauchy Integrals, Construction}\\
\centerline{of Conformal Maps, Univalent Functions}\\
SMITH and ROMANOWSKA-Post-Modem Algebra\\
STAKGOLD Green's Functions and Boundary Value Problems, Second Editon\\
STAHL-Introduction to Topology and Geometry\\
STANOYEVITCH-Introduction to Numerical Ordinary and Partial Differential\\
\centerline{Equations Using MATLAB \textregistered}\\
*STOKER-Differential Geometry\\
*STOKER-Nonlinear Vibrations in Mechanical and Electrical Systems\\
*STOKER-Water Waves: The Mathematical Theory with Applications\\
WATKINS-Fundamentals of Matrix Computations, Second Edition\\
WESSELING-An Introduction to Multigrid Methods\\
"WHITHAM-Linear and Nonlinear Waves\\
+ZAUDERER-Partial Differential Equations of Applied Mathematics, Second Edition




\clearpage
\end{document} 
